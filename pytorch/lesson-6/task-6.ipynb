{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fdcb05d-4010-478f-8a47-896f455a5607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#csv_path = \"../../../DataSetStore/twitter_msg_sentiment_anal/twitter_sentiment_analysis.csv\"\n",
    "csv_path = \"../../../DataSetStore/twitter_msg_sentiment_anal/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6471fc3-acf6-4373-a59f-14079bf9dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 2000\n",
    "max_len = 20\n",
    "num_classes = 1\n",
    "\n",
    "# Training\n",
    "epochs = 5\n",
    "batch_size = 512\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd5abe4c-1430-4078-a0fc-af1816a17b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install stop-words pymorphy2\n",
    "#!pip install invoke\n",
    "#!pip install nltk\n",
    "#!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9f0f3c8-45f0-4c28-a17f-3483d7d0d35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f46916b6-c790-4d52-873f-204e17cca2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    29720\n",
       "1     2242\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7972c3e9-1142-4dbc-9783-97f39fb43251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " \"can't\",\n",
       " 'cannot',\n",
       " 'could',\n",
       " \"couldn't\",\n",
       " 'did',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " \"he's\",\n",
       " 'her',\n",
       " 'here',\n",
       " \"here's\",\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " \"how's\",\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"let's\",\n",
       " 'me',\n",
       " 'more',\n",
       " 'most',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'ought',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'same',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that's\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " \"there's\",\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 'very',\n",
       " 'was',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'were',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " \"what's\",\n",
       " 'when',\n",
       " \"when's\",\n",
       " 'where',\n",
       " \"where's\",\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " \"who's\",\n",
       " 'whom',\n",
       " 'why',\n",
       " \"why's\",\n",
       " 'with',\n",
       " \"won't\",\n",
       " 'would',\n",
       " \"wouldn't\",\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stop_words import get_stop_words\n",
    "\n",
    "stop_word_set = set(get_stop_words(\"en\"))\n",
    "stop_word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d249274-a300-45b9-8ff4-075429e7d3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation_set = set (punctuation)\n",
    "punctuation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d944ba7-a798-45e1-ac14-103661c85f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import ascii_lowercase\n",
    "ascii_list= list(ascii_lowercase)\n",
    "ascii_list.append(\" \")\n",
    "en_alphabet_set = set(ascii_list)\n",
    "en_alphabet_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dbb932e-10d6-4078-92aa-48ab1fb8cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It's failed due to python version\n",
    "#from pymorphy2 import MorphAnalyzer\n",
    "#morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = txt.lower()\n",
    "    txt = \"\".join(char for char in txt if char not in punctuation_set)\n",
    "    txt = \"\".join(char for char in txt if char in en_alphabet_set)\n",
    "    #txt = [morpher.parse(w)[0].normal_form for w in txt.split() if w not in stop_word_set]\n",
    "    txt =  [w for w in txt.split() if w not in stop_word_set]\n",
    "    txt = \" \".join(txt)\n",
    "    return txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f84d9ff1-fd47-4d1a-9ada-35118357fc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31962/31962 [00:00<00:00, 134004.88it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "tqdm.pandas()\n",
    "\n",
    "df_st1 = df.copy()\n",
    "df_st1['tweet'] = df_st1['tweet'].progress_apply(preprocess_text)\n",
    "df_st1_twt = df_st1['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60b24262-ba8c-43e5-9c43-405dbea41814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alex/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['user',\n",
       " 'father',\n",
       " 'dysfunctional',\n",
       " 'selfish',\n",
       " 'drags',\n",
       " 'kids',\n",
       " 'dysfunction',\n",
       " 'run',\n",
       " 'user',\n",
       " 'user']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "all_tweet_words = \" \".join(df_st1_twt)\n",
    "tokens = word_tokenize(all_tweet_words)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac3f92ea-ab34-438a-8894-a82ca77f85cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_filtered = [word for word in tokens if word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cffbf7f-5dce-4e8c-a73c-4fb2ff5a382a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "dist = FreqDist(tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]  # вычитание 1 для padding\n",
    "len(tokens_filtered_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "730b9930-aeae-45cb-b7b0-b068e0010eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': 1,\n",
       " 'love': 2,\n",
       " 'day': 3,\n",
       " 'happy': 4,\n",
       " 'amp': 5,\n",
       " 'just': 6,\n",
       " 'will': 7,\n",
       " 'im': 8,\n",
       " 'u': 9,\n",
       " 'life': 10,\n",
       " 'time': 11,\n",
       " 'like': 12,\n",
       " 'today': 13,\n",
       " 'now': 14,\n",
       " 'new': 15,\n",
       " 'positive': 16,\n",
       " 'thankful': 17,\n",
       " 'get': 18,\n",
       " 'people': 19,\n",
       " 'bihday': 20,\n",
       " 'good': 21,\n",
       " 'cant': 22,\n",
       " 'one': 23,\n",
       " 'see': 24,\n",
       " 'can': 25,\n",
       " 'dont': 26,\n",
       " 'fathers': 27,\n",
       " 'smile': 28,\n",
       " 'go': 29,\n",
       " 'want': 30,\n",
       " 'take': 31,\n",
       " 'work': 32,\n",
       " 'healthy': 33,\n",
       " 'fun': 34,\n",
       " 'weekend': 35,\n",
       " 'got': 36,\n",
       " 'summer': 37,\n",
       " 'make': 38,\n",
       " 'days': 39,\n",
       " 'family': 40,\n",
       " 'friday': 41,\n",
       " 'us': 42,\n",
       " 'best': 43,\n",
       " 'need': 44,\n",
       " 'way': 45,\n",
       " 'beautiful': 46,\n",
       " 'great': 47,\n",
       " 'bull': 48,\n",
       " 'friends': 49,\n",
       " 'going': 50,\n",
       " 'first': 51,\n",
       " 'really': 52,\n",
       " 'wait': 53,\n",
       " 'morning': 54,\n",
       " 'music': 55,\n",
       " 'ur': 56,\n",
       " 'back': 57,\n",
       " 'world': 58,\n",
       " 'know': 59,\n",
       " 'fathersday': 60,\n",
       " 'tomorrow': 61,\n",
       " 'cute': 62,\n",
       " 'week': 63,\n",
       " 'sad': 64,\n",
       " 'never': 65,\n",
       " 'orlando': 66,\n",
       " 'think': 67,\n",
       " 'happiness': 68,\n",
       " 'feel': 69,\n",
       " 'blog': 70,\n",
       " 'sunday': 71,\n",
       " 'trump': 72,\n",
       " 'well': 73,\n",
       " 'home': 74,\n",
       " 'model': 75,\n",
       " 'much': 76,\n",
       " 'right': 77,\n",
       " 'night': 78,\n",
       " 'affirmation': 79,\n",
       " 'girl': 80,\n",
       " 'always': 81,\n",
       " 'next': 82,\n",
       " 'last': 83,\n",
       " 'even': 84,\n",
       " 'youre': 85,\n",
       " 'finally': 86,\n",
       " 'live': 87,\n",
       " 'come': 88,\n",
       " 'follow': 89,\n",
       " 'still': 90,\n",
       " 'amazing': 91,\n",
       " 'gold': 92,\n",
       " 'year': 93,\n",
       " 'iam': 94,\n",
       " 'silver': 95,\n",
       " 'thank': 96,\n",
       " 'things': 97,\n",
       " 'thanks': 98,\n",
       " 'look': 99,\n",
       " 'find': 100,\n",
       " 'ready': 101,\n",
       " 'selfie': 102,\n",
       " 'altwaystoheal': 103,\n",
       " 'makes': 104,\n",
       " 'via': 105,\n",
       " 'dad': 106,\n",
       " 'tonight': 107,\n",
       " 'little': 108,\n",
       " 'many': 109,\n",
       " 'free': 110,\n",
       " 'na': 111,\n",
       " 'pay': 112,\n",
       " 'looking': 113,\n",
       " 'man': 114,\n",
       " 'everyone': 115,\n",
       " 'forex': 116,\n",
       " 'show': 117,\n",
       " 'another': 118,\n",
       " 'old': 119,\n",
       " 'ever': 120,\n",
       " 'getting': 121,\n",
       " 'feeling': 122,\n",
       " 'peace': 123,\n",
       " 'hope': 124,\n",
       " 'game': 125,\n",
       " 'girls': 126,\n",
       " 'blessed': 127,\n",
       " 'black': 128,\n",
       " 'watch': 129,\n",
       " 'climb': 130,\n",
       " 'city': 131,\n",
       " 'food': 132,\n",
       " 'stop': 133,\n",
       " 'bear': 134,\n",
       " 'say': 135,\n",
       " 'enjoy': 136,\n",
       " 'sta': 137,\n",
       " 'hate': 138,\n",
       " 'god': 139,\n",
       " 'news': 140,\n",
       " 'sun': 141,\n",
       " 'every': 142,\n",
       " 'made': 143,\n",
       " 'whatever': 144,\n",
       " 'help': 145,\n",
       " 'd': 146,\n",
       " 'saturday': 147,\n",
       " 'th': 148,\n",
       " 'ive': 149,\n",
       " 'might': 150,\n",
       " 'friend': 151,\n",
       " 'years': 152,\n",
       " 'thats': 153,\n",
       " 'excited': 154,\n",
       " 'dog': 155,\n",
       " 'polar': 156,\n",
       " 'baby': 157,\n",
       " 'funny': 158,\n",
       " 'white': 159,\n",
       " 'may': 160,\n",
       " 'instagood': 161,\n",
       " 'keep': 162,\n",
       " 'someone': 163,\n",
       " 'lol': 164,\n",
       " 'coming': 165,\n",
       " 'kids': 166,\n",
       " 'nothing': 167,\n",
       " 'angry': 168,\n",
       " 'beach': 169,\n",
       " 'father': 170,\n",
       " 'big': 171,\n",
       " 'healing': 172,\n",
       " 'school': 173,\n",
       " 'nice': 174,\n",
       " 'guys': 175,\n",
       " 'believe': 176,\n",
       " 'around': 177,\n",
       " 'better': 178,\n",
       " 'awesome': 179,\n",
       " 'let': 180,\n",
       " 'video': 181,\n",
       " 'cool': 182,\n",
       " 's': 183,\n",
       " 'found': 184,\n",
       " 'please': 185,\n",
       " 'wedding': 186,\n",
       " 'long': 187,\n",
       " 'yes': 188,\n",
       " 'hea': 189,\n",
       " 'n': 190,\n",
       " 'grateful': 191,\n",
       " 'done': 192,\n",
       " 'quote': 193,\n",
       " 'direct': 194,\n",
       " 'proud': 195,\n",
       " 'soon': 196,\n",
       " 'change': 197,\n",
       " 'true': 198,\n",
       " 'holiday': 199,\n",
       " 'motivation': 200,\n",
       " 'lost': 201,\n",
       " 'dominate': 202,\n",
       " 'thing': 203,\n",
       " 'women': 204,\n",
       " 'two': 205,\n",
       " 'monday': 206,\n",
       " 'something': 207,\n",
       " 'weeks': 208,\n",
       " 'waiting': 209,\n",
       " 'bad': 210,\n",
       " 'america': 211,\n",
       " 'play': 212,\n",
       " 'didnt': 213,\n",
       " 'away': 214,\n",
       " 'june': 215,\n",
       " 'miss': 216,\n",
       " 'real': 217,\n",
       " 'team': 218,\n",
       " 'watching': 219,\n",
       " 'without': 220,\n",
       " 'attack': 221,\n",
       " 'travel': 222,\n",
       " 'euro': 223,\n",
       " 'forward': 224,\n",
       " 'place': 225,\n",
       " 'end': 226,\n",
       " 'hot': 227,\n",
       " 'playing': 228,\n",
       " 'wish': 229,\n",
       " 'rip': 230,\n",
       " 'give': 231,\n",
       " 'face': 232,\n",
       " 'yeah': 233,\n",
       " 'racing': 234,\n",
       " 'strong': 235,\n",
       " 'oh': 236,\n",
       " 'photooftheday': 237,\n",
       " 'hair': 238,\n",
       " 'followme': 239,\n",
       " 'bing': 240,\n",
       " 'libtard': 241,\n",
       " 'fashion': 242,\n",
       " 'check': 243,\n",
       " 'left': 244,\n",
       " 'person': 245,\n",
       " 'bong': 246,\n",
       " 'lovely': 247,\n",
       " 'doesnt': 248,\n",
       " 'mindset': 249,\n",
       " 'boy': 250,\n",
       " 'sex': 251,\n",
       " 'lt': 252,\n",
       " 'buffalo': 253,\n",
       " 'hard': 254,\n",
       " 'ill': 255,\n",
       " 'twitter': 256,\n",
       " 'gon': 257,\n",
       " 'season': 258,\n",
       " 'wow': 259,\n",
       " 'living': 260,\n",
       " 'joy': 261,\n",
       " 'everything': 262,\n",
       " 'racist': 263,\n",
       " 'dads': 264,\n",
       " 'sexy': 265,\n",
       " 'book': 266,\n",
       " 'r': 267,\n",
       " 'making': 268,\n",
       " 'yet': 269,\n",
       " 'lot': 270,\n",
       " 'leave': 271,\n",
       " 'health': 272,\n",
       " 'money': 273,\n",
       " 'tbt': 274,\n",
       " 'london': 275,\n",
       " 'wont': 276,\n",
       " 'young': 277,\n",
       " 'tweets': 278,\n",
       " 'house': 279,\n",
       " 'sleep': 280,\n",
       " 'moment': 281,\n",
       " 'looks': 282,\n",
       " 'pa': 283,\n",
       " 'job': 284,\n",
       " 'gay': 285,\n",
       " 'x': 286,\n",
       " 'st': 287,\n",
       " 'shooting': 288,\n",
       " 'success': 289,\n",
       " 'win': 290,\n",
       " 'w': 291,\n",
       " 'pretty': 292,\n",
       " 'said': 293,\n",
       " 'politics': 294,\n",
       " 'stay': 295,\n",
       " 'gorilla': 296,\n",
       " 'try': 297,\n",
       " 'read': 298,\n",
       " 'full': 299,\n",
       " 'poetry': 300,\n",
       " 'already': 301,\n",
       " 'says': 302,\n",
       " 'listen': 303,\n",
       " 'e': 304,\n",
       " 'depression': 305,\n",
       " 'beauty': 306,\n",
       " 'thought': 307,\n",
       " 'body': 308,\n",
       " 'loved': 309,\n",
       " 'tear': 310,\n",
       " 'mom': 311,\n",
       " 'lets': 312,\n",
       " 'obama': 313,\n",
       " 'inspiration': 314,\n",
       " 'omg': 315,\n",
       " 'working': 316,\n",
       " 'conference': 317,\n",
       " 'mind': 318,\n",
       " 'couple': 319,\n",
       " 'environment': 320,\n",
       " 'whats': 321,\n",
       " 'dance': 322,\n",
       " 'head': 323,\n",
       " 'b': 324,\n",
       " 'hours': 325,\n",
       " 'porn': 326,\n",
       " 'perfect': 327,\n",
       " 'truth': 328,\n",
       " 'hes': 329,\n",
       " 'woman': 330,\n",
       " 'guy': 331,\n",
       " 'quotes': 332,\n",
       " 'thursday': 333,\n",
       " 'use': 334,\n",
       " 'song': 335,\n",
       " 'isnt': 336,\n",
       " 'since': 337,\n",
       " 'shit': 338,\n",
       " 'fitness': 339,\n",
       " 'retweet': 340,\n",
       " 'children': 341,\n",
       " 'fuck': 342,\n",
       " 'photo': 343,\n",
       " 'month': 344,\n",
       " 'enough': 345,\n",
       " 'must': 346,\n",
       " 'call': 347,\n",
       " 'cold': 348,\n",
       " 'simulator': 349,\n",
       " 'adapt': 350,\n",
       " 'also': 351,\n",
       " 'buy': 352,\n",
       " 'simulation': 353,\n",
       " 'open': 354,\n",
       " 'super': 355,\n",
       " 'times': 356,\n",
       " 'country': 357,\n",
       " 'wonderful': 358,\n",
       " 'men': 359,\n",
       " 'hear': 360,\n",
       " 'mood': 361,\n",
       " 'run': 362,\n",
       " 'pm': 363,\n",
       " 'words': 364,\n",
       " 'rest': 365,\n",
       " 'nude': 366,\n",
       " 'media': 367,\n",
       " 'hour': 368,\n",
       " 'shop': 369,\n",
       " 'cat': 370,\n",
       " 'others': 371,\n",
       " 'business': 372,\n",
       " 'dream': 373,\n",
       " 'dead': 374,\n",
       " 'hey': 375,\n",
       " 'post': 376,\n",
       " 'share': 377,\n",
       " 'meet': 378,\n",
       " 'yay': 379,\n",
       " 'crazy': 380,\n",
       " 'alone': 381,\n",
       " 'seeing': 382,\n",
       " 'movie': 383,\n",
       " 'wednesday': 384,\n",
       " 'coffee': 385,\n",
       " 'put': 386,\n",
       " 'till': 387,\n",
       " 'comes': 388,\n",
       " 'liberal': 389,\n",
       " 'trying': 390,\n",
       " 'tell': 391,\n",
       " 'smiles': 392,\n",
       " 'race': 393,\n",
       " 'ppl': 394,\n",
       " 'relax': 395,\n",
       " 'together': 396,\n",
       " 'flowers': 397,\n",
       " 'almost': 398,\n",
       " 'usa': 399,\n",
       " 'months': 400,\n",
       " 'story': 401,\n",
       " 'came': 402,\n",
       " 'trip': 403,\n",
       " 'anything': 404,\n",
       " 'lifestyle': 405,\n",
       " 'kind': 406,\n",
       " 'care': 407,\n",
       " 'tweet': 408,\n",
       " 'fans': 409,\n",
       " 'gone': 410,\n",
       " 'thoughts': 411,\n",
       " 'remember': 412,\n",
       " 'sunshine': 413,\n",
       " 'celebrate': 414,\n",
       " 'needs': 415,\n",
       " 'tired': 416,\n",
       " 'gift': 417,\n",
       " 'single': 418,\n",
       " 'toptags': 419,\n",
       " 'far': 420,\n",
       " 'tickets': 421,\n",
       " 'allahsoil': 422,\n",
       " 'sweet': 423,\n",
       " 'lives': 424,\n",
       " 'tgif': 425,\n",
       " 'gym': 426,\n",
       " 'empty': 427,\n",
       " 'join': 428,\n",
       " 'bed': 429,\n",
       " 'delete': 430,\n",
       " 'wrong': 431,\n",
       " 'prayfororlando': 432,\n",
       " 'loving': 433,\n",
       " 'fact': 434,\n",
       " 'goes': 435,\n",
       " 'sorry': 436,\n",
       " 'forever': 437,\n",
       " 'places': 438,\n",
       " 'actually': 439,\n",
       " 'social': 440,\n",
       " 'blue': 441,\n",
       " 'sure': 442,\n",
       " 'sick': 443,\n",
       " 'anyone': 444,\n",
       " 'aww': 445,\n",
       " 'saw': 446,\n",
       " 'vacation': 447,\n",
       " 'useful': 448,\n",
       " 'son': 449,\n",
       " 'else': 450,\n",
       " 'tuesday': 451,\n",
       " 'photography': 452,\n",
       " 'went': 453,\n",
       " 'power': 454,\n",
       " 'k': 455,\n",
       " 'child': 456,\n",
       " 'lgbt': 457,\n",
       " 'car': 458,\n",
       " 'talk': 459,\n",
       " 'high': 460,\n",
       " 'goodmorning': 461,\n",
       " 'side': 462,\n",
       " 'hardcore': 463,\n",
       " 'anymore': 464,\n",
       " 'running': 465,\n",
       " 'deletetweets': 466,\n",
       " 'hello': 467,\n",
       " 'lunch': 468,\n",
       " 'yesterday': 469,\n",
       " 'daily': 470,\n",
       " 'hu': 471,\n",
       " 'gets': 472,\n",
       " 'impoant': 473,\n",
       " 'happened': 474,\n",
       " 'victims': 475,\n",
       " 'followers': 476,\n",
       " 'theres': 477,\n",
       " 'suppo': 478,\n",
       " 'y': 479,\n",
       " 'visit': 480,\n",
       " 'special': 481,\n",
       " 'daddy': 482,\n",
       " 'h': 483,\n",
       " 'gun': 484,\n",
       " 'complete': 485,\n",
       " 'laugh': 486,\n",
       " 'nature': 487,\n",
       " 'evening': 488,\n",
       " 'latest': 489,\n",
       " 'anxiety': 490,\n",
       " 'uk': 491,\n",
       " 'matter': 492,\n",
       " 'early': 493,\n",
       " 'gt': 494,\n",
       " 'nervous': 495,\n",
       " 'smiling': 496,\n",
       " 'less': 497,\n",
       " 'todays': 498,\n",
       " 'sometimes': 499,\n",
       " 'football': 500,\n",
       " 'birds': 501,\n",
       " 'yall': 502,\n",
       " 'boys': 503,\n",
       " 'reading': 504,\n",
       " 'shopping': 505,\n",
       " 'favorite': 506,\n",
       " 'order': 507,\n",
       " 'picoftheday': 508,\n",
       " 'instagram': 509,\n",
       " 'late': 510,\n",
       " 'ago': 511,\n",
       " 'word': 512,\n",
       " 'style': 513,\n",
       " 'history': 514,\n",
       " 'depressed': 515,\n",
       " 'future': 516,\n",
       " 'racism': 517,\n",
       " 'sjw': 518,\n",
       " 'miami': 519,\n",
       " 'red': 520,\n",
       " 'cause': 521,\n",
       " 'arrived': 522,\n",
       " 'ok': 523,\n",
       " 'sunny': 524,\n",
       " 'pic': 525,\n",
       " 'vs': 526,\n",
       " 'guess': 527,\n",
       " 'green': 528,\n",
       " 'cry': 529,\n",
       " 'seen': 530,\n",
       " 'leads': 531,\n",
       " 'point': 532,\n",
       " 'prayers': 533,\n",
       " 'safe': 534,\n",
       " 'able': 535,\n",
       " 'fucking': 536,\n",
       " 'damn': 537,\n",
       " 'park': 538,\n",
       " 'stas': 539,\n",
       " 'everyday': 540,\n",
       " 'mean': 541,\n",
       " 'daughter': 542,\n",
       " 'vine': 543,\n",
       " 'wishing': 544,\n",
       " 'nd': 545,\n",
       " 'death': 546,\n",
       " 'later': 547,\n",
       " 'booked': 548,\n",
       " 'tv': 549,\n",
       " 'walk': 550,\n",
       " 'set': 551,\n",
       " 'education': 552,\n",
       " 'whole': 553,\n",
       " 'learn': 554,\n",
       " 'act': 555,\n",
       " 'families': 556,\n",
       " 'date': 557,\n",
       " 'lucky': 558,\n",
       " 'reason': 559,\n",
       " 'app': 560,\n",
       " 'event': 561,\n",
       " 'become': 562,\n",
       " 'cantwait': 563,\n",
       " 'florida': 564,\n",
       " 'understand': 565,\n",
       " 'ass': 566,\n",
       " 'saying': 567,\n",
       " 'target': 568,\n",
       " 'homes': 569,\n",
       " 'though': 570,\n",
       " 'ff': 571,\n",
       " 'brexit': 572,\n",
       " 'killed': 573,\n",
       " 'theyre': 574,\n",
       " 'finished': 575,\n",
       " 'rain': 576,\n",
       " 'staing': 577,\n",
       " 'yo': 578,\n",
       " 'pray': 579,\n",
       " 'close': 580,\n",
       " 'organizations': 581,\n",
       " 'snapchat': 582,\n",
       " 'update': 583,\n",
       " 'seems': 584,\n",
       " 'xxx': 585,\n",
       " 'ht': 586,\n",
       " 'youtube': 587,\n",
       " 'picture': 588,\n",
       " 'bday': 589,\n",
       " 'flag': 590,\n",
       " 'fan': 591,\n",
       " 'talking': 592,\n",
       " 'control': 593,\n",
       " 'disney': 594,\n",
       " 'bless': 595,\n",
       " 'nyc': 596,\n",
       " 'guns': 597,\n",
       " 'despite': 598,\n",
       " 'conce': 599,\n",
       " 'thankyou': 600,\n",
       " 'cultureofdevelopment': 601,\n",
       " 'memories': 602,\n",
       " 'broken': 603,\n",
       " 'reached': 604,\n",
       " 'anniversary': 605,\n",
       " 'afternoon': 606,\n",
       " 'choose': 607,\n",
       " 'used': 608,\n",
       " 'p': 609,\n",
       " 'bit': 610,\n",
       " 'parents': 611,\n",
       " 'garden': 612,\n",
       " 'break': 613,\n",
       " 'comments': 614,\n",
       " 'photos': 615,\n",
       " 'top': 616,\n",
       " 'goals': 617,\n",
       " 'sea': 618,\n",
       " 'welcome': 619,\n",
       " 'bring': 620,\n",
       " 'club': 621,\n",
       " 'mad': 622,\n",
       " 'kill': 623,\n",
       " 'episode': 624,\n",
       " 'meeting': 625,\n",
       " 'dinner': 626,\n",
       " 'save': 627,\n",
       " 'smh': 628,\n",
       " 'f': 629,\n",
       " 'wan': 630,\n",
       " 'happen': 631,\n",
       " 'fresh': 632,\n",
       " 't': 633,\n",
       " 'freedom': 634,\n",
       " 'animals': 635,\n",
       " 'heard': 636,\n",
       " 'pathetic': 637,\n",
       " 'police': 638,\n",
       " 'easy': 639,\n",
       " 'dear': 640,\n",
       " 'boyfriend': 641,\n",
       " 'wanted': 642,\n",
       " 'dreams': 643,\n",
       " 'cake': 644,\n",
       " 'forget': 645,\n",
       " 'july': 646,\n",
       " 'vote': 647,\n",
       " 'name': 648,\n",
       " 'half': 649,\n",
       " 'training': 650,\n",
       " 'lover': 651,\n",
       " 'taking': 652,\n",
       " 'havent': 653,\n",
       " 'friendship': 654,\n",
       " 'hill': 655,\n",
       " 'survive': 656,\n",
       " 'eat': 657,\n",
       " 'rock': 658,\n",
       " 'design': 659,\n",
       " 'dogs': 660,\n",
       " 'reach': 661,\n",
       " 'vicinity': 662,\n",
       " 'makeup': 663,\n",
       " 'feels': 664,\n",
       " 'eyes': 665,\n",
       " 'orlandoshooting': 666,\n",
       " 'shes': 667,\n",
       " 'kid': 668,\n",
       " 'state': 669,\n",
       " 'president': 670,\n",
       " 'affirmations': 671,\n",
       " 'breakfast': 672,\n",
       " 'film': 673,\n",
       " 'htt': 674,\n",
       " 'yoga': 675,\n",
       " 'hell': 676,\n",
       " 'least': 677,\n",
       " 'mountains': 678,\n",
       " 'ramadan': 679,\n",
       " 'hit': 680,\n",
       " 'feelings': 681,\n",
       " 'stuff': 682,\n",
       " 'happening': 683,\n",
       " 'heal': 684,\n",
       " 'truly': 685,\n",
       " 'moments': 686,\n",
       " 'maybe': 687,\n",
       " 'nasty': 688,\n",
       " 'brother': 689,\n",
       " 'm': 690,\n",
       " 'missing': 691,\n",
       " 'group': 692,\n",
       " 'oitnb': 693,\n",
       " 'view': 694,\n",
       " 'send': 695,\n",
       " 'tragedy': 696,\n",
       " 'soul': 697,\n",
       " 'wants': 698,\n",
       " 'final': 699,\n",
       " 'called': 700,\n",
       " 'service': 701,\n",
       " 'youve': 702,\n",
       " 'gbp': 703,\n",
       " 'la': 704,\n",
       " 'worst': 705,\n",
       " 'leadership': 706,\n",
       " 'mother': 707,\n",
       " 'thinking': 708,\n",
       " 'color': 709,\n",
       " 'water': 710,\n",
       " 'pain': 711,\n",
       " 'lighttherapy': 712,\n",
       " 'couldnt': 713,\n",
       " 'officially': 714,\n",
       " 'crying': 715,\n",
       " 'different': 716,\n",
       " 'lawofattraction': 717,\n",
       " 'bought': 718,\n",
       " 'chill': 719,\n",
       " 'americans': 720,\n",
       " 'minutes': 721,\n",
       " 'mine': 722,\n",
       " 'england': 723,\n",
       " 'ta': 724,\n",
       " 'dj': 725,\n",
       " 'list': 726,\n",
       " 'wishes': 727,\n",
       " 'means': 728,\n",
       " 'voice': 729,\n",
       " 'wife': 730,\n",
       " 'course': 731,\n",
       " 'arent': 732,\n",
       " 'community': 733,\n",
       " 'slut': 734,\n",
       " 'enjoying': 735,\n",
       " 'light': 736,\n",
       " 'heres': 737,\n",
       " 'ahead': 738,\n",
       " 'simple': 739,\n",
       " 'bc': 740,\n",
       " 'phone': 741,\n",
       " 'wake': 742,\n",
       " 'won': 743,\n",
       " 'hillary': 744,\n",
       " 'human': 745,\n",
       " 'violence': 746,\n",
       " 'nbafinals': 747,\n",
       " 'sister': 748,\n",
       " 'ones': 749,\n",
       " 'wet': 750,\n",
       " 'fridayfeeling': 751,\n",
       " 'india': 752,\n",
       " 'respect': 753,\n",
       " 'task': 754,\n",
       " 'gop': 755,\n",
       " 'suppoers': 756,\n",
       " 'glad': 757,\n",
       " 'along': 758,\n",
       " 'festival': 759,\n",
       " 'wtf': 760,\n",
       " 'udtapunjab': 761,\n",
       " 'ride': 762,\n",
       " 'present': 763,\n",
       " 'past': 764,\n",
       " 'shows': 765,\n",
       " 'finding': 766,\n",
       " 'naughty': 767,\n",
       " 'ask': 768,\n",
       " 'reality': 769,\n",
       " 'using': 770,\n",
       " 'mass': 771,\n",
       " 'tears': 772,\n",
       " 'id': 773,\n",
       " 'lose': 774,\n",
       " 'horny': 775,\n",
       " 'shy': 776,\n",
       " 'sunset': 777,\n",
       " 'american': 778,\n",
       " 'fantastic': 779,\n",
       " 'room': 780,\n",
       " 'tragic': 781,\n",
       " 'chase': 782,\n",
       " 'blonde': 783,\n",
       " 'agree': 784,\n",
       " 'whos': 785,\n",
       " 'line': 786,\n",
       " 'exciting': 787,\n",
       " 'lonely': 788,\n",
       " 'takes': 789,\n",
       " 'instead': 790,\n",
       " 'staed': 791,\n",
       " 'rather': 792,\n",
       " 'die': 793,\n",
       " 'source': 794,\n",
       " 'needed': 795,\n",
       " 'small': 796,\n",
       " 'disappointed': 797,\n",
       " 'giving': 798,\n",
       " 'blur': 799,\n",
       " 'workout': 800,\n",
       " 'wine': 801,\n",
       " 'drink': 802,\n",
       " 'videos': 803,\n",
       " 'shot': 804,\n",
       " 'aint': 805,\n",
       " 'ways': 806,\n",
       " 'beer': 807,\n",
       " 'leaving': 808,\n",
       " 'kinky': 809,\n",
       " 'instalike': 810,\n",
       " 'problem': 811,\n",
       " 'move': 812,\n",
       " 'stomping': 813,\n",
       " 'behind': 814,\n",
       " 'husband': 815,\n",
       " 'moving': 816,\n",
       " 'congrats': 817,\n",
       " 'happier': 818,\n",
       " 'dark': 819,\n",
       " 'rooster': 820,\n",
       " 'vast': 821,\n",
       " 'fear': 822,\n",
       " 'lots': 823,\n",
       " 'stupid': 824,\n",
       " 'gave': 825,\n",
       " 'sho': 826,\n",
       " 'actor': 827,\n",
       " 'teen': 828,\n",
       " 'customer': 829,\n",
       " 'pussy': 830,\n",
       " 'expanse': 831,\n",
       " 'haha': 832,\n",
       " 'three': 833,\n",
       " 'cats': 834,\n",
       " 'muslim': 835,\n",
       " 'o': 836,\n",
       " 'l': 837,\n",
       " 'tech': 838,\n",
       " 'loves': 839,\n",
       " 'flight': 840,\n",
       " 'poor': 841,\n",
       " 'hatred': 842,\n",
       " 'france': 843,\n",
       " 'gorgeous': 844,\n",
       " 'sky': 845,\n",
       " 'political': 846,\n",
       " 'islam': 847,\n",
       " 'national': 848,\n",
       " 'star': 849,\n",
       " 'local': 850,\n",
       " 'wonder': 851,\n",
       " 'weather': 852,\n",
       " 'likelike': 853,\n",
       " 'students': 854,\n",
       " 'apple': 855,\n",
       " 'countdown': 856,\n",
       " 'united': 857,\n",
       " 'puppy': 858,\n",
       " 'class': 859,\n",
       " 'instamood': 860,\n",
       " 'luck': 861,\n",
       " 'college': 862,\n",
       " 'walking': 863,\n",
       " 'facebook': 864,\n",
       " 'account': 865,\n",
       " 'york': 866,\n",
       " 'heabroken': 867,\n",
       " 'due': 868,\n",
       " 'writing': 869,\n",
       " 'self': 870,\n",
       " 'pizza': 871,\n",
       " 'busy': 872,\n",
       " 'woh': 873,\n",
       " 'games': 874,\n",
       " 'babies': 875,\n",
       " 'online': 876,\n",
       " 'series': 877,\n",
       " 'spos': 878,\n",
       " 'speak': 879,\n",
       " 'queen': 880,\n",
       " 'content': 881,\n",
       " 'seriously': 882,\n",
       " 'university': 883,\n",
       " 'hands': 884,\n",
       " 'pride': 885,\n",
       " 'hi': 886,\n",
       " 'energy': 887,\n",
       " 'street': 888,\n",
       " 'loss': 889,\n",
       " 'official': 890,\n",
       " 'jobs': 891,\n",
       " 'took': 892,\n",
       " 'dancing': 893,\n",
       " 'pink': 894,\n",
       " 'told': 895,\n",
       " 'died': 896,\n",
       " 'huge': 897,\n",
       " 'ripchristina': 898,\n",
       " 'internet': 899,\n",
       " 'missed': 900,\n",
       " 'scared': 901,\n",
       " 'vegan': 902,\n",
       " 'drinks': 903,\n",
       " 'yummy': 904,\n",
       " 'sale': 905,\n",
       " 'shame': 906,\n",
       " 'fall': 907,\n",
       " 'c': 908,\n",
       " 'given': 909,\n",
       " 'met': 910,\n",
       " 'adventure': 911,\n",
       " 'stand': 912,\n",
       " 'lady': 913,\n",
       " 'bitch': 914,\n",
       " 'experience': 915,\n",
       " 'joke': 916,\n",
       " 'literally': 917,\n",
       " 'fit': 918,\n",
       " 'grow': 919,\n",
       " 'naked': 920,\n",
       " 'spend': 921,\n",
       " 'launch': 922,\n",
       " 'absolutely': 923,\n",
       " 'germany': 924,\n",
       " 'congratulations': 925,\n",
       " 'wasnt': 926,\n",
       " 'turn': 927,\n",
       " 'weve': 928,\n",
       " 'fly': 929,\n",
       " 'inside': 930,\n",
       " 'office': 931,\n",
       " 'punjab': 932,\n",
       " 'camp': 933,\n",
       " 'hungry': 934,\n",
       " 'donald': 935,\n",
       " 'opening': 936,\n",
       " 'road': 937,\n",
       " 'page': 938,\n",
       " 'war': 939,\n",
       " 'previous': 940,\n",
       " 'test': 941,\n",
       " 'pool': 942,\n",
       " 'probably': 943,\n",
       " 'instadaily': 944,\n",
       " 'listening': 945,\n",
       " 'v': 946,\n",
       " 'newyork': 947,\n",
       " 'vibes': 948,\n",
       " 'staff': 949,\n",
       " 'xx': 950,\n",
       " 'treat': 951,\n",
       " 'sense': 952,\n",
       " 'tips': 953,\n",
       " 'inshot': 954,\n",
       " 'celebration': 955,\n",
       " 'okay': 956,\n",
       " 'dress': 957,\n",
       " 'trending': 958,\n",
       " 'sign': 959,\n",
       " 'nba': 960,\n",
       " 'mr': 961,\n",
       " 'vegas': 962,\n",
       " 'female': 963,\n",
       " 'rd': 964,\n",
       " 'trust': 965,\n",
       " 'inspirational': 966,\n",
       " 'idea': 967,\n",
       " 'folks': 968,\n",
       " 'stories': 969,\n",
       " 'melancholy': 970,\n",
       " 'church': 971,\n",
       " 'realize': 972,\n",
       " 'step': 973,\n",
       " 'flower': 974,\n",
       " 'chance': 975,\n",
       " 'fight': 976,\n",
       " 'bike': 977,\n",
       " 'album': 978,\n",
       " 'dory': 979,\n",
       " 'emotions': 980,\n",
       " 'snapshot': 981,\n",
       " 'faith': 982,\n",
       " 'oil': 983,\n",
       " 'alive': 984,\n",
       " 'youll': 985,\n",
       " 'ice': 986,\n",
       " 'married': 987,\n",
       " 'campaign': 988,\n",
       " 'marriage': 989,\n",
       " 'choice': 990,\n",
       " 'king': 991,\n",
       " 'lovelife': 992,\n",
       " 'goodvibes': 993,\n",
       " 'either': 994,\n",
       " 'confused': 995,\n",
       " 'cavs': 996,\n",
       " 'calling': 997,\n",
       " 'wouldnt': 998,\n",
       " 'japan': 999,\n",
       " 'nobody': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b842c48-9824-4798-ab83-373717b303de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    29720\n",
       "1     2242\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_st1['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f56bff6-ce5b-4725-98e0-39642ef57dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance:  (array([0, 1]), array([29720,  2242]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens_filtered = tokens#[word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "\n",
    "    padding = [0] * (maxlen-len(result))\n",
    "    return result[-maxlen:] + padding\n",
    "\n",
    "#Y=2*(np.array(df_st1[\"label\"])-0.5)\n",
    "Y=np.array(df_st1[\"label\"])\n",
    "X=np.array([text_to_sequence(tweet, max_len) for tweet in df_st1[\"tweet\"]])\n",
    "\n",
    "print (\"Class balance: \",np.unique(Y, return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c23dc58b-7591-4598-8f9d-d1b010f00329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance:  (array([0, 1]), array([20772,  1601]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y, train_size=0.7, shuffle=True)\n",
    "\n",
    "#x_train,y_train\n",
    "print (\"Class balance: \",np.unique(y_train, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5a9bc339-8e2a-4588-886f-65a43e45bfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TomekLinks:\t (array([0, 1]), array([20219,  1601]))\n",
      "RepeatedEditedNearestNeighbours:\t (array([0, 1]), array([15284,  1601]))\n",
      "EditedNearestNeighbours:\t (array([0, 1]), array([15284,  1601]))\n",
      "AllKNN:\t (array([0, 1]), array([15284,  1601]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import RepeatedEditedNearestNeighbours\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.under_sampling import AllKNN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#\n",
    "# Sampling:------------------------------------------------------------\n",
    "sampler = TomekLinks();\n",
    "x_train,y_train = sampler.fit_resample(x_train,y_train);\n",
    "print (\"TomekLinks:\\t\",np.unique(y_train, return_counts=True))\n",
    "\n",
    "renn = RepeatedEditedNearestNeighbours()\n",
    "x_train, y_train = renn.fit_resample(x_train, y_train)\n",
    "print (\"RepeatedEditedNearestNeighbours:\\t\",np.unique(y_train, return_counts=True))\n",
    "\n",
    "renn = EditedNearestNeighbours()\n",
    "x_train, y_train = renn.fit_resample(x_train, y_train)\n",
    "print (\"EditedNearestNeighbours:\\t\",np.unique(y_train, return_counts=True))\n",
    "\n",
    "allknn = AllKNN()\n",
    "x_train, y_train = allknn.fit_resample(x_train, y_train)\n",
    "print (\"AllKNN:\\t\",np.unique(y_train, return_counts=True))\n",
    "\n",
    "# smt = SMOTE()\n",
    "# x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "# print (\"SMOTE:\\t\",np.unique(y_train, return_counts=True))\n",
    "\n",
    "# rus = RandomUnderSampler(random_state=0)\n",
    "# x_train, y_train = rus.fit_resample(x_train, y_train)\n",
    "# print (\"RandomUnderSampler:\\t\",np.unique(y_train, return_counts=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "09039fc7-1bd0-4dac-a9dd-76ce48a94792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class DataWrapper(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.data = torch.from_numpy(data).long()\n",
    "        self.target = torch.from_numpy(target).long()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "                    \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "train_dataset = DataWrapper(data=x_train, target=y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = DataWrapper(data=x_test, target=y_test)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e8d40389-0d83-44fc-9da9-d416c2103493",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, vocab_size=2000, embedding_dim=128, out_channel=64, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.conv_1 = nn.Conv1d (embedding_dim, out_channel, kernel_size=3,padding=1)\n",
    "        self.conv_2 = nn.Conv1d (out_channel, out_channel, kernel_size=3,padding=1)\n",
    "        self.conv_3 = nn.Conv1d (out_channel, out_channel, kernel_size=3,padding=1)\n",
    "        self.conv_4 = nn.Conv1d (out_channel, out_channel, kernel_size=3,padding=1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear_1 = nn.Linear(out_channel, out_channel // 2)\n",
    "        self.linear_2 = nn.Linear(out_channel // 2, num_classes)\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        output = self.embedding(x)\n",
    "        #                       B, L, E\n",
    "        #                       B  E  L         \n",
    "        output = output.permute(0, 2, 1)\n",
    "        output = self.conv_1(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.pool(output)\n",
    "        #print(output.shape)\n",
    "        \n",
    "        output = self.conv_2(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.pool(output)\n",
    "        #print(output.shape)\n",
    "        \n",
    "        output = self.conv_3(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.pool(output)\n",
    "        #print(output.shape)\n",
    "        \n",
    "        output = self.conv_4(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.pool(output)\n",
    "        #print(output.shape)\n",
    "\n",
    "        output=output.reshape((output.shape[0],output.shape[1]*output.shape[2]))\n",
    "        #output = torch.max(output, axis=2).values\n",
    "        output = self.linear_1(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.linear_2(output)\n",
    "        output = F.sigmoid(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4d9ab8ee-da8c-4d54-8935-06e9d63cf16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(vocab_size=max_words)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01,momentum=0.007)\n",
    "criterion = nn.MSELoss()#BCELoss()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "070ee0d5-994a-452e-ae61-20bc037f5e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (embedding): Embedding(2000, 128)\n",
      "  (conv_1): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv_2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv_3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv_4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu): ReLU()\n",
      "  (linear_1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (linear_2): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cbe9d6ad-acea-46cd-bcd5-a04202de3681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000]. Step [1/33]. Loss: 0.25019. Acc: 0.471. Test loss: 0.24972. Test acc: 0.757\n",
      "Epoch [2/1000]. Step [1/33]. Loss: 0.24964. Acc: 0.730. Test loss: 0.24928. Test acc: 0.878\n",
      "Epoch [3/1000]. Step [1/33]. Loss: 0.24896. Acc: 0.867. Test loss: 0.24822. Test acc: 0.927\n",
      "Epoch [4/1000]. Step [1/33]. Loss: 0.24839. Acc: 0.908. Test loss: 0.24842. Test acc: 0.933\n",
      "Epoch [5/1000]. Step [1/33]. Loss: 0.24773. Acc: 0.930. Test loss: 0.24651. Test acc: 0.933\n",
      "Epoch [6/1000]. Step [1/33]. Loss: 0.24737. Acc: 0.887. Test loss: 0.24786. Test acc: 0.933\n",
      "Epoch [7/1000]. Step [1/33]. Loss: 0.24664. Acc: 0.914. Test loss: 0.24462. Test acc: 0.933\n",
      "Epoch [8/1000]. Step [1/33]. Loss: 0.24607. Acc: 0.914. Test loss: 0.24451. Test acc: 0.933\n",
      "Epoch [9/1000]. Step [1/33]. Loss: 0.24582. Acc: 0.885. Test loss: 0.24359. Test acc: 0.933\n",
      "Epoch [10/1000]. Step [1/33]. Loss: 0.24506. Acc: 0.902. Test loss: 0.24297. Test acc: 0.933\n",
      "Epoch [11/1000]. Step [1/33]. Loss: 0.24430. Acc: 0.920. Test loss: 0.24290. Test acc: 0.933\n",
      "Epoch [12/1000]. Step [1/33]. Loss: 0.24386. Acc: 0.912. Test loss: 0.24156. Test acc: 0.933\n",
      "Epoch [13/1000]. Step [1/33]. Loss: 0.24308. Acc: 0.920. Test loss: 0.24468. Test acc: 0.933\n",
      "Epoch [14/1000]. Step [1/33]. Loss: 0.24349. Acc: 0.865. Test loss: 0.24408. Test acc: 0.933\n",
      "Epoch [15/1000]. Step [1/33]. Loss: 0.24234. Acc: 0.904. Test loss: 0.24407. Test acc: 0.933\n",
      "Epoch [16/1000]. Step [1/33]. Loss: 0.24177. Acc: 0.906. Test loss: 0.23912. Test acc: 0.933\n",
      "Epoch [17/1000]. Step [1/33]. Loss: 0.24121. Acc: 0.908. Test loss: 0.24336. Test acc: 0.933\n",
      "Epoch [18/1000]. Step [1/33]. Loss: 0.24067. Acc: 0.904. Test loss: 0.23798. Test acc: 0.933\n",
      "Epoch [19/1000]. Step [1/33]. Loss: 0.24022. Acc: 0.902. Test loss: 0.23694. Test acc: 0.933\n",
      "Epoch [20/1000]. Step [1/33]. Loss: 0.23998. Acc: 0.889. Test loss: 0.23699. Test acc: 0.933\n",
      "Epoch [21/1000]. Step [1/33]. Loss: 0.23926. Acc: 0.900. Test loss: 0.23571. Test acc: 0.933\n",
      "Epoch [22/1000]. Step [1/33]. Loss: 0.23877. Acc: 0.898. Test loss: 0.23513. Test acc: 0.933\n",
      "Epoch [23/1000]. Step [1/33]. Loss: 0.23758. Acc: 0.922. Test loss: 0.24078. Test acc: 0.933\n",
      "Epoch [24/1000]. Step [1/33]. Loss: 0.23727. Acc: 0.914. Test loss: 0.24032. Test acc: 0.933\n",
      "Epoch [25/1000]. Step [1/33]. Loss: 0.23724. Acc: 0.896. Test loss: 0.23320. Test acc: 0.933\n",
      "Epoch [26/1000]. Step [1/33]. Loss: 0.23594. Acc: 0.922. Test loss: 0.23266. Test acc: 0.933\n",
      "Epoch [27/1000]. Step [1/33]. Loss: 0.23593. Acc: 0.906. Test loss: 0.23160. Test acc: 0.933\n",
      "Epoch [28/1000]. Step [1/33]. Loss: 0.23518. Acc: 0.912. Test loss: 0.23905. Test acc: 0.933\n",
      "Epoch [29/1000]. Step [1/33]. Loss: 0.23547. Acc: 0.891. Test loss: 0.23068. Test acc: 0.933\n",
      "Epoch [30/1000]. Step [1/33]. Loss: 0.23410. Acc: 0.912. Test loss: 0.23044. Test acc: 0.933\n",
      "Epoch [31/1000]. Step [1/33]. Loss: 0.23409. Acc: 0.900. Test loss: 0.22915. Test acc: 0.933\n",
      "Epoch [32/1000]. Step [1/33]. Loss: 0.23352. Acc: 0.902. Test loss: 0.23745. Test acc: 0.933\n",
      "Epoch [33/1000]. Step [1/33]. Loss: 0.23268. Acc: 0.910. Test loss: 0.22802. Test acc: 0.933\n",
      "Epoch [34/1000]. Step [1/33]. Loss: 0.23257. Acc: 0.902. Test loss: 0.22771. Test acc: 0.933\n",
      "Epoch [35/1000]. Step [1/33]. Loss: 0.23214. Acc: 0.900. Test loss: 0.22685. Test acc: 0.933\n",
      "Epoch [36/1000]. Step [1/33]. Loss: 0.23148. Acc: 0.904. Test loss: 0.24565. Test acc: 0.933\n",
      "Epoch [37/1000]. Step [1/33]. Loss: 0.23046. Acc: 0.916. Test loss: 0.22585. Test acc: 0.933\n",
      "Epoch [38/1000]. Step [1/33]. Loss: 0.23009. Acc: 0.912. Test loss: 0.22462. Test acc: 0.933\n",
      "Epoch [39/1000]. Step [1/33]. Loss: 0.22926. Acc: 0.918. Test loss: 0.23498. Test acc: 0.933\n",
      "Epoch [40/1000]. Step [1/33]. Loss: 0.22935. Acc: 0.906. Test loss: 0.23427. Test acc: 0.933\n",
      "Epoch [41/1000]. Step [1/33]. Loss: 0.22889. Acc: 0.906. Test loss: 0.22297. Test acc: 0.933\n",
      "Epoch [42/1000]. Step [1/33]. Loss: 0.22855. Acc: 0.902. Test loss: 0.22266. Test acc: 0.933\n",
      "Epoch [43/1000]. Step [1/33]. Loss: 0.22802. Acc: 0.904. Test loss: 0.22244. Test acc: 0.933\n",
      "Epoch [44/1000]. Step [1/33]. Loss: 0.22711. Acc: 0.912. Test loss: 0.22146. Test acc: 0.933\n",
      "Epoch [45/1000]. Step [1/33]. Loss: 0.22739. Acc: 0.898. Test loss: 0.22067. Test acc: 0.933\n",
      "Epoch [46/1000]. Step [1/33]. Loss: 0.22590. Acc: 0.916. Test loss: 0.22011. Test acc: 0.933\n",
      "Epoch [47/1000]. Step [1/33]. Loss: 0.22548. Acc: 0.914. Test loss: 0.22004. Test acc: 0.933\n",
      "Epoch [48/1000]. Step [1/33]. Loss: 0.22477. Acc: 0.918. Test loss: 0.21941. Test acc: 0.933\n",
      "Epoch [49/1000]. Step [1/33]. Loss: 0.22527. Acc: 0.902. Test loss: 0.23113. Test acc: 0.933\n",
      "Epoch [50/1000]. Step [1/33]. Loss: 0.22530. Acc: 0.895. Test loss: 0.21758. Test acc: 0.933\n",
      "Epoch [51/1000]. Step [1/33]. Loss: 0.22215. Acc: 0.936. Test loss: 0.23080. Test acc: 0.933\n",
      "Epoch [52/1000]. Step [1/33]. Loss: 0.22333. Acc: 0.910. Test loss: 0.21641. Test acc: 0.933\n",
      "Epoch [53/1000]. Step [1/33]. Loss: 0.22417. Acc: 0.891. Test loss: 0.21648. Test acc: 0.933\n",
      "Epoch [54/1000]. Step [1/33]. Loss: 0.22144. Acc: 0.924. Test loss: 0.21536. Test acc: 0.933\n",
      "Epoch [55/1000]. Step [1/33]. Loss: 0.22159. Acc: 0.914. Test loss: 0.21484. Test acc: 0.933\n",
      "Epoch [56/1000]. Step [1/33]. Loss: 0.22057. Acc: 0.922. Test loss: 0.22965. Test acc: 0.933\n",
      "Epoch [57/1000]. Step [1/33]. Loss: 0.22325. Acc: 0.879. Test loss: 0.22898. Test acc: 0.933\n",
      "Epoch [58/1000]. Step [1/33]. Loss: 0.22109. Acc: 0.902. Test loss: 0.21315. Test acc: 0.933\n",
      "Epoch [59/1000]. Step [1/33]. Loss: 0.22022. Acc: 0.908. Test loss: 0.21299. Test acc: 0.933\n",
      "Epoch [60/1000]. Step [1/33]. Loss: 0.22018. Acc: 0.902. Test loss: 0.24370. Test acc: 0.933\n",
      "Epoch [61/1000]. Step [1/33]. Loss: 0.21848. Acc: 0.918. Test loss: 0.22720. Test acc: 0.933\n",
      "Epoch [62/1000]. Step [1/33]. Loss: 0.21898. Acc: 0.906. Test loss: 0.21070. Test acc: 0.933\n",
      "Epoch [63/1000]. Step [1/33]. Loss: 0.21945. Acc: 0.895. Test loss: 0.21027. Test acc: 0.933\n",
      "Epoch [64/1000]. Step [1/33]. Loss: 0.21786. Acc: 0.908. Test loss: 0.24372. Test acc: 0.933\n",
      "Epoch [65/1000]. Step [1/33]. Loss: 0.21897. Acc: 0.891. Test loss: 0.22608. Test acc: 0.933\n",
      "Epoch [66/1000]. Step [1/33]. Loss: 0.21935. Acc: 0.881. Test loss: 0.20866. Test acc: 0.933\n",
      "Epoch [67/1000]. Step [1/33]. Loss: 0.21575. Acc: 0.918. Test loss: 0.20805. Test acc: 0.933\n",
      "Epoch [68/1000]. Step [1/33]. Loss: 0.21564. Acc: 0.914. Test loss: 0.22526. Test acc: 0.933\n",
      "Epoch [69/1000]. Step [1/33]. Loss: 0.21486. Acc: 0.918. Test loss: 0.20709. Test acc: 0.933\n",
      "Epoch [70/1000]. Step [1/33]. Loss: 0.21421. Acc: 0.920. Test loss: 0.24315. Test acc: 0.933\n",
      "Epoch [71/1000]. Step [1/33]. Loss: 0.21515. Acc: 0.904. Test loss: 0.20585. Test acc: 0.933\n",
      "Epoch [72/1000]. Step [1/33]. Loss: 0.21541. Acc: 0.896. Test loss: 0.20538. Test acc: 0.933\n",
      "Epoch [73/1000]. Step [1/33]. Loss: 0.21323. Acc: 0.916. Test loss: 0.22368. Test acc: 0.933\n",
      "Epoch [74/1000]. Step [1/33]. Loss: 0.21255. Acc: 0.918. Test loss: 0.20450. Test acc: 0.933\n",
      "Epoch [75/1000]. Step [1/33]. Loss: 0.21434. Acc: 0.895. Test loss: 0.20422. Test acc: 0.933\n",
      "Epoch [76/1000]. Step [1/33]. Loss: 0.21394. Acc: 0.895. Test loss: 0.20336. Test acc: 0.933\n",
      "Epoch [77/1000]. Step [1/33]. Loss: 0.21335. Acc: 0.896. Test loss: 0.20239. Test acc: 0.933\n",
      "Epoch [78/1000]. Step [1/33]. Loss: 0.21217. Acc: 0.904. Test loss: 0.22268. Test acc: 0.933\n",
      "Epoch [79/1000]. Step [1/33]. Loss: 0.21175. Acc: 0.904. Test loss: 0.20135. Test acc: 0.933\n",
      "Epoch [80/1000]. Step [1/33]. Loss: 0.21095. Acc: 0.908. Test loss: 0.20116. Test acc: 0.933\n",
      "Epoch [81/1000]. Step [1/33]. Loss: 0.21252. Acc: 0.889. Test loss: 0.22136. Test acc: 0.933\n",
      "Epoch [82/1000]. Step [1/33]. Loss: 0.21009. Acc: 0.908. Test loss: 0.20024. Test acc: 0.933\n",
      "Epoch [83/1000]. Step [1/33]. Loss: 0.20946. Acc: 0.910. Test loss: 0.19983. Test acc: 0.933\n",
      "Epoch [84/1000]. Step [1/33]. Loss: 0.21009. Acc: 0.900. Test loss: 0.22025. Test acc: 0.933\n",
      "Epoch [85/1000]. Step [1/33]. Loss: 0.21118. Acc: 0.887. Test loss: 0.19877. Test acc: 0.933\n",
      "Epoch [86/1000]. Step [1/33]. Loss: 0.20885. Acc: 0.904. Test loss: 0.19796. Test acc: 0.933\n",
      "Epoch [87/1000]. Step [1/33]. Loss: 0.20654. Acc: 0.922. Test loss: 0.21966. Test acc: 0.933\n",
      "Epoch [88/1000]. Step [1/33]. Loss: 0.20671. Acc: 0.916. Test loss: 0.21957. Test acc: 0.933\n",
      "Epoch [89/1000]. Step [1/33]. Loss: 0.20721. Acc: 0.908. Test loss: 0.24185. Test acc: 0.933\n",
      "Epoch [90/1000]. Step [1/33]. Loss: 0.21013. Acc: 0.879. Test loss: 0.21898. Test acc: 0.933\n",
      "Epoch [91/1000]. Step [1/33]. Loss: 0.20706. Acc: 0.902. Test loss: 0.21877. Test acc: 0.933\n",
      "Epoch [92/1000]. Step [1/33]. Loss: 0.20604. Acc: 0.908. Test loss: 0.21821. Test acc: 0.933\n",
      "Epoch [93/1000]. Step [1/33]. Loss: 0.20699. Acc: 0.896. Test loss: 0.21784. Test acc: 0.933\n",
      "Epoch [94/1000]. Step [1/33]. Loss: 0.20681. Acc: 0.895. Test loss: 0.19374. Test acc: 0.933\n",
      "Epoch [95/1000]. Step [1/33]. Loss: 0.20530. Acc: 0.904. Test loss: 0.19339. Test acc: 0.933\n",
      "Epoch [96/1000]. Step [1/33]. Loss: 0.20604. Acc: 0.895. Test loss: 0.19267. Test acc: 0.933\n",
      "Epoch [97/1000]. Step [1/33]. Loss: 0.20712. Acc: 0.883. Test loss: 0.19258. Test acc: 0.933\n",
      "Epoch [98/1000]. Step [1/33]. Loss: 0.20436. Acc: 0.902. Test loss: 0.19191. Test acc: 0.933\n",
      "Epoch [99/1000]. Step [1/33]. Loss: 0.20131. Acc: 0.924. Test loss: 0.19101. Test acc: 0.933\n",
      "Epoch [100/1000]. Step [1/33]. Loss: 0.20579. Acc: 0.885. Test loss: 0.19079. Test acc: 0.933\n",
      "Epoch [101/1000]. Step [1/33]. Loss: 0.20249. Acc: 0.908. Test loss: 0.18997. Test acc: 0.933\n",
      "Epoch [102/1000]. Step [1/33]. Loss: 0.20058. Acc: 0.920. Test loss: 0.18994. Test acc: 0.933\n",
      "Epoch [103/1000]. Step [1/33]. Loss: 0.19938. Acc: 0.926. Test loss: 0.21519. Test acc: 0.933\n",
      "Epoch [104/1000]. Step [1/33]. Loss: 0.20228. Acc: 0.900. Test loss: 0.18865. Test acc: 0.933\n",
      "Epoch [105/1000]. Step [1/33]. Loss: 0.20391. Acc: 0.885. Test loss: 0.18838. Test acc: 0.933\n",
      "Epoch [106/1000]. Step [1/33]. Loss: 0.20461. Acc: 0.877. Test loss: 0.21435. Test acc: 0.933\n",
      "Epoch [107/1000]. Step [1/33]. Loss: 0.20223. Acc: 0.893. Test loss: 0.18757. Test acc: 0.933\n",
      "Epoch [108/1000]. Step [1/33]. Loss: 0.20056. Acc: 0.902. Test loss: 0.18703. Test acc: 0.933\n",
      "Epoch [109/1000]. Step [1/33]. Loss: 0.19755. Acc: 0.922. Test loss: 0.18618. Test acc: 0.933\n",
      "Epoch [110/1000]. Step [1/33]. Loss: 0.19870. Acc: 0.910. Test loss: 0.18615. Test acc: 0.933\n",
      "Epoch [111/1000]. Step [1/33]. Loss: 0.19805. Acc: 0.912. Test loss: 0.21285. Test acc: 0.933\n",
      "Epoch [112/1000]. Step [1/33]. Loss: 0.19817. Acc: 0.908. Test loss: 0.18465. Test acc: 0.933\n",
      "Epoch [113/1000]. Step [1/33]. Loss: 0.19644. Acc: 0.918. Test loss: 0.21303. Test acc: 0.933\n",
      "Epoch [114/1000]. Step [1/33]. Loss: 0.19796. Acc: 0.904. Test loss: 0.18400. Test acc: 0.933\n",
      "Epoch [115/1000]. Step [1/33]. Loss: 0.19816. Acc: 0.900. Test loss: 0.18358. Test acc: 0.933\n",
      "Epoch [116/1000]. Step [1/33]. Loss: 0.19667. Acc: 0.908. Test loss: 0.18289. Test acc: 0.933\n",
      "Epoch [117/1000]. Step [1/33]. Loss: 0.19630. Acc: 0.908. Test loss: 0.18273. Test acc: 0.933\n",
      "Epoch [118/1000]. Step [1/33]. Loss: 0.19593. Acc: 0.908. Test loss: 0.18240. Test acc: 0.933\n",
      "Epoch [119/1000]. Step [1/33]. Loss: 0.19638. Acc: 0.902. Test loss: 0.21117. Test acc: 0.933\n",
      "Epoch [120/1000]. Step [1/33]. Loss: 0.19862. Acc: 0.885. Test loss: 0.18091. Test acc: 0.933\n",
      "Epoch [121/1000]. Step [1/33]. Loss: 0.19396. Acc: 0.914. Test loss: 0.18070. Test acc: 0.933\n",
      "Epoch [122/1000]. Step [1/33]. Loss: 0.19709. Acc: 0.891. Test loss: 0.18001. Test acc: 0.933\n",
      "Epoch [123/1000]. Step [1/33]. Loss: 0.19468. Acc: 0.904. Test loss: 0.17991. Test acc: 0.933\n",
      "Epoch [124/1000]. Step [1/33]. Loss: 0.19431. Acc: 0.904. Test loss: 0.17940. Test acc: 0.933\n",
      "Epoch [125/1000]. Step [1/33]. Loss: 0.19368. Acc: 0.906. Test loss: 0.20959. Test acc: 0.933\n",
      "Epoch [126/1000]. Step [1/33]. Loss: 0.19302. Acc: 0.908. Test loss: 0.24058. Test acc: 0.933\n",
      "Epoch [127/1000]. Step [1/33]. Loss: 0.19077. Acc: 0.920. Test loss: 0.17780. Test acc: 0.933\n",
      "Epoch [128/1000]. Step [1/33]. Loss: 0.19378. Acc: 0.898. Test loss: 0.17740. Test acc: 0.933\n",
      "Epoch [129/1000]. Step [1/33]. Loss: 0.19560. Acc: 0.885. Test loss: 0.17709. Test acc: 0.933\n",
      "Epoch [130/1000]. Step [1/33]. Loss: 0.18754. Acc: 0.934. Test loss: 0.17640. Test acc: 0.933\n",
      "Epoch [131/1000]. Step [1/33]. Loss: 0.19401. Acc: 0.891. Test loss: 0.17608. Test acc: 0.933\n",
      "Epoch [132/1000]. Step [1/33]. Loss: 0.18955. Acc: 0.916. Test loss: 0.17568. Test acc: 0.933\n",
      "Epoch [133/1000]. Step [1/33]. Loss: 0.19232. Acc: 0.896. Test loss: 0.17515. Test acc: 0.933\n",
      "Epoch [134/1000]. Step [1/33]. Loss: 0.19139. Acc: 0.900. Test loss: 0.17481. Test acc: 0.933\n",
      "Epoch [135/1000]. Step [1/33]. Loss: 0.19298. Acc: 0.889. Test loss: 0.17398. Test acc: 0.933\n",
      "Epoch [136/1000]. Step [1/33]. Loss: 0.19007. Acc: 0.904. Test loss: 0.20689. Test acc: 0.933\n",
      "Epoch [137/1000]. Step [1/33]. Loss: 0.19424. Acc: 0.877. Test loss: 0.17338. Test acc: 0.933\n",
      "Epoch [138/1000]. Step [1/33]. Loss: 0.18610. Acc: 0.924. Test loss: 0.17276. Test acc: 0.933\n",
      "Epoch [139/1000]. Step [1/33]. Loss: 0.19368. Acc: 0.877. Test loss: 0.17263. Test acc: 0.933\n",
      "Epoch [140/1000]. Step [1/33]. Loss: 0.18938. Acc: 0.900. Test loss: 0.20634. Test acc: 0.933\n",
      "Epoch [141/1000]. Step [1/33]. Loss: 0.18872. Acc: 0.902. Test loss: 0.17160. Test acc: 0.933\n",
      "Epoch [142/1000]. Step [1/33]. Loss: 0.18535. Acc: 0.920. Test loss: 0.17171. Test acc: 0.933\n",
      "Epoch [143/1000]. Step [1/33]. Loss: 0.18568. Acc: 0.916. Test loss: 0.17076. Test acc: 0.933\n",
      "Epoch [144/1000]. Step [1/33]. Loss: 0.18567. Acc: 0.914. Test loss: 0.17022. Test acc: 0.933\n",
      "Epoch [145/1000]. Step [1/33]. Loss: 0.19005. Acc: 0.887. Test loss: 0.16982. Test acc: 0.933\n",
      "Epoch [146/1000]. Step [1/33]. Loss: 0.18462. Acc: 0.916. Test loss: 0.20470. Test acc: 0.933\n",
      "Epoch [147/1000]. Step [1/33]. Loss: 0.18356. Acc: 0.920. Test loss: 0.20447. Test acc: 0.933\n",
      "Epoch [148/1000]. Step [1/33]. Loss: 0.18876. Acc: 0.889. Test loss: 0.20409. Test acc: 0.933\n",
      "Epoch [149/1000]. Step [1/33]. Loss: 0.18529. Acc: 0.906. Test loss: 0.16821. Test acc: 0.933\n",
      "Epoch [150/1000]. Step [1/33]. Loss: 0.18498. Acc: 0.906. Test loss: 0.16752. Test acc: 0.933\n",
      "Epoch [151/1000]. Step [1/33]. Loss: 0.18640. Acc: 0.896. Test loss: 0.20331. Test acc: 0.933\n",
      "Epoch [152/1000]. Step [1/33]. Loss: 0.18466. Acc: 0.904. Test loss: 0.16647. Test acc: 0.933\n",
      "Epoch [153/1000]. Step [1/33]. Loss: 0.18002. Acc: 0.928. Test loss: 0.24045. Test acc: 0.933\n",
      "Epoch [154/1000]. Step [1/33]. Loss: 0.18215. Acc: 0.914. Test loss: 0.16584. Test acc: 0.933\n",
      "Epoch [155/1000]. Step [1/33]. Loss: 0.18868. Acc: 0.877. Test loss: 0.16573. Test acc: 0.933\n",
      "Epoch [156/1000]. Step [1/33]. Loss: 0.18222. Acc: 0.910. Test loss: 0.16504. Test acc: 0.933\n",
      "Epoch [157/1000]. Step [1/33]. Loss: 0.17859. Acc: 0.928. Test loss: 0.16481. Test acc: 0.933\n",
      "Epoch [158/1000]. Step [1/33]. Loss: 0.18226. Acc: 0.906. Test loss: 0.16412. Test acc: 0.933\n",
      "Epoch [159/1000]. Step [1/33]. Loss: 0.18304. Acc: 0.900. Test loss: 0.20211. Test acc: 0.933\n",
      "Epoch [160/1000]. Step [1/33]. Loss: 0.18124. Acc: 0.908. Test loss: 0.16344. Test acc: 0.933\n",
      "Epoch [161/1000]. Step [1/33]. Loss: 0.18051. Acc: 0.910. Test loss: 0.16319. Test acc: 0.933\n",
      "Epoch [162/1000]. Step [1/33]. Loss: 0.17905. Acc: 0.916. Test loss: 0.16293. Test acc: 0.933\n",
      "Epoch [163/1000]. Step [1/33]. Loss: 0.18479. Acc: 0.885. Test loss: 0.16225. Test acc: 0.933\n",
      "Epoch [164/1000]. Step [1/33]. Loss: 0.18413. Acc: 0.887. Test loss: 0.16167. Test acc: 0.933\n",
      "Epoch [165/1000]. Step [1/33]. Loss: 0.18037. Acc: 0.904. Test loss: 0.16079. Test acc: 0.933\n",
      "Epoch [166/1000]. Step [1/33]. Loss: 0.17965. Acc: 0.906. Test loss: 0.16078. Test acc: 0.933\n",
      "Epoch [167/1000]. Step [1/33]. Loss: 0.17974. Acc: 0.904. Test loss: 0.16039. Test acc: 0.933\n",
      "Epoch [168/1000]. Step [1/33]. Loss: 0.18057. Acc: 0.898. Test loss: 0.16038. Test acc: 0.933\n",
      "Epoch [169/1000]. Step [1/33]. Loss: 0.17678. Acc: 0.916. Test loss: 0.15956. Test acc: 0.933\n",
      "Epoch [170/1000]. Step [1/33]. Loss: 0.17723. Acc: 0.912. Test loss: 0.15880. Test acc: 0.933\n",
      "Epoch [171/1000]. Step [1/33]. Loss: 0.17689. Acc: 0.912. Test loss: 0.15866. Test acc: 0.933\n",
      "Epoch [172/1000]. Step [1/33]. Loss: 0.17500. Acc: 0.920. Test loss: 0.15844. Test acc: 0.933\n",
      "Epoch [173/1000]. Step [1/33]. Loss: 0.17667. Acc: 0.910. Test loss: 0.15747. Test acc: 0.933\n",
      "Epoch [174/1000]. Step [1/33]. Loss: 0.17470. Acc: 0.918. Test loss: 0.19872. Test acc: 0.933\n",
      "Epoch [175/1000]. Step [1/33]. Loss: 0.17883. Acc: 0.896. Test loss: 0.15715. Test acc: 0.933\n",
      "Epoch [176/1000]. Step [1/33]. Loss: 0.17723. Acc: 0.902. Test loss: 0.15645. Test acc: 0.933\n",
      "Epoch [177/1000]. Step [1/33]. Loss: 0.17903. Acc: 0.893. Test loss: 0.19805. Test acc: 0.933\n",
      "Epoch [178/1000]. Step [1/33]. Loss: 0.17545. Acc: 0.908. Test loss: 0.15597. Test acc: 0.933\n",
      "Epoch [179/1000]. Step [1/33]. Loss: 0.17721. Acc: 0.898. Test loss: 0.19795. Test acc: 0.933\n",
      "Epoch [180/1000]. Step [1/33]. Loss: 0.17857. Acc: 0.891. Test loss: 0.15466. Test acc: 0.933\n",
      "Epoch [181/1000]. Step [1/33]. Loss: 0.17162. Acc: 0.922. Test loss: 0.19696. Test acc: 0.933\n",
      "Epoch [182/1000]. Step [1/33]. Loss: 0.17546. Acc: 0.902. Test loss: 0.15404. Test acc: 0.933\n",
      "Epoch [183/1000]. Step [1/33]. Loss: 0.17562. Acc: 0.900. Test loss: 0.23980. Test acc: 0.933\n",
      "Epoch [184/1000]. Step [1/33]. Loss: 0.17408. Acc: 0.906. Test loss: 0.23987. Test acc: 0.933\n",
      "Epoch [185/1000]. Step [1/33]. Loss: 0.17543. Acc: 0.898. Test loss: 0.15276. Test acc: 0.933\n",
      "Epoch [186/1000]. Step [1/33]. Loss: 0.16915. Acc: 0.926. Test loss: 0.15298. Test acc: 0.933\n",
      "Epoch [187/1000]. Step [1/33]. Loss: 0.17144. Acc: 0.914. Test loss: 0.28428. Test acc: 0.933\n",
      "Epoch [188/1000]. Step [1/33]. Loss: 0.17621. Acc: 0.891. Test loss: 0.15177. Test acc: 0.933\n",
      "Epoch [189/1000]. Step [1/33]. Loss: 0.17382. Acc: 0.900. Test loss: 0.19597. Test acc: 0.933\n",
      "Epoch [190/1000]. Step [1/33]. Loss: 0.17612. Acc: 0.889. Test loss: 0.15117. Test acc: 0.933\n",
      "Epoch [191/1000]. Step [1/33]. Loss: 0.17324. Acc: 0.900. Test loss: 0.15044. Test acc: 0.933\n",
      "Epoch [192/1000]. Step [1/33]. Loss: 0.17338. Acc: 0.898. Test loss: 0.15043. Test acc: 0.933\n",
      "Epoch [193/1000]. Step [1/33]. Loss: 0.17093. Acc: 0.908. Test loss: 0.14999. Test acc: 0.933\n",
      "Epoch [194/1000]. Step [1/33]. Loss: 0.16974. Acc: 0.912. Test loss: 0.14969. Test acc: 0.933\n",
      "Epoch [195/1000]. Step [1/33]. Loss: 0.16500. Acc: 0.932. Test loss: 0.14926. Test acc: 0.933\n",
      "Epoch [196/1000]. Step [1/33]. Loss: 0.17270. Acc: 0.896. Test loss: 0.19464. Test acc: 0.933\n",
      "Epoch [197/1000]. Step [1/33]. Loss: 0.17194. Acc: 0.898. Test loss: 0.14873. Test acc: 0.933\n",
      "Epoch [198/1000]. Step [1/33]. Loss: 0.17209. Acc: 0.896. Test loss: 0.19393. Test acc: 0.933\n",
      "Epoch [199/1000]. Step [1/33]. Loss: 0.17140. Acc: 0.898. Test loss: 0.24047. Test acc: 0.933\n",
      "Epoch [200/1000]. Step [1/33]. Loss: 0.16795. Acc: 0.912. Test loss: 0.28702. Test acc: 0.933\n",
      "Epoch [201/1000]. Step [1/33]. Loss: 0.17130. Acc: 0.896. Test loss: 0.14679. Test acc: 0.933\n",
      "Epoch [202/1000]. Step [1/33]. Loss: 0.16731. Acc: 0.912. Test loss: 0.14632. Test acc: 0.933\n",
      "Epoch [203/1000]. Step [1/33]. Loss: 0.17025. Acc: 0.898. Test loss: 0.19302. Test acc: 0.933\n",
      "Epoch [204/1000]. Step [1/33]. Loss: 0.16954. Acc: 0.900. Test loss: 0.14531. Test acc: 0.933\n",
      "Epoch [205/1000]. Step [1/33]. Loss: 0.16879. Acc: 0.902. Test loss: 0.14536. Test acc: 0.933\n",
      "Epoch [206/1000]. Step [1/33]. Loss: 0.16943. Acc: 0.898. Test loss: 0.19256. Test acc: 0.933\n",
      "Epoch [207/1000]. Step [1/33]. Loss: 0.16729. Acc: 0.906. Test loss: 0.14497. Test acc: 0.933\n",
      "Epoch [208/1000]. Step [1/33]. Loss: 0.16653. Acc: 0.908. Test loss: 0.14423. Test acc: 0.933\n",
      "Epoch [209/1000]. Step [1/33]. Loss: 0.16341. Acc: 0.920. Test loss: 0.14353. Test acc: 0.933\n",
      "Epoch [210/1000]. Step [1/33]. Loss: 0.17017. Acc: 0.891. Test loss: 0.24073. Test acc: 0.933\n",
      "Epoch [211/1000]. Step [1/33]. Loss: 0.16941. Acc: 0.893. Test loss: 0.14283. Test acc: 0.933\n",
      "Epoch [212/1000]. Step [1/33]. Loss: 0.16493. Acc: 0.910. Test loss: 0.19148. Test acc: 0.933\n",
      "Epoch [213/1000]. Step [1/33]. Loss: 0.16324. Acc: 0.916. Test loss: 0.14244. Test acc: 0.933\n",
      "Epoch [214/1000]. Step [1/33]. Loss: 0.16532. Acc: 0.906. Test loss: 0.19117. Test acc: 0.933\n",
      "Epoch [215/1000]. Step [1/33]. Loss: 0.16313. Acc: 0.914. Test loss: 0.14133. Test acc: 0.933\n",
      "Epoch [216/1000]. Step [1/33]. Loss: 0.17057. Acc: 0.883. Test loss: 0.14157. Test acc: 0.933\n",
      "Epoch [217/1000]. Step [1/33]. Loss: 0.16304. Acc: 0.912. Test loss: 0.14109. Test acc: 0.933\n",
      "Epoch [218/1000]. Step [1/33]. Loss: 0.16227. Acc: 0.914. Test loss: 0.14057. Test acc: 0.933\n",
      "Epoch [219/1000]. Step [1/33]. Loss: 0.16636. Acc: 0.896. Test loss: 0.18993. Test acc: 0.933\n",
      "Epoch [220/1000]. Step [1/33]. Loss: 0.16266. Acc: 0.910. Test loss: 0.13951. Test acc: 0.933\n",
      "Epoch [221/1000]. Step [1/33]. Loss: 0.16390. Acc: 0.904. Test loss: 0.13906. Test acc: 0.933\n",
      "Epoch [222/1000]. Step [1/33]. Loss: 0.16759. Acc: 0.889. Test loss: 0.13968. Test acc: 0.933\n",
      "Epoch [223/1000]. Step [1/33]. Loss: 0.16685. Acc: 0.891. Test loss: 0.13852. Test acc: 0.933\n",
      "Epoch [224/1000]. Step [1/33]. Loss: 0.16761. Acc: 0.887. Test loss: 0.13825. Test acc: 0.933\n",
      "Epoch [225/1000]. Step [1/33]. Loss: 0.16234. Acc: 0.906. Test loss: 0.13833. Test acc: 0.933\n",
      "Epoch [226/1000]. Step [1/33]. Loss: 0.16611. Acc: 0.891. Test loss: 0.13788. Test acc: 0.933\n",
      "Epoch [227/1000]. Step [1/33]. Loss: 0.16287. Acc: 0.902. Test loss: 0.13721. Test acc: 0.933\n",
      "Epoch [228/1000]. Step [1/33]. Loss: 0.16614. Acc: 0.889. Test loss: 0.13662. Test acc: 0.933\n",
      "Epoch [229/1000]. Step [1/33]. Loss: 0.15829. Acc: 0.918. Test loss: 0.13655. Test acc: 0.933\n",
      "Epoch [230/1000]. Step [1/33]. Loss: 0.16053. Acc: 0.908. Test loss: 0.13633. Test acc: 0.933\n",
      "Epoch [231/1000]. Step [1/33]. Loss: 0.16181. Acc: 0.902. Test loss: 0.18839. Test acc: 0.933\n",
      "Epoch [232/1000]. Step [1/33]. Loss: 0.16156. Acc: 0.902. Test loss: 0.13582. Test acc: 0.933\n",
      "Epoch [233/1000]. Step [1/33]. Loss: 0.16235. Acc: 0.898. Test loss: 0.13550. Test acc: 0.933\n",
      "Epoch [234/1000]. Step [1/33]. Loss: 0.16161. Acc: 0.900. Test loss: 0.18807. Test acc: 0.933\n",
      "Epoch [235/1000]. Step [1/33]. Loss: 0.16343. Acc: 0.893. Test loss: 0.13468. Test acc: 0.933\n",
      "Epoch [236/1000]. Step [1/33]. Loss: 0.15851. Acc: 0.910. Test loss: 0.18792. Test acc: 0.933\n",
      "Epoch [237/1000]. Step [1/33]. Loss: 0.16186. Acc: 0.896. Test loss: 0.13361. Test acc: 0.933\n",
      "Epoch [238/1000]. Step [1/33]. Loss: 0.15691. Acc: 0.914. Test loss: 0.13344. Test acc: 0.933\n",
      "Epoch [239/1000]. Step [1/33]. Loss: 0.15982. Acc: 0.902. Test loss: 0.18750. Test acc: 0.933\n",
      "Epoch [240/1000]. Step [1/33]. Loss: 0.16057. Acc: 0.898. Test loss: 0.18738. Test acc: 0.933\n",
      "Epoch [241/1000]. Step [1/33]. Loss: 0.16037. Acc: 0.898. Test loss: 0.24100. Test acc: 0.933\n",
      "Epoch [242/1000]. Step [1/33]. Loss: 0.15532. Acc: 0.916. Test loss: 0.13229. Test acc: 0.933\n",
      "Epoch [243/1000]. Step [1/33]. Loss: 0.15723. Acc: 0.908. Test loss: 0.13183. Test acc: 0.933\n",
      "Epoch [244/1000]. Step [1/33]. Loss: 0.15532. Acc: 0.914. Test loss: 0.18663. Test acc: 0.933\n",
      "Epoch [245/1000]. Step [1/33]. Loss: 0.15503. Acc: 0.914. Test loss: 0.13088. Test acc: 0.933\n",
      "Epoch [246/1000]. Step [1/33]. Loss: 0.14999. Acc: 0.932. Test loss: 0.13059. Test acc: 0.933\n",
      "Epoch [247/1000]. Step [1/33]. Loss: 0.16048. Acc: 0.893. Test loss: 0.18591. Test acc: 0.933\n",
      "Epoch [248/1000]. Step [1/33]. Loss: 0.15429. Acc: 0.914. Test loss: 0.18554. Test acc: 0.933\n",
      "Epoch [249/1000]. Step [1/33]. Loss: 0.15616. Acc: 0.906. Test loss: 0.12985. Test acc: 0.933\n",
      "Epoch [250/1000]. Step [1/33]. Loss: 0.15866. Acc: 0.896. Test loss: 0.12951. Test acc: 0.933\n",
      "Epoch [251/1000]. Step [1/33]. Loss: 0.15402. Acc: 0.912. Test loss: 0.12924. Test acc: 0.933\n",
      "Epoch [252/1000]. Step [1/33]. Loss: 0.15985. Acc: 0.891. Test loss: 0.12925. Test acc: 0.933\n",
      "Epoch [253/1000]. Step [1/33]. Loss: 0.15468. Acc: 0.908. Test loss: 0.12841. Test acc: 0.933\n",
      "Epoch [254/1000]. Step [1/33]. Loss: 0.15279. Acc: 0.914. Test loss: 0.12778. Test acc: 0.933\n",
      "Epoch [255/1000]. Step [1/33]. Loss: 0.15810. Acc: 0.895. Test loss: 0.18473. Test acc: 0.933\n",
      "Epoch [256/1000]. Step [1/33]. Loss: 0.14949. Acc: 0.924. Test loss: 0.12772. Test acc: 0.933\n",
      "Epoch [257/1000]. Step [1/33]. Loss: 0.16038. Acc: 0.885. Test loss: 0.12659. Test acc: 0.933\n",
      "Epoch [258/1000]. Step [1/33]. Loss: 0.15400. Acc: 0.906. Test loss: 0.18400. Test acc: 0.933\n",
      "Epoch [259/1000]. Step [1/33]. Loss: 0.15602. Acc: 0.898. Test loss: 0.12645. Test acc: 0.933\n",
      "Epoch [260/1000]. Step [1/33]. Loss: 0.15641. Acc: 0.896. Test loss: 0.12631. Test acc: 0.933\n",
      "Epoch [261/1000]. Step [1/33]. Loss: 0.15277. Acc: 0.908. Test loss: 0.12578. Test acc: 0.933\n",
      "Epoch [262/1000]. Step [1/33]. Loss: 0.15876. Acc: 0.887. Test loss: 0.18394. Test acc: 0.933\n",
      "Epoch [263/1000]. Step [1/33]. Loss: 0.15004. Acc: 0.916. Test loss: 0.12504. Test acc: 0.933\n",
      "Epoch [264/1000]. Step [1/33]. Loss: 0.15602. Acc: 0.895. Test loss: 0.12508. Test acc: 0.933\n",
      "Epoch [265/1000]. Step [1/33]. Loss: 0.14956. Acc: 0.916. Test loss: 0.12453. Test acc: 0.933\n",
      "Epoch [266/1000]. Step [1/33]. Loss: 0.14699. Acc: 0.924. Test loss: 0.12430. Test acc: 0.933\n",
      "Epoch [267/1000]. Step [1/33]. Loss: 0.15826. Acc: 0.885. Test loss: 0.12390. Test acc: 0.933\n",
      "Epoch [268/1000]. Step [1/33]. Loss: 0.15168. Acc: 0.906. Test loss: 0.12346. Test acc: 0.933\n",
      "Epoch [269/1000]. Step [1/33]. Loss: 0.15088. Acc: 0.908. Test loss: 0.12319. Test acc: 0.933\n",
      "Epoch [270/1000]. Step [1/33]. Loss: 0.15058. Acc: 0.908. Test loss: 0.24288. Test acc: 0.933\n",
      "Epoch [271/1000]. Step [1/33]. Loss: 0.14631. Acc: 0.922. Test loss: 0.12271. Test acc: 0.933\n",
      "Epoch [272/1000]. Step [1/33]. Loss: 0.15303. Acc: 0.898. Test loss: 0.12236. Test acc: 0.933\n",
      "Epoch [273/1000]. Step [1/33]. Loss: 0.15111. Acc: 0.904. Test loss: 0.18257. Test acc: 0.933\n",
      "Epoch [274/1000]. Step [1/33]. Loss: 0.14438. Acc: 0.926. Test loss: 0.12170. Test acc: 0.933\n",
      "Epoch [275/1000]. Step [1/33]. Loss: 0.15185. Acc: 0.900. Test loss: 0.12146. Test acc: 0.933\n",
      "Epoch [276/1000]. Step [1/33]. Loss: 0.15038. Acc: 0.904. Test loss: 0.12137. Test acc: 0.933\n",
      "Epoch [277/1000]. Step [1/33]. Loss: 0.15076. Acc: 0.902. Test loss: 0.12063. Test acc: 0.933\n",
      "Epoch [278/1000]. Step [1/33]. Loss: 0.14698. Acc: 0.914. Test loss: 0.12052. Test acc: 0.933\n",
      "Epoch [279/1000]. Step [1/33]. Loss: 0.14787. Acc: 0.910. Test loss: 0.18247. Test acc: 0.933\n",
      "Epoch [280/1000]. Step [1/33]. Loss: 0.15005. Acc: 0.902. Test loss: 0.12021. Test acc: 0.933\n",
      "Epoch [281/1000]. Step [1/33]. Loss: 0.15163. Acc: 0.896. Test loss: 0.11977. Test acc: 0.933\n",
      "Epoch [282/1000]. Step [1/33]. Loss: 0.14542. Acc: 0.916. Test loss: 0.11957. Test acc: 0.933\n",
      "Epoch [283/1000]. Step [1/33]. Loss: 0.14642. Acc: 0.912. Test loss: 0.11907. Test acc: 0.933\n",
      "Epoch [284/1000]. Step [1/33]. Loss: 0.14494. Acc: 0.916. Test loss: 0.11882. Test acc: 0.933\n",
      "Epoch [285/1000]. Step [1/33]. Loss: 0.14953. Acc: 0.900. Test loss: 0.11856. Test acc: 0.933\n",
      "Epoch [286/1000]. Step [1/33]. Loss: 0.14632. Acc: 0.910. Test loss: 0.11782. Test acc: 0.933\n",
      "Epoch [287/1000]. Step [1/33]. Loss: 0.14730. Acc: 0.906. Test loss: 0.11695. Test acc: 0.933\n",
      "Epoch [288/1000]. Step [1/33]. Loss: 0.15264. Acc: 0.889. Test loss: 0.11749. Test acc: 0.933\n",
      "Epoch [289/1000]. Step [1/33]. Loss: 0.14321. Acc: 0.918. Test loss: 0.11685. Test acc: 0.933\n",
      "Epoch [290/1000]. Step [1/33]. Loss: 0.14415. Acc: 0.914. Test loss: 0.11681. Test acc: 0.933\n",
      "Epoch [291/1000]. Step [1/33]. Loss: 0.14892. Acc: 0.898. Test loss: 0.11654. Test acc: 0.933\n",
      "Epoch [292/1000]. Step [1/33]. Loss: 0.13814. Acc: 0.932. Test loss: 0.17943. Test acc: 0.933\n",
      "Epoch [293/1000]. Step [1/33]. Loss: 0.14039. Acc: 0.924. Test loss: 0.24382. Test acc: 0.933\n",
      "Epoch [294/1000]. Step [1/33]. Loss: 0.14325. Acc: 0.914. Test loss: 0.11576. Test acc: 0.933\n",
      "Epoch [295/1000]. Step [1/33]. Loss: 0.14803. Acc: 0.898. Test loss: 0.11453. Test acc: 0.933\n",
      "Epoch [296/1000]. Step [1/33]. Loss: 0.15033. Acc: 0.891. Test loss: 0.30817. Test acc: 0.933\n",
      "Epoch [297/1000]. Step [1/33]. Loss: 0.14763. Acc: 0.898. Test loss: 0.17880. Test acc: 0.933\n",
      "Epoch [298/1000]. Step [1/33]. Loss: 0.14362. Acc: 0.910. Test loss: 0.11405. Test acc: 0.933\n",
      "Epoch [299/1000]. Step [1/33]. Loss: 0.14912. Acc: 0.893. Test loss: 0.11410. Test acc: 0.933\n",
      "Epoch [300/1000]. Step [1/33]. Loss: 0.14515. Acc: 0.904. Test loss: 0.11425. Test acc: 0.933\n",
      "Epoch [301/1000]. Step [1/33]. Loss: 0.13981. Acc: 0.920. Test loss: 0.11302. Test acc: 0.933\n",
      "Epoch [302/1000]. Step [1/33]. Loss: 0.15104. Acc: 0.885. Test loss: 0.11314. Test acc: 0.933\n",
      "Epoch [303/1000]. Step [1/33]. Loss: 0.15151. Acc: 0.883. Test loss: 0.11257. Test acc: 0.933\n",
      "Epoch [304/1000]. Step [1/33]. Loss: 0.14755. Acc: 0.895. Test loss: 0.11265. Test acc: 0.933\n",
      "Epoch [305/1000]. Step [1/33]. Loss: 0.14546. Acc: 0.900. Test loss: 0.11213. Test acc: 0.933\n",
      "Epoch [306/1000]. Step [1/33]. Loss: 0.13937. Acc: 0.918. Test loss: 0.17836. Test acc: 0.933\n",
      "Epoch [307/1000]. Step [1/33]. Loss: 0.14375. Acc: 0.904. Test loss: 0.17759. Test acc: 0.933\n",
      "Epoch [308/1000]. Step [1/33]. Loss: 0.14154. Acc: 0.910. Test loss: 0.11131. Test acc: 0.933\n",
      "Epoch [309/1000]. Step [1/33]. Loss: 0.13999. Acc: 0.914. Test loss: 0.11129. Test acc: 0.933\n",
      "Epoch [310/1000]. Step [1/33]. Loss: 0.14761. Acc: 0.891. Test loss: 0.11121. Test acc: 0.933\n",
      "Epoch [311/1000]. Step [1/33]. Loss: 0.14485. Acc: 0.898. Test loss: 0.11019. Test acc: 0.933\n",
      "Epoch [312/1000]. Step [1/33]. Loss: 0.14916. Acc: 0.885. Test loss: 0.17781. Test acc: 0.933\n",
      "Epoch [313/1000]. Step [1/33]. Loss: 0.14317. Acc: 0.902. Test loss: 0.17722. Test acc: 0.933\n",
      "Epoch [314/1000]. Step [1/33]. Loss: 0.13967. Acc: 0.912. Test loss: 0.17705. Test acc: 0.933\n",
      "Epoch [315/1000]. Step [1/33]. Loss: 0.13678. Acc: 0.920. Test loss: 0.10953. Test acc: 0.933\n",
      "Epoch [316/1000]. Step [1/33]. Loss: 0.14513. Acc: 0.895. Test loss: 0.10911. Test acc: 0.933\n",
      "Epoch [317/1000]. Step [1/33]. Loss: 0.14827. Acc: 0.885. Test loss: 0.10929. Test acc: 0.933\n",
      "Epoch [318/1000]. Step [1/33]. Loss: 0.14345. Acc: 0.898. Test loss: 0.10879. Test acc: 0.933\n",
      "Epoch [319/1000]. Step [1/33]. Loss: 0.13594. Acc: 0.920. Test loss: 0.17656. Test acc: 0.933\n",
      "Epoch [320/1000]. Step [1/33]. Loss: 0.14111. Acc: 0.904. Test loss: 0.10854. Test acc: 0.933\n",
      "Epoch [321/1000]. Step [1/33]. Loss: 0.14553. Acc: 0.891. Test loss: 0.17657. Test acc: 0.933\n",
      "Epoch [322/1000]. Step [1/33]. Loss: 0.14268. Acc: 0.898. Test loss: 0.10743. Test acc: 0.933\n",
      "Epoch [323/1000]. Step [1/33]. Loss: 0.14520. Acc: 0.891. Test loss: 0.17589. Test acc: 0.933\n",
      "Epoch [324/1000]. Step [1/33]. Loss: 0.14500. Acc: 0.891. Test loss: 0.24531. Test acc: 0.933\n",
      "Epoch [325/1000]. Step [1/33]. Loss: 0.13739. Acc: 0.912. Test loss: 0.10670. Test acc: 0.933\n",
      "Epoch [326/1000]. Step [1/33]. Loss: 0.14055. Acc: 0.902. Test loss: 0.17567. Test acc: 0.933\n",
      "Epoch [327/1000]. Step [1/33]. Loss: 0.14447. Acc: 0.891. Test loss: 0.17602. Test acc: 0.933\n",
      "Epoch [328/1000]. Step [1/33]. Loss: 0.13753. Acc: 0.910. Test loss: 0.10566. Test acc: 0.933\n",
      "Epoch [329/1000]. Step [1/33]. Loss: 0.14681. Acc: 0.883. Test loss: 0.10614. Test acc: 0.933\n",
      "Epoch [330/1000]. Step [1/33]. Loss: 0.13978. Acc: 0.902. Test loss: 0.10599. Test acc: 0.933\n",
      "Epoch [331/1000]. Step [1/33]. Loss: 0.13694. Acc: 0.910. Test loss: 0.10557. Test acc: 0.933\n",
      "Epoch [332/1000]. Step [1/33]. Loss: 0.13325. Acc: 0.920. Test loss: 0.10482. Test acc: 0.933\n",
      "Epoch [333/1000]. Step [1/33]. Loss: 0.14130. Acc: 0.896. Test loss: 0.17582. Test acc: 0.933\n",
      "Epoch [334/1000]. Step [1/33]. Loss: 0.14112. Acc: 0.896. Test loss: 0.17431. Test acc: 0.933\n",
      "Epoch [335/1000]. Step [1/33]. Loss: 0.14645. Acc: 0.881. Test loss: 0.10408. Test acc: 0.933\n",
      "Epoch [336/1000]. Step [1/33]. Loss: 0.13735. Acc: 0.906. Test loss: 0.10361. Test acc: 0.933\n",
      "Epoch [337/1000]. Step [1/33]. Loss: 0.13713. Acc: 0.906. Test loss: 0.10332. Test acc: 0.933\n",
      "Epoch [338/1000]. Step [1/33]. Loss: 0.13831. Acc: 0.902. Test loss: 0.17531. Test acc: 0.933\n",
      "Epoch [339/1000]. Step [1/33]. Loss: 0.14094. Acc: 0.895. Test loss: 0.10288. Test acc: 0.933\n",
      "Epoch [340/1000]. Step [1/33]. Loss: 0.12744. Acc: 0.932. Test loss: 0.17405. Test acc: 0.933\n",
      "Epoch [341/1000]. Step [1/33]. Loss: 0.13705. Acc: 0.904. Test loss: 0.10244. Test acc: 0.933\n",
      "Epoch [342/1000]. Step [1/33]. Loss: 0.13269. Acc: 0.916. Test loss: 0.10188. Test acc: 0.933\n",
      "Epoch [343/1000]. Step [1/33]. Loss: 0.13459. Acc: 0.910. Test loss: 0.10138. Test acc: 0.933\n",
      "Epoch [344/1000]. Step [1/33]. Loss: 0.14352. Acc: 0.885. Test loss: 0.10151. Test acc: 0.933\n",
      "Epoch [345/1000]. Step [1/33]. Loss: 0.13913. Acc: 0.896. Test loss: 0.10130. Test acc: 0.933\n",
      "Epoch [346/1000]. Step [1/33]. Loss: 0.13324. Acc: 0.912. Test loss: 0.10135. Test acc: 0.933\n",
      "Epoch [347/1000]. Step [1/33]. Loss: 0.14307. Acc: 0.885. Test loss: 0.10054. Test acc: 0.933\n",
      "Epoch [348/1000]. Step [1/33]. Loss: 0.12792. Acc: 0.926. Test loss: 0.10061. Test acc: 0.933\n",
      "Epoch [349/1000]. Step [1/33]. Loss: 0.13702. Acc: 0.900. Test loss: 0.09974. Test acc: 0.933\n",
      "Epoch [350/1000]. Step [1/33]. Loss: 0.14326. Acc: 0.883. Test loss: 0.17352. Test acc: 0.933\n",
      "Epoch [351/1000]. Step [1/33]. Loss: 0.13952. Acc: 0.893. Test loss: 0.09988. Test acc: 0.933\n",
      "Epoch [352/1000]. Step [1/33]. Loss: 0.13289. Acc: 0.910. Test loss: 0.09939. Test acc: 0.933\n",
      "Epoch [353/1000]. Step [1/33]. Loss: 0.13339. Acc: 0.908. Test loss: 0.09934. Test acc: 0.933\n",
      "Epoch [354/1000]. Step [1/33]. Loss: 0.13680. Acc: 0.898. Test loss: 0.09907. Test acc: 0.933\n",
      "Epoch [355/1000]. Step [1/33]. Loss: 0.14242. Acc: 0.883. Test loss: 0.09852. Test acc: 0.933\n",
      "Epoch [356/1000]. Step [1/33]. Loss: 0.13069. Acc: 0.914. Test loss: 0.17311. Test acc: 0.933\n",
      "Epoch [357/1000]. Step [1/33]. Loss: 0.13564. Acc: 0.900. Test loss: 0.09841. Test acc: 0.933\n",
      "Epoch [358/1000]. Step [1/33]. Loss: 0.13833. Acc: 0.893. Test loss: 0.09750. Test acc: 0.933\n",
      "Epoch [359/1000]. Step [1/33]. Loss: 0.13818. Acc: 0.893. Test loss: 0.09790. Test acc: 0.933\n",
      "Epoch [360/1000]. Step [1/33]. Loss: 0.13658. Acc: 0.896. Test loss: 0.09797. Test acc: 0.933\n",
      "Epoch [361/1000]. Step [1/33]. Loss: 0.13265. Acc: 0.906. Test loss: 0.24823. Test acc: 0.933\n",
      "Epoch [362/1000]. Step [1/33]. Loss: 0.13032. Acc: 0.912. Test loss: 0.09630. Test acc: 0.933\n",
      "Epoch [363/1000]. Step [1/33]. Loss: 0.12643. Acc: 0.922. Test loss: 0.24776. Test acc: 0.933\n",
      "Epoch [364/1000]. Step [1/33]. Loss: 0.13433. Acc: 0.900. Test loss: 0.09696. Test acc: 0.933\n",
      "Epoch [365/1000]. Step [1/33]. Loss: 0.13347. Acc: 0.902. Test loss: 0.09678. Test acc: 0.933\n",
      "Epoch [366/1000]. Step [1/33]. Loss: 0.13330. Acc: 0.902. Test loss: 0.09596. Test acc: 0.933\n",
      "Epoch [367/1000]. Step [1/33]. Loss: 0.13381. Acc: 0.900. Test loss: 0.09533. Test acc: 0.933\n",
      "Epoch [368/1000]. Step [1/33]. Loss: 0.13967. Acc: 0.885. Test loss: 0.09566. Test acc: 0.933\n",
      "Epoch [369/1000]. Step [1/33]. Loss: 0.12977. Acc: 0.910. Test loss: 0.24856. Test acc: 0.933\n",
      "Epoch [370/1000]. Step [1/33]. Loss: 0.12587. Acc: 0.920. Test loss: 0.17194. Test acc: 0.933\n",
      "Epoch [371/1000]. Step [1/33]. Loss: 0.13017. Acc: 0.908. Test loss: 0.09466. Test acc: 0.933\n",
      "Epoch [372/1000]. Step [1/33]. Loss: 0.13452. Acc: 0.896. Test loss: 0.09396. Test acc: 0.933\n",
      "Epoch [373/1000]. Step [1/33]. Loss: 0.13583. Acc: 0.893. Test loss: 0.17214. Test acc: 0.933\n",
      "Epoch [374/1000]. Step [1/33]. Loss: 0.13043. Acc: 0.906. Test loss: 0.17154. Test acc: 0.933\n",
      "Epoch [375/1000]. Step [1/33]. Loss: 0.13478. Acc: 0.895. Test loss: 0.17067. Test acc: 0.933\n",
      "Epoch [376/1000]. Step [1/33]. Loss: 0.12859. Acc: 0.910. Test loss: 0.09347. Test acc: 0.933\n",
      "Epoch [377/1000]. Step [1/33]. Loss: 0.13600. Acc: 0.891. Test loss: 0.09346. Test acc: 0.933\n",
      "Epoch [378/1000]. Step [1/33]. Loss: 0.12823. Acc: 0.910. Test loss: 0.09265. Test acc: 0.933\n",
      "Epoch [379/1000]. Step [1/33]. Loss: 0.12568. Acc: 0.916. Test loss: 0.17173. Test acc: 0.933\n",
      "Epoch [380/1000]. Step [1/33]. Loss: 0.13013. Acc: 0.904. Test loss: 0.09247. Test acc: 0.933\n",
      "Epoch [381/1000]. Step [1/33]. Loss: 0.13379. Acc: 0.895. Test loss: 0.09177. Test acc: 0.933\n",
      "Epoch [382/1000]. Step [1/33]. Loss: 0.13212. Acc: 0.898. Test loss: 0.09173. Test acc: 0.933\n",
      "Epoch [383/1000]. Step [1/33]. Loss: 0.13421. Acc: 0.893. Test loss: 0.09134. Test acc: 0.933\n",
      "Epoch [384/1000]. Step [1/33]. Loss: 0.12177. Acc: 0.924. Test loss: 0.09151. Test acc: 0.933\n",
      "Epoch [385/1000]. Step [1/33]. Loss: 0.12775. Acc: 0.908. Test loss: 0.09149. Test acc: 0.933\n",
      "Epoch [386/1000]. Step [1/33]. Loss: 0.12062. Acc: 0.926. Test loss: 0.09094. Test acc: 0.933\n",
      "Epoch [387/1000]. Step [1/33]. Loss: 0.13206. Acc: 0.896. Test loss: 0.09068. Test acc: 0.933\n",
      "Epoch [388/1000]. Step [1/33]. Loss: 0.13576. Acc: 0.887. Test loss: 0.16978. Test acc: 0.933\n",
      "Epoch [389/1000]. Step [1/33]. Loss: 0.13247. Acc: 0.895. Test loss: 0.17034. Test acc: 0.933\n",
      "Epoch [390/1000]. Step [1/33]. Loss: 0.12292. Acc: 0.918. Test loss: 0.17028. Test acc: 0.933\n",
      "Epoch [391/1000]. Step [1/33]. Loss: 0.11893. Acc: 0.928. Test loss: 0.09020. Test acc: 0.933\n",
      "Epoch [392/1000]. Step [1/33]. Loss: 0.12341. Acc: 0.916. Test loss: 0.16997. Test acc: 0.933\n",
      "Epoch [393/1000]. Step [1/33]. Loss: 0.12244. Acc: 0.918. Test loss: 0.08933. Test acc: 0.933\n",
      "Epoch [394/1000]. Step [1/33]. Loss: 0.12700. Acc: 0.906. Test loss: 0.08897. Test acc: 0.933\n",
      "Epoch [395/1000]. Step [1/33]. Loss: 0.12677. Acc: 0.906. Test loss: 0.08852. Test acc: 0.933\n",
      "Epoch [396/1000]. Step [1/33]. Loss: 0.14011. Acc: 0.873. Test loss: 0.08909. Test acc: 0.933\n",
      "Epoch [397/1000]. Step [1/33]. Loss: 0.13517. Acc: 0.885. Test loss: 0.08819. Test acc: 0.933\n",
      "Epoch [398/1000]. Step [1/33]. Loss: 0.13740. Acc: 0.879. Test loss: 0.08794. Test acc: 0.933\n",
      "Epoch [399/1000]. Step [1/33]. Loss: 0.12456. Acc: 0.910. Test loss: 0.08804. Test acc: 0.933\n",
      "Epoch [400/1000]. Step [1/33]. Loss: 0.12364. Acc: 0.912. Test loss: 0.16893. Test acc: 0.933\n",
      "Epoch [401/1000]. Step [1/33]. Loss: 0.12193. Acc: 0.916. Test loss: 0.08745. Test acc: 0.933\n",
      "Epoch [402/1000]. Step [1/33]. Loss: 0.13124. Acc: 0.893. Test loss: 0.08743. Test acc: 0.933\n",
      "Epoch [403/1000]. Step [1/33]. Loss: 0.12630. Acc: 0.904. Test loss: 0.08777. Test acc: 0.933\n",
      "Epoch [404/1000]. Step [1/33]. Loss: 0.12619. Acc: 0.904. Test loss: 0.08690. Test acc: 0.933\n",
      "Epoch [405/1000]. Step [1/33]. Loss: 0.12759. Acc: 0.900. Test loss: 0.08694. Test acc: 0.933\n",
      "Epoch [406/1000]. Step [1/33]. Loss: 0.12506. Acc: 0.906. Test loss: 0.08628. Test acc: 0.933\n",
      "Epoch [407/1000]. Step [1/33]. Loss: 0.12563. Acc: 0.904. Test loss: 0.08597. Test acc: 0.933\n",
      "Epoch [408/1000]. Step [1/33]. Loss: 0.12476. Acc: 0.906. Test loss: 0.08560. Test acc: 0.933\n",
      "Epoch [409/1000]. Step [1/33]. Loss: 0.13113. Acc: 0.891. Test loss: 0.08508. Test acc: 0.933\n",
      "Epoch [410/1000]. Step [1/33]. Loss: 0.12359. Acc: 0.908. Test loss: 0.08508. Test acc: 0.933\n",
      "Epoch [411/1000]. Step [1/33]. Loss: 0.12584. Acc: 0.902. Test loss: 0.08492. Test acc: 0.933\n",
      "Epoch [412/1000]. Step [1/33]. Loss: 0.12824. Acc: 0.896. Test loss: 0.08417. Test acc: 0.933\n",
      "Epoch [413/1000]. Step [1/33]. Loss: 0.12398. Acc: 0.906. Test loss: 0.16862. Test acc: 0.933\n",
      "Epoch [414/1000]. Step [1/33]. Loss: 0.12462. Acc: 0.904. Test loss: 0.08391. Test acc: 0.933\n",
      "Epoch [415/1000]. Step [1/33]. Loss: 0.12529. Acc: 0.902. Test loss: 0.08394. Test acc: 0.933\n",
      "Epoch [416/1000]. Step [1/33]. Loss: 0.12185. Acc: 0.910. Test loss: 0.08346. Test acc: 0.933\n",
      "Epoch [417/1000]. Step [1/33]. Loss: 0.11918. Acc: 0.916. Test loss: 0.08332. Test acc: 0.933\n",
      "Epoch [418/1000]. Step [1/33]. Loss: 0.11903. Acc: 0.916. Test loss: 0.08331. Test acc: 0.933\n",
      "Epoch [419/1000]. Step [1/33]. Loss: 0.11223. Acc: 0.932. Test loss: 0.08310. Test acc: 0.933\n",
      "Epoch [420/1000]. Step [1/33]. Loss: 0.12112. Acc: 0.910. Test loss: 0.08288. Test acc: 0.933\n",
      "Epoch [421/1000]. Step [1/33]. Loss: 0.11602. Acc: 0.922. Test loss: 0.16750. Test acc: 0.933\n",
      "Epoch [422/1000]. Step [1/33]. Loss: 0.12257. Acc: 0.906. Test loss: 0.08225. Test acc: 0.933\n",
      "Epoch [423/1000]. Step [1/33]. Loss: 0.12146. Acc: 0.908. Test loss: 0.16727. Test acc: 0.933\n",
      "Epoch [424/1000]. Step [1/33]. Loss: 0.12551. Acc: 0.898. Test loss: 0.08244. Test acc: 0.933\n",
      "Epoch [425/1000]. Step [1/33]. Loss: 0.11872. Acc: 0.914. Test loss: 0.08107. Test acc: 0.933\n",
      "Epoch [426/1000]. Step [1/33]. Loss: 0.11597. Acc: 0.920. Test loss: 0.16756. Test acc: 0.933\n",
      "Epoch [427/1000]. Step [1/33]. Loss: 0.12339. Acc: 0.902. Test loss: 0.08106. Test acc: 0.933\n",
      "Epoch [428/1000]. Step [1/33]. Loss: 0.11319. Acc: 0.926. Test loss: 0.08124. Test acc: 0.933\n",
      "Epoch [429/1000]. Step [1/33]. Loss: 0.12213. Acc: 0.904. Test loss: 0.08091. Test acc: 0.933\n",
      "Epoch [430/1000]. Step [1/33]. Loss: 0.12035. Acc: 0.908. Test loss: 0.16762. Test acc: 0.933\n",
      "Epoch [431/1000]. Step [1/33]. Loss: 0.11180. Acc: 0.928. Test loss: 0.08018. Test acc: 0.933\n",
      "Epoch [432/1000]. Step [1/33]. Loss: 0.11584. Acc: 0.918. Test loss: 0.07949. Test acc: 0.933\n",
      "Epoch [433/1000]. Step [1/33]. Loss: 0.12669. Acc: 0.893. Test loss: 0.07964. Test acc: 0.933\n",
      "Epoch [434/1000]. Step [1/33]. Loss: 0.13169. Acc: 0.881. Test loss: 0.08016. Test acc: 0.933\n",
      "Epoch [435/1000]. Step [1/33]. Loss: 0.11878. Acc: 0.910. Test loss: 0.07922. Test acc: 0.933\n",
      "Epoch [436/1000]. Step [1/33]. Loss: 0.12629. Acc: 0.893. Test loss: 0.16575. Test acc: 0.933\n",
      "Epoch [437/1000]. Step [1/33]. Loss: 0.12099. Acc: 0.904. Test loss: 0.07878. Test acc: 0.933\n",
      "Epoch [438/1000]. Step [1/33]. Loss: 0.11920. Acc: 0.908. Test loss: 0.07859. Test acc: 0.933\n",
      "Epoch [439/1000]. Step [1/33]. Loss: 0.12236. Acc: 0.900. Test loss: 0.16707. Test acc: 0.933\n",
      "Epoch [440/1000]. Step [1/33]. Loss: 0.13092. Acc: 0.881. Test loss: 0.16553. Test acc: 0.933\n",
      "Epoch [441/1000]. Step [1/33]. Loss: 0.11446. Acc: 0.918. Test loss: 0.07799. Test acc: 0.933\n",
      "Epoch [442/1000]. Step [1/33]. Loss: 0.11160. Acc: 0.924. Test loss: 0.07748. Test acc: 0.933\n",
      "Epoch [443/1000]. Step [1/33]. Loss: 0.10981. Acc: 0.928. Test loss: 0.16579. Test acc: 0.933\n",
      "Epoch [444/1000]. Step [1/33]. Loss: 0.11045. Acc: 0.926. Test loss: 0.07672. Test acc: 0.933\n",
      "Epoch [445/1000]. Step [1/33]. Loss: 0.11722. Acc: 0.910. Test loss: 0.07785. Test acc: 0.933\n",
      "Epoch [446/1000]. Step [1/33]. Loss: 0.11957. Acc: 0.904. Test loss: 0.07665. Test acc: 0.933\n",
      "Epoch [447/1000]. Step [1/33]. Loss: 0.12564. Acc: 0.891. Test loss: 0.16612. Test acc: 0.933\n",
      "Epoch [448/1000]. Step [1/33]. Loss: 0.12285. Acc: 0.896. Test loss: 0.16655. Test acc: 0.933\n",
      "Epoch [449/1000]. Step [1/33]. Loss: 0.12270. Acc: 0.896. Test loss: 0.16617. Test acc: 0.933\n",
      "Epoch [450/1000]. Step [1/33]. Loss: 0.10514. Acc: 0.936. Test loss: 0.16579. Test acc: 0.933\n",
      "Epoch [451/1000]. Step [1/33]. Loss: 0.11288. Acc: 0.918. Test loss: 0.07700. Test acc: 0.933\n",
      "Epoch [452/1000]. Step [1/33]. Loss: 0.12411. Acc: 0.893. Test loss: 0.16540. Test acc: 0.933\n",
      "Epoch [453/1000]. Step [1/33]. Loss: 0.11596. Acc: 0.910. Test loss: 0.07505. Test acc: 0.933\n",
      "Epoch [454/1000]. Step [1/33]. Loss: 0.11934. Acc: 0.902. Test loss: 0.07481. Test acc: 0.933\n",
      "Epoch [455/1000]. Step [1/33]. Loss: 0.11305. Acc: 0.916. Test loss: 0.07489. Test acc: 0.933\n",
      "Epoch [456/1000]. Step [1/33]. Loss: 0.10940. Acc: 0.924. Test loss: 0.16601. Test acc: 0.933\n",
      "Epoch [457/1000]. Step [1/33]. Loss: 0.11446. Acc: 0.912. Test loss: 0.16527. Test acc: 0.933\n",
      "Epoch [458/1000]. Step [1/33]. Loss: 0.12590. Acc: 0.887. Test loss: 0.16494. Test acc: 0.933\n",
      "Epoch [459/1000]. Step [1/33]. Loss: 0.11335. Acc: 0.914. Test loss: 0.07316. Test acc: 0.933\n",
      "Epoch [460/1000]. Step [1/33]. Loss: 0.10511. Acc: 0.932. Test loss: 0.07382. Test acc: 0.933\n",
      "Epoch [461/1000]. Step [1/33]. Loss: 0.11386. Acc: 0.912. Test loss: 0.16510. Test acc: 0.933\n",
      "Epoch [462/1000]. Step [1/33]. Loss: 0.11823. Acc: 0.902. Test loss: 0.07337. Test acc: 0.933\n",
      "Epoch [463/1000]. Step [1/33]. Loss: 0.11811. Acc: 0.902. Test loss: 0.07317. Test acc: 0.933\n",
      "Epoch [464/1000]. Step [1/33]. Loss: 0.10262. Acc: 0.936. Test loss: 0.16470. Test acc: 0.933\n",
      "Epoch [465/1000]. Step [1/33]. Loss: 0.10785. Acc: 0.924. Test loss: 0.07260. Test acc: 0.933\n",
      "Epoch [466/1000]. Step [1/33]. Loss: 0.12575. Acc: 0.885. Test loss: 0.07276. Test acc: 0.933\n",
      "Epoch [467/1000]. Step [1/33]. Loss: 0.12472. Acc: 0.887. Test loss: 0.07296. Test acc: 0.933\n",
      "Epoch [468/1000]. Step [1/33]. Loss: 0.12644. Acc: 0.883. Test loss: 0.07199. Test acc: 0.933\n",
      "Epoch [469/1000]. Step [1/33]. Loss: 0.11454. Acc: 0.908. Test loss: 0.07114. Test acc: 0.933\n",
      "Epoch [470/1000]. Step [1/33]. Loss: 0.11805. Acc: 0.900. Test loss: 0.07101. Test acc: 0.933\n",
      "Epoch [471/1000]. Step [1/33]. Loss: 0.11612. Acc: 0.904. Test loss: 0.07125. Test acc: 0.933\n",
      "Epoch [472/1000]. Step [1/33]. Loss: 0.12145. Acc: 0.893. Test loss: 0.07134. Test acc: 0.933\n",
      "Epoch [473/1000]. Step [1/33]. Loss: 0.11584. Acc: 0.904. Test loss: 0.07115. Test acc: 0.933\n",
      "Epoch [474/1000]. Step [1/33]. Loss: 0.11111. Acc: 0.914. Test loss: 0.07009. Test acc: 0.933\n",
      "Epoch [475/1000]. Step [1/33]. Loss: 0.11838. Acc: 0.898. Test loss: 0.07029. Test acc: 0.933\n",
      "Epoch [476/1000]. Step [1/33]. Loss: 0.11722. Acc: 0.900. Test loss: 0.06986. Test acc: 0.933\n",
      "Epoch [477/1000]. Step [1/33]. Loss: 0.12172. Acc: 0.891. Test loss: 0.07173. Test acc: 0.933\n",
      "Epoch [478/1000]. Step [1/33]. Loss: 0.11421. Acc: 0.906. Test loss: 0.16420. Test acc: 0.933\n",
      "Epoch [479/1000]. Step [1/33]. Loss: 0.11428. Acc: 0.906. Test loss: 0.06930. Test acc: 0.933\n",
      "Epoch [480/1000]. Step [1/33]. Loss: 0.11954. Acc: 0.895. Test loss: 0.06979. Test acc: 0.933\n",
      "Epoch [481/1000]. Step [1/33]. Loss: 0.12682. Acc: 0.879. Test loss: 0.06945. Test acc: 0.933\n",
      "Epoch [482/1000]. Step [1/33]. Loss: 0.11938. Acc: 0.895. Test loss: 0.25871. Test acc: 0.933\n",
      "Epoch [483/1000]. Step [1/33]. Loss: 0.11727. Acc: 0.898. Test loss: 0.06884. Test acc: 0.933\n",
      "Epoch [484/1000]. Step [1/33]. Loss: 0.10705. Acc: 0.920. Test loss: 0.06959. Test acc: 0.933\n",
      "Epoch [485/1000]. Step [1/33]. Loss: 0.10868. Acc: 0.916. Test loss: 0.06819. Test acc: 0.933\n",
      "Epoch [486/1000]. Step [1/33]. Loss: 0.10765. Acc: 0.918. Test loss: 0.06837. Test acc: 0.933\n",
      "Epoch [487/1000]. Step [1/33]. Loss: 0.11965. Acc: 0.893. Test loss: 0.16410. Test acc: 0.933\n",
      "Epoch [488/1000]. Step [1/33]. Loss: 0.11854. Acc: 0.895. Test loss: 0.06819. Test acc: 0.933\n",
      "Epoch [489/1000]. Step [1/33]. Loss: 0.12227. Acc: 0.887. Test loss: 0.16327. Test acc: 0.933\n",
      "Epoch [490/1000]. Step [1/33]. Loss: 0.10903. Acc: 0.914. Test loss: 0.06793. Test acc: 0.933\n",
      "Epoch [491/1000]. Step [1/33]. Loss: 0.10703. Acc: 0.918. Test loss: 0.06726. Test acc: 0.933\n",
      "Epoch [492/1000]. Step [1/33]. Loss: 0.10950. Acc: 0.912. Test loss: 0.06702. Test acc: 0.933\n",
      "Epoch [493/1000]. Step [1/33]. Loss: 0.11420. Acc: 0.902. Test loss: 0.06663. Test acc: 0.933\n",
      "Epoch [494/1000]. Step [1/33]. Loss: 0.12069. Acc: 0.889. Test loss: 0.06702. Test acc: 0.933\n",
      "Epoch [495/1000]. Step [1/33]. Loss: 0.10639. Acc: 0.918. Test loss: 0.16420. Test acc: 0.933\n",
      "Epoch [496/1000]. Step [1/33]. Loss: 0.11386. Acc: 0.902. Test loss: 0.16375. Test acc: 0.933\n",
      "Epoch [497/1000]. Step [1/33]. Loss: 0.11750. Acc: 0.895. Test loss: 0.06586. Test acc: 0.933\n",
      "Epoch [498/1000]. Step [1/33]. Loss: 0.10416. Acc: 0.922. Test loss: 0.06601. Test acc: 0.933\n",
      "Epoch [499/1000]. Step [1/33]. Loss: 0.10296. Acc: 0.924. Test loss: 0.26127. Test acc: 0.933\n",
      "Epoch [500/1000]. Step [1/33]. Loss: 0.10953. Acc: 0.910. Test loss: 0.06476. Test acc: 0.933\n",
      "Epoch [501/1000]. Step [1/33]. Loss: 0.12292. Acc: 0.883. Test loss: 0.06572. Test acc: 0.933\n",
      "Epoch [502/1000]. Step [1/33]. Loss: 0.10922. Acc: 0.910. Test loss: 0.06462. Test acc: 0.933\n",
      "Epoch [503/1000]. Step [1/33]. Loss: 0.10043. Acc: 0.928. Test loss: 0.06477. Test acc: 0.933\n",
      "Epoch [504/1000]. Step [1/33]. Loss: 0.10314. Acc: 0.922. Test loss: 0.06439. Test acc: 0.933\n",
      "Epoch [505/1000]. Step [1/33]. Loss: 0.11173. Acc: 0.904. Test loss: 0.06521. Test acc: 0.933\n",
      "Epoch [506/1000]. Step [1/33]. Loss: 0.12593. Acc: 0.875. Test loss: 0.06463. Test acc: 0.933\n",
      "Epoch [507/1000]. Step [1/33]. Loss: 0.11424. Acc: 0.898. Test loss: 0.06399. Test acc: 0.933\n",
      "Epoch [508/1000]. Step [1/33]. Loss: 0.11231. Acc: 0.902. Test loss: 0.06325. Test acc: 0.933\n",
      "Epoch [509/1000]. Step [1/33]. Loss: 0.11126. Acc: 0.904. Test loss: 0.16334. Test acc: 0.933\n",
      "Epoch [510/1000]. Step [1/33]. Loss: 0.12088. Acc: 0.885. Test loss: 0.16249. Test acc: 0.933\n",
      "Epoch [511/1000]. Step [1/33]. Loss: 0.11678. Acc: 0.893. Test loss: 0.06272. Test acc: 0.933\n",
      "Epoch [512/1000]. Step [1/33]. Loss: 0.10508. Acc: 0.916. Test loss: 0.06293. Test acc: 0.933\n",
      "Epoch [513/1000]. Step [1/33]. Loss: 0.11954. Acc: 0.887. Test loss: 0.06313. Test acc: 0.933\n",
      "Epoch [514/1000]. Step [1/33]. Loss: 0.13405. Acc: 0.857. Test loss: 0.06323. Test acc: 0.933\n",
      "Epoch [515/1000]. Step [1/33]. Loss: 0.10759. Acc: 0.910. Test loss: 0.06219. Test acc: 0.933\n",
      "Epoch [516/1000]. Step [1/33]. Loss: 0.11334. Acc: 0.898. Test loss: 0.06364. Test acc: 0.933\n",
      "Epoch [517/1000]. Step [1/33]. Loss: 0.11035. Acc: 0.904. Test loss: 0.06246. Test acc: 0.933\n",
      "Epoch [518/1000]. Step [1/33]. Loss: 0.10246. Acc: 0.920. Test loss: 0.16217. Test acc: 0.933\n",
      "Epoch [519/1000]. Step [1/33]. Loss: 0.10118. Acc: 0.922. Test loss: 0.06128. Test acc: 0.933\n",
      "Epoch [520/1000]. Step [1/33]. Loss: 0.11782. Acc: 0.889. Test loss: 0.06132. Test acc: 0.933\n",
      "Epoch [521/1000]. Step [1/33]. Loss: 0.10302. Acc: 0.918. Test loss: 0.06213. Test acc: 0.933\n",
      "Epoch [522/1000]. Step [1/33]. Loss: 0.10680. Acc: 0.910. Test loss: 0.16316. Test acc: 0.933\n",
      "Epoch [523/1000]. Step [1/33]. Loss: 0.10764. Acc: 0.908. Test loss: 0.16187. Test acc: 0.933\n",
      "Epoch [524/1000]. Step [1/33]. Loss: 0.10253. Acc: 0.918. Test loss: 0.06073. Test acc: 0.933\n",
      "Epoch [525/1000]. Step [1/33]. Loss: 0.11128. Acc: 0.900. Test loss: 0.06042. Test acc: 0.933\n",
      "Epoch [526/1000]. Step [1/33]. Loss: 0.10725. Acc: 0.908. Test loss: 0.06047. Test acc: 0.933\n",
      "Epoch [527/1000]. Step [1/33]. Loss: 0.10722. Acc: 0.908. Test loss: 0.06070. Test acc: 0.933\n",
      "Epoch [528/1000]. Step [1/33]. Loss: 0.10989. Acc: 0.902. Test loss: 0.05932. Test acc: 0.933\n",
      "Epoch [529/1000]. Step [1/33]. Loss: 0.11495. Acc: 0.893. Test loss: 0.06047. Test acc: 0.933\n",
      "Epoch [530/1000]. Step [1/33]. Loss: 0.10276. Acc: 0.916. Test loss: 0.05927. Test acc: 0.933\n",
      "Epoch [531/1000]. Step [1/33]. Loss: 0.10366. Acc: 0.914. Test loss: 0.05950. Test acc: 0.933\n",
      "Epoch [532/1000]. Step [1/33]. Loss: 0.11169. Acc: 0.898. Test loss: 0.05917. Test acc: 0.933\n",
      "Epoch [533/1000]. Step [1/33]. Loss: 0.10248. Acc: 0.916. Test loss: 0.16172. Test acc: 0.933\n",
      "Epoch [534/1000]. Step [1/33]. Loss: 0.10928. Acc: 0.902. Test loss: 0.05901. Test acc: 0.933\n",
      "Epoch [535/1000]. Step [1/33]. Loss: 0.10727. Acc: 0.906. Test loss: 0.05855. Test acc: 0.933\n",
      "Epoch [536/1000]. Step [1/33]. Loss: 0.12020. Acc: 0.881. Test loss: 0.05849. Test acc: 0.933\n",
      "Epoch [537/1000]. Step [1/33]. Loss: 0.10399. Acc: 0.912. Test loss: 0.05816. Test acc: 0.933\n",
      "Epoch [538/1000]. Step [1/33]. Loss: 0.10871. Acc: 0.902. Test loss: 0.05926. Test acc: 0.933\n",
      "Epoch [539/1000]. Step [1/33]. Loss: 0.11072. Acc: 0.898. Test loss: 0.05826. Test acc: 0.933\n",
      "Epoch [540/1000]. Step [1/33]. Loss: 0.10770. Acc: 0.904. Test loss: 0.05750. Test acc: 0.933\n",
      "Epoch [541/1000]. Step [1/33]. Loss: 0.10639. Acc: 0.906. Test loss: 0.16232. Test acc: 0.933\n",
      "Epoch [542/1000]. Step [1/33]. Loss: 0.10121. Acc: 0.916. Test loss: 0.05711. Test acc: 0.933\n",
      "Epoch [543/1000]. Step [1/33]. Loss: 0.10832. Acc: 0.902. Test loss: 0.16131. Test acc: 0.933\n",
      "Epoch [544/1000]. Step [1/33]. Loss: 0.11021. Acc: 0.898. Test loss: 0.05729. Test acc: 0.933\n",
      "Epoch [545/1000]. Step [1/33]. Loss: 0.11417. Acc: 0.891. Test loss: 0.05704. Test acc: 0.933\n",
      "Epoch [546/1000]. Step [1/33]. Loss: 0.10083. Acc: 0.916. Test loss: 0.05746. Test acc: 0.933\n",
      "Epoch [547/1000]. Step [1/33]. Loss: 0.09562. Acc: 0.926. Test loss: 0.16292. Test acc: 0.933\n",
      "Epoch [548/1000]. Step [1/33]. Loss: 0.10064. Acc: 0.916. Test loss: 0.05598. Test acc: 0.933\n",
      "Epoch [549/1000]. Step [1/33]. Loss: 0.10238. Acc: 0.912. Test loss: 0.05625. Test acc: 0.933\n",
      "Epoch [550/1000]. Step [1/33]. Loss: 0.10035. Acc: 0.916. Test loss: 0.05558. Test acc: 0.933\n",
      "Epoch [551/1000]. Step [1/33]. Loss: 0.09714. Acc: 0.922. Test loss: 0.05516. Test acc: 0.933\n",
      "Epoch [552/1000]. Step [1/33]. Loss: 0.11140. Acc: 0.895. Test loss: 0.05579. Test acc: 0.933\n",
      "Epoch [553/1000]. Step [1/33]. Loss: 0.10507. Acc: 0.906. Test loss: 0.16223. Test acc: 0.933\n",
      "Epoch [554/1000]. Step [1/33]. Loss: 0.10404. Acc: 0.908. Test loss: 0.05501. Test acc: 0.933\n",
      "Epoch [555/1000]. Step [1/33]. Loss: 0.10806. Acc: 0.900. Test loss: 0.05415. Test acc: 0.933\n",
      "Epoch [556/1000]. Step [1/33]. Loss: 0.11822. Acc: 0.881. Test loss: 0.16060. Test acc: 0.933\n",
      "Epoch [557/1000]. Step [1/33]. Loss: 0.11937. Acc: 0.879. Test loss: 0.16089. Test acc: 0.933\n",
      "Epoch [558/1000]. Step [1/33]. Loss: 0.10043. Acc: 0.914. Test loss: 0.05409. Test acc: 0.933\n",
      "Epoch [559/1000]. Step [1/33]. Loss: 0.11177. Acc: 0.893. Test loss: 0.05412. Test acc: 0.933\n",
      "Epoch [560/1000]. Step [1/33]. Loss: 0.10232. Acc: 0.910. Test loss: 0.16123. Test acc: 0.933\n",
      "Epoch [561/1000]. Step [1/33]. Loss: 0.10948. Acc: 0.896. Test loss: 0.05450. Test acc: 0.933\n",
      "Epoch [562/1000]. Step [1/33]. Loss: 0.10839. Acc: 0.898. Test loss: 0.05319. Test acc: 0.933\n",
      "Epoch [563/1000]. Step [1/33]. Loss: 0.11769. Acc: 0.881. Test loss: 0.05554. Test acc: 0.933\n",
      "Epoch [564/1000]. Step [1/33]. Loss: 0.10626. Acc: 0.902. Test loss: 0.05350. Test acc: 0.933\n",
      "Epoch [565/1000]. Step [1/33]. Loss: 0.10808. Acc: 0.898. Test loss: 0.16111. Test acc: 0.933\n",
      "Epoch [566/1000]. Step [1/33]. Loss: 0.10983. Acc: 0.895. Test loss: 0.05323. Test acc: 0.933\n",
      "Epoch [567/1000]. Step [1/33]. Loss: 0.09626. Acc: 0.920. Test loss: 0.05264. Test acc: 0.933\n",
      "Epoch [568/1000]. Step [1/33]. Loss: 0.11533. Acc: 0.885. Test loss: 0.05221. Test acc: 0.933\n",
      "Epoch [569/1000]. Step [1/33]. Loss: 0.10355. Acc: 0.906. Test loss: 0.16159. Test acc: 0.933\n",
      "Epoch [570/1000]. Step [1/33]. Loss: 0.09909. Acc: 0.914. Test loss: 0.16139. Test acc: 0.933\n",
      "Epoch [571/1000]. Step [1/33]. Loss: 0.09694. Acc: 0.918. Test loss: 0.05292. Test acc: 0.933\n",
      "Epoch [572/1000]. Step [1/33]. Loss: 0.10537. Acc: 0.902. Test loss: 0.16144. Test acc: 0.933\n",
      "Epoch [573/1000]. Step [1/33]. Loss: 0.11061. Acc: 0.893. Test loss: 0.05141. Test acc: 0.933\n",
      "Epoch [574/1000]. Step [1/33]. Loss: 0.10508. Acc: 0.902. Test loss: 0.05106. Test acc: 0.933\n",
      "Epoch [575/1000]. Step [1/33]. Loss: 0.10292. Acc: 0.906. Test loss: 0.16030. Test acc: 0.933\n",
      "Epoch [576/1000]. Step [1/33]. Loss: 0.09950. Acc: 0.912. Test loss: 0.16148. Test acc: 0.933\n",
      "Epoch [577/1000]. Step [1/33]. Loss: 0.09949. Acc: 0.912. Test loss: 0.05031. Test acc: 0.933\n",
      "Epoch [578/1000]. Step [1/33]. Loss: 0.09725. Acc: 0.916. Test loss: 0.16004. Test acc: 0.933\n",
      "Epoch [579/1000]. Step [1/33]. Loss: 0.09398. Acc: 0.922. Test loss: 0.05126. Test acc: 0.933\n",
      "Epoch [580/1000]. Step [1/33]. Loss: 0.09380. Acc: 0.922. Test loss: 0.05162. Test acc: 0.933\n",
      "Epoch [581/1000]. Step [1/33]. Loss: 0.11191. Acc: 0.889. Test loss: 0.04973. Test acc: 0.933\n",
      "Epoch [582/1000]. Step [1/33]. Loss: 0.10439. Acc: 0.902. Test loss: 0.05069. Test acc: 0.933\n",
      "Epoch [583/1000]. Step [1/33]. Loss: 0.10951. Acc: 0.893. Test loss: 0.05027. Test acc: 0.933\n",
      "Epoch [584/1000]. Step [1/33]. Loss: 0.10307. Acc: 0.904. Test loss: 0.16089. Test acc: 0.933\n",
      "Epoch [585/1000]. Step [1/33]. Loss: 0.10392. Acc: 0.902. Test loss: 0.04858. Test acc: 0.933\n",
      "Epoch [586/1000]. Step [1/33]. Loss: 0.10606. Acc: 0.898. Test loss: 0.05024. Test acc: 0.933\n",
      "Epoch [587/1000]. Step [1/33]. Loss: 0.11138. Acc: 0.889. Test loss: 0.16184. Test acc: 0.933\n",
      "Epoch [588/1000]. Step [1/33]. Loss: 0.09931. Acc: 0.910. Test loss: 0.16115. Test acc: 0.933\n",
      "Epoch [589/1000]. Step [1/33]. Loss: 0.10248. Acc: 0.904. Test loss: 0.05058. Test acc: 0.933\n",
      "Epoch [590/1000]. Step [1/33]. Loss: 0.10025. Acc: 0.908. Test loss: 0.16064. Test acc: 0.933\n",
      "Epoch [591/1000]. Step [1/33]. Loss: 0.10669. Acc: 0.896. Test loss: 0.04899. Test acc: 0.933\n",
      "Epoch [592/1000]. Step [1/33]. Loss: 0.10450. Acc: 0.900. Test loss: 0.04840. Test acc: 0.933\n",
      "Epoch [593/1000]. Step [1/33]. Loss: 0.10230. Acc: 0.904. Test loss: 0.16140. Test acc: 0.933\n",
      "Epoch [594/1000]. Step [1/33]. Loss: 0.10654. Acc: 0.896. Test loss: 0.16060. Test acc: 0.933\n",
      "Epoch [595/1000]. Step [1/33]. Loss: 0.10646. Acc: 0.896. Test loss: 0.16119. Test acc: 0.933\n",
      "Epoch [596/1000]. Step [1/33]. Loss: 0.09202. Acc: 0.922. Test loss: 0.04716. Test acc: 0.933\n",
      "Epoch [597/1000]. Step [1/33]. Loss: 0.09624. Acc: 0.914. Test loss: 0.16051. Test acc: 0.933\n",
      "Epoch [598/1000]. Step [1/33]. Loss: 0.09076. Acc: 0.924. Test loss: 0.15622. Test acc: 0.933\n",
      "Epoch [599/1000]. Step [1/33]. Loss: 0.10486. Acc: 0.898. Test loss: 0.04760. Test acc: 0.933\n",
      "Epoch [600/1000]. Step [1/33]. Loss: 0.08927. Acc: 0.926. Test loss: 0.04681. Test acc: 0.933\n",
      "Epoch [601/1000]. Step [1/33]. Loss: 0.11358. Acc: 0.883. Test loss: 0.04699. Test acc: 0.933\n",
      "Epoch [602/1000]. Step [1/33]. Loss: 0.10251. Acc: 0.902. Test loss: 0.04738. Test acc: 0.933\n",
      "Epoch [603/1000]. Step [1/33]. Loss: 0.09686. Acc: 0.912. Test loss: 0.04593. Test acc: 0.933\n",
      "Epoch [604/1000]. Step [1/33]. Loss: 0.09009. Acc: 0.924. Test loss: 0.16034. Test acc: 0.933\n",
      "Epoch [605/1000]. Step [1/33]. Loss: 0.09661. Acc: 0.912. Test loss: 0.04622. Test acc: 0.933\n",
      "Epoch [606/1000]. Step [1/33]. Loss: 0.10549. Acc: 0.896. Test loss: 0.04549. Test acc: 0.933\n",
      "Epoch [607/1000]. Step [1/33]. Loss: 0.09177. Acc: 0.920. Test loss: 0.04627. Test acc: 0.933\n",
      "Epoch [608/1000]. Step [1/33]. Loss: 0.10427. Acc: 0.898. Test loss: 0.04646. Test acc: 0.933\n",
      "Epoch [609/1000]. Step [1/33]. Loss: 0.10060. Acc: 0.904. Test loss: 0.04505. Test acc: 0.933\n",
      "Epoch [610/1000]. Step [1/33]. Loss: 0.10064. Acc: 0.904. Test loss: 0.27541. Test acc: 0.933\n",
      "Epoch [611/1000]. Step [1/33]. Loss: 0.10841. Acc: 0.891. Test loss: 0.04565. Test acc: 0.933\n",
      "Epoch [612/1000]. Step [1/33]. Loss: 0.09485. Acc: 0.914. Test loss: 0.16085. Test acc: 0.933\n",
      "Epoch [613/1000]. Step [1/33]. Loss: 0.09377. Acc: 0.916. Test loss: 0.04549. Test acc: 0.933\n",
      "Epoch [614/1000]. Step [1/33]. Loss: 0.10592. Acc: 0.895. Test loss: 0.04549. Test acc: 0.933\n",
      "Epoch [615/1000]. Step [1/33]. Loss: 0.10021. Acc: 0.904. Test loss: 0.04501. Test acc: 0.933\n",
      "Epoch [616/1000]. Step [1/33]. Loss: 0.10902. Acc: 0.889. Test loss: 0.04466. Test acc: 0.933\n",
      "Epoch [617/1000]. Step [1/33]. Loss: 0.09901. Acc: 0.906. Test loss: 0.04381. Test acc: 0.933\n",
      "Epoch [618/1000]. Step [1/33]. Loss: 0.09646. Acc: 0.910. Test loss: 0.04481. Test acc: 0.933\n",
      "Epoch [619/1000]. Step [1/33]. Loss: 0.09759. Acc: 0.908. Test loss: 0.04382. Test acc: 0.933\n",
      "Epoch [620/1000]. Step [1/33]. Loss: 0.10191. Acc: 0.900. Test loss: 0.04377. Test acc: 0.933\n",
      "Epoch [621/1000]. Step [1/33]. Loss: 0.10313. Acc: 0.898. Test loss: 0.04545. Test acc: 0.933\n",
      "Epoch [622/1000]. Step [1/33]. Loss: 0.09504. Acc: 0.912. Test loss: 0.16104. Test acc: 0.933\n",
      "Epoch [623/1000]. Step [1/33]. Loss: 0.09828. Acc: 0.906. Test loss: 0.04388. Test acc: 0.933\n",
      "Epoch [624/1000]. Step [1/33]. Loss: 0.10611. Acc: 0.893. Test loss: 0.16045. Test acc: 0.933\n",
      "Epoch [625/1000]. Step [1/33]. Loss: 0.09936. Acc: 0.904. Test loss: 0.04271. Test acc: 0.933\n",
      "Epoch [626/1000]. Step [1/33]. Loss: 0.10600. Acc: 0.893. Test loss: 0.04402. Test acc: 0.933\n",
      "Epoch [627/1000]. Step [1/33]. Loss: 0.09911. Acc: 0.904. Test loss: 0.04304. Test acc: 0.933\n",
      "Epoch [628/1000]. Step [1/33]. Loss: 0.10917. Acc: 0.887. Test loss: 0.04178. Test acc: 0.933\n",
      "Epoch [629/1000]. Step [1/33]. Loss: 0.10356. Acc: 0.896. Test loss: 0.15978. Test acc: 0.933\n",
      "Epoch [630/1000]. Step [1/33]. Loss: 0.09771. Acc: 0.906. Test loss: 0.04263. Test acc: 0.933\n",
      "Epoch [631/1000]. Step [1/33]. Loss: 0.08979. Acc: 0.920. Test loss: 0.04237. Test acc: 0.933\n",
      "Epoch [632/1000]. Step [1/33]. Loss: 0.10442. Acc: 0.895. Test loss: 0.04163. Test acc: 0.933\n",
      "Epoch [633/1000]. Step [1/33]. Loss: 0.08714. Acc: 0.924. Test loss: 0.16127. Test acc: 0.933\n",
      "Epoch [634/1000]. Step [1/33]. Loss: 0.10680. Acc: 0.891. Test loss: 0.15994. Test acc: 0.933\n",
      "Epoch [635/1000]. Step [1/33]. Loss: 0.10200. Acc: 0.898. Test loss: 0.04077. Test acc: 0.933\n",
      "Epoch [636/1000]. Step [1/33]. Loss: 0.09264. Acc: 0.914. Test loss: 0.15974. Test acc: 0.933\n",
      "Epoch [637/1000]. Step [1/33]. Loss: 0.09937. Acc: 0.902. Test loss: 0.04084. Test acc: 0.933\n",
      "Epoch [638/1000]. Step [1/33]. Loss: 0.08779. Acc: 0.922. Test loss: 0.16076. Test acc: 0.933\n",
      "Epoch [639/1000]. Step [1/33]. Loss: 0.11681. Acc: 0.873. Test loss: 0.04196. Test acc: 0.933\n",
      "Epoch [640/1000]. Step [1/33]. Loss: 0.10274. Acc: 0.896. Test loss: 0.04119. Test acc: 0.933\n",
      "Epoch [641/1000]. Step [1/33]. Loss: 0.10728. Acc: 0.889. Test loss: 0.15953. Test acc: 0.933\n",
      "Epoch [642/1000]. Step [1/33]. Loss: 0.10154. Acc: 0.898. Test loss: 0.04110. Test acc: 0.933\n",
      "Epoch [643/1000]. Step [1/33]. Loss: 0.09550. Acc: 0.908. Test loss: 0.16186. Test acc: 0.933\n",
      "Epoch [644/1000]. Step [1/33]. Loss: 0.09766. Acc: 0.904. Test loss: 0.15991. Test acc: 0.933\n",
      "Epoch [645/1000]. Step [1/33]. Loss: 0.09995. Acc: 0.900. Test loss: 0.04144. Test acc: 0.933\n",
      "Epoch [646/1000]. Step [1/33]. Loss: 0.08237. Acc: 0.930. Test loss: 0.16011. Test acc: 0.933\n",
      "Epoch [647/1000]. Step [1/33]. Loss: 0.10689. Acc: 0.889. Test loss: 0.03952. Test acc: 0.933\n",
      "Epoch [648/1000]. Step [1/33]. Loss: 0.09385. Acc: 0.910. Test loss: 0.03893. Test acc: 0.933\n",
      "Epoch [649/1000]. Step [1/33]. Loss: 0.09975. Acc: 0.900. Test loss: 0.03903. Test acc: 0.933\n",
      "Epoch [650/1000]. Step [1/33]. Loss: 0.09387. Acc: 0.910. Test loss: 0.03911. Test acc: 0.933\n",
      "Epoch [651/1000]. Step [1/33]. Loss: 0.09732. Acc: 0.904. Test loss: 0.16122. Test acc: 0.933\n",
      "Epoch [652/1000]. Step [1/33]. Loss: 0.09814. Acc: 0.902. Test loss: 0.15993. Test acc: 0.933\n",
      "Epoch [653/1000]. Step [1/33]. Loss: 0.07470. Acc: 0.941. Test loss: 0.03982. Test acc: 0.933\n",
      "Epoch [654/1000]. Step [1/33]. Loss: 0.10780. Acc: 0.887. Test loss: 0.03814. Test acc: 0.933\n",
      "Epoch [655/1000]. Step [1/33]. Loss: 0.09559. Acc: 0.906. Test loss: 0.16029. Test acc: 0.933\n",
      "Epoch [656/1000]. Step [1/33]. Loss: 0.10049. Acc: 0.898. Test loss: 0.15945. Test acc: 0.933\n",
      "Epoch [657/1000]. Step [1/33]. Loss: 0.08962. Acc: 0.916. Test loss: 0.03839. Test acc: 0.933\n",
      "Epoch [658/1000]. Step [1/33]. Loss: 0.10028. Acc: 0.898. Test loss: 0.15969. Test acc: 0.933\n",
      "Epoch [659/1000]. Step [1/33]. Loss: 0.08810. Acc: 0.918. Test loss: 0.03797. Test acc: 0.933\n",
      "Epoch [660/1000]. Step [1/33]. Loss: 0.10392. Acc: 0.893. Test loss: 0.16019. Test acc: 0.933\n",
      "Epoch [661/1000]. Step [1/33]. Loss: 0.09295. Acc: 0.910. Test loss: 0.15739. Test acc: 0.933\n",
      "Epoch [662/1000]. Step [1/33]. Loss: 0.10249. Acc: 0.895. Test loss: 0.15991. Test acc: 0.933\n",
      "Epoch [663/1000]. Step [1/33]. Loss: 0.10589. Acc: 0.889. Test loss: 0.15918. Test acc: 0.933\n",
      "Epoch [664/1000]. Step [1/33]. Loss: 0.10959. Acc: 0.883. Test loss: 0.03745. Test acc: 0.933\n",
      "Epoch [665/1000]. Step [1/33]. Loss: 0.08677. Acc: 0.920. Test loss: 0.03718. Test acc: 0.933\n",
      "Epoch [666/1000]. Step [1/33]. Loss: 0.08641. Acc: 0.920. Test loss: 0.03708. Test acc: 0.933\n",
      "Epoch [667/1000]. Step [1/33]. Loss: 0.10211. Acc: 0.895. Test loss: 0.03747. Test acc: 0.933\n",
      "Epoch [668/1000]. Step [1/33]. Loss: 0.09615. Acc: 0.904. Test loss: 0.03748. Test acc: 0.933\n",
      "Epoch [669/1000]. Step [1/33]. Loss: 0.09122. Acc: 0.912. Test loss: 0.03922. Test acc: 0.933\n",
      "Epoch [670/1000]. Step [1/33]. Loss: 0.08763. Acc: 0.918. Test loss: 0.03714. Test acc: 0.933\n",
      "Epoch [671/1000]. Step [1/33]. Loss: 0.09809. Acc: 0.900. Test loss: 0.03855. Test acc: 0.933\n",
      "Epoch [672/1000]. Step [1/33]. Loss: 0.09941. Acc: 0.898. Test loss: 0.03692. Test acc: 0.933\n",
      "Epoch [673/1000]. Step [1/33]. Loss: 0.08850. Acc: 0.916. Test loss: 0.16065. Test acc: 0.933\n",
      "Epoch [674/1000]. Step [1/33]. Loss: 0.09560. Acc: 0.904. Test loss: 0.03607. Test acc: 0.933\n",
      "Epoch [675/1000]. Step [1/33]. Loss: 0.10400. Acc: 0.891. Test loss: 0.03589. Test acc: 0.933\n",
      "Epoch [676/1000]. Step [1/33]. Loss: 0.10032. Acc: 0.896. Test loss: 0.03675. Test acc: 0.933\n",
      "Epoch [677/1000]. Step [1/33]. Loss: 0.08806. Acc: 0.916. Test loss: 0.16212. Test acc: 0.933\n",
      "Epoch [678/1000]. Step [1/33]. Loss: 0.09525. Acc: 0.904. Test loss: 0.16246. Test acc: 0.933\n",
      "Epoch [679/1000]. Step [1/33]. Loss: 0.11470. Acc: 0.873. Test loss: 0.16102. Test acc: 0.933\n",
      "Epoch [680/1000]. Step [1/33]. Loss: 0.09144. Acc: 0.910. Test loss: 0.03518. Test acc: 0.933\n",
      "Epoch [681/1000]. Step [1/33]. Loss: 0.09029. Acc: 0.912. Test loss: 0.15915. Test acc: 0.933\n",
      "Epoch [682/1000]. Step [1/33]. Loss: 0.09885. Acc: 0.898. Test loss: 0.15983. Test acc: 0.933\n",
      "Epoch [683/1000]. Step [1/33]. Loss: 0.09614. Acc: 0.902. Test loss: 0.16064. Test acc: 0.933\n",
      "Epoch [684/1000]. Step [1/33]. Loss: 0.09123. Acc: 0.910. Test loss: 0.03521. Test acc: 0.933\n",
      "Epoch [685/1000]. Step [1/33]. Loss: 0.08126. Acc: 0.926. Test loss: 0.03318. Test acc: 0.933\n",
      "Epoch [686/1000]. Step [1/33]. Loss: 0.08965. Acc: 0.912. Test loss: 0.16072. Test acc: 0.933\n",
      "Epoch [687/1000]. Step [1/33]. Loss: 0.09597. Acc: 0.902. Test loss: 0.03321. Test acc: 0.933\n",
      "Epoch [688/1000]. Step [1/33]. Loss: 0.08815. Acc: 0.914. Test loss: 0.03374. Test acc: 0.933\n",
      "Epoch [689/1000]. Step [1/33]. Loss: 0.10184. Acc: 0.893. Test loss: 0.03362. Test acc: 0.933\n",
      "Epoch [690/1000]. Step [1/33]. Loss: 0.08719. Acc: 0.916. Test loss: 0.03603. Test acc: 0.933\n",
      "Epoch [691/1000]. Step [1/33]. Loss: 0.09337. Acc: 0.906. Test loss: 0.15988. Test acc: 0.933\n",
      "Epoch [692/1000]. Step [1/33]. Loss: 0.10272. Acc: 0.891. Test loss: 0.16188. Test acc: 0.933\n",
      "Epoch [693/1000]. Step [1/33]. Loss: 0.09298. Acc: 0.906. Test loss: 0.03369. Test acc: 0.933\n",
      "Epoch [694/1000]. Step [1/33]. Loss: 0.08175. Acc: 0.924. Test loss: 0.15974. Test acc: 0.933\n",
      "Epoch [695/1000]. Step [1/33]. Loss: 0.08933. Acc: 0.912. Test loss: 0.15778. Test acc: 0.933\n",
      "Epoch [696/1000]. Step [1/33]. Loss: 0.10660. Acc: 0.885. Test loss: 0.03269. Test acc: 0.933\n",
      "Epoch [697/1000]. Step [1/33]. Loss: 0.09799. Acc: 0.898. Test loss: 0.03398. Test acc: 0.933\n",
      "Epoch [698/1000]. Step [1/33]. Loss: 0.09416. Acc: 0.904. Test loss: 0.03355. Test acc: 0.933\n",
      "Epoch [699/1000]. Step [1/33]. Loss: 0.07674. Acc: 0.932. Test loss: 0.03420. Test acc: 0.933\n",
      "Epoch [700/1000]. Step [1/33]. Loss: 0.08771. Acc: 0.914. Test loss: 0.03202. Test acc: 0.933\n",
      "Epoch [701/1000]. Step [1/33]. Loss: 0.09126. Acc: 0.908. Test loss: 0.03208. Test acc: 0.933\n",
      "Epoch [702/1000]. Step [1/33]. Loss: 0.09871. Acc: 0.896. Test loss: 0.03490. Test acc: 0.933\n",
      "Epoch [703/1000]. Step [1/33]. Loss: 0.08132. Acc: 0.924. Test loss: 0.16053. Test acc: 0.933\n",
      "Epoch [704/1000]. Step [1/33]. Loss: 0.09000. Acc: 0.910. Test loss: 0.16037. Test acc: 0.933\n",
      "Epoch [705/1000]. Step [1/33]. Loss: 0.10865. Acc: 0.881. Test loss: 0.03160. Test acc: 0.933\n",
      "Epoch [706/1000]. Step [1/33]. Loss: 0.09746. Acc: 0.898. Test loss: 0.03146. Test acc: 0.933\n",
      "Epoch [707/1000]. Step [1/33]. Loss: 0.10099. Acc: 0.893. Test loss: 0.03134. Test acc: 0.933\n",
      "Epoch [708/1000]. Step [1/33]. Loss: 0.10498. Acc: 0.887. Test loss: 0.03243. Test acc: 0.933\n",
      "Epoch [709/1000]. Step [1/33]. Loss: 0.09857. Acc: 0.896. Test loss: 0.03062. Test acc: 0.933\n",
      "Epoch [710/1000]. Step [1/33]. Loss: 0.10718. Acc: 0.883. Test loss: 0.03062. Test acc: 0.933\n",
      "Epoch [711/1000]. Step [1/33]. Loss: 0.09198. Acc: 0.906. Test loss: 0.03203. Test acc: 0.933\n",
      "Epoch [712/1000]. Step [1/33]. Loss: 0.09557. Acc: 0.900. Test loss: 0.03124. Test acc: 0.933\n",
      "Epoch [713/1000]. Step [1/33]. Loss: 0.08817. Acc: 0.912. Test loss: 0.16056. Test acc: 0.933\n",
      "Epoch [714/1000]. Step [1/33]. Loss: 0.08673. Acc: 0.914. Test loss: 0.16007. Test acc: 0.933\n",
      "Epoch [715/1000]. Step [1/33]. Loss: 0.09065. Acc: 0.908. Test loss: 0.03100. Test acc: 0.933\n",
      "Epoch [716/1000]. Step [1/33]. Loss: 0.09560. Acc: 0.900. Test loss: 0.03199. Test acc: 0.933\n",
      "Epoch [717/1000]. Step [1/33]. Loss: 0.09083. Acc: 0.908. Test loss: 0.03083. Test acc: 0.933\n",
      "Epoch [718/1000]. Step [1/33]. Loss: 0.09301. Acc: 0.904. Test loss: 0.03269. Test acc: 0.933\n",
      "Epoch [719/1000]. Step [1/33]. Loss: 0.07765. Acc: 0.928. Test loss: 0.16272. Test acc: 0.933\n",
      "Epoch [720/1000]. Step [1/33]. Loss: 0.08770. Acc: 0.912. Test loss: 0.28560. Test acc: 0.933\n",
      "Epoch [721/1000]. Step [1/33]. Loss: 0.07484. Acc: 0.932. Test loss: 0.02965. Test acc: 0.933\n",
      "Epoch [722/1000]. Step [1/33]. Loss: 0.08002. Acc: 0.924. Test loss: 0.16055. Test acc: 0.933\n",
      "Epoch [723/1000]. Step [1/33]. Loss: 0.08758. Acc: 0.912. Test loss: 0.03277. Test acc: 0.933\n",
      "Epoch [724/1000]. Step [1/33]. Loss: 0.09269. Acc: 0.904. Test loss: 0.02923. Test acc: 0.933\n",
      "Epoch [725/1000]. Step [1/33]. Loss: 0.10414. Acc: 0.887. Test loss: 0.03093. Test acc: 0.933\n",
      "Epoch [726/1000]. Step [1/33]. Loss: 0.09651. Acc: 0.898. Test loss: 0.16015. Test acc: 0.933\n",
      "Epoch [727/1000]. Step [1/33]. Loss: 0.10026. Acc: 0.893. Test loss: 0.02839. Test acc: 0.933\n",
      "Epoch [728/1000]. Step [1/33]. Loss: 0.07945. Acc: 0.924. Test loss: 0.29431. Test acc: 0.933\n",
      "Epoch [729/1000]. Step [1/33]. Loss: 0.08697. Acc: 0.912. Test loss: 0.02963. Test acc: 0.933\n",
      "Epoch [730/1000]. Step [1/33]. Loss: 0.08045. Acc: 0.922. Test loss: 0.15977. Test acc: 0.933\n",
      "Epoch [731/1000]. Step [1/33]. Loss: 0.09098. Acc: 0.906. Test loss: 0.16216. Test acc: 0.933\n",
      "Epoch [732/1000]. Step [1/33]. Loss: 0.08959. Acc: 0.908. Test loss: 0.02808. Test acc: 0.933\n",
      "Epoch [733/1000]. Step [1/33]. Loss: 0.09336. Acc: 0.902. Test loss: 0.02915. Test acc: 0.933\n",
      "Epoch [734/1000]. Step [1/33]. Loss: 0.08856. Acc: 0.910. Test loss: 0.02871. Test acc: 0.933\n",
      "Epoch [735/1000]. Step [1/33]. Loss: 0.09855. Acc: 0.895. Test loss: 0.02771. Test acc: 0.933\n",
      "Epoch [736/1000]. Step [1/33]. Loss: 0.08294. Acc: 0.918. Test loss: 0.16174. Test acc: 0.933\n",
      "Epoch [737/1000]. Step [1/33]. Loss: 0.11287. Acc: 0.873. Test loss: 0.02956. Test acc: 0.933\n",
      "Epoch [738/1000]. Step [1/33]. Loss: 0.08663. Acc: 0.912. Test loss: 0.02783. Test acc: 0.933\n",
      "Epoch [739/1000]. Step [1/33]. Loss: 0.09305. Acc: 0.902. Test loss: 0.02805. Test acc: 0.933\n",
      "Epoch [740/1000]. Step [1/33]. Loss: 0.08154. Acc: 0.920. Test loss: 0.16130. Test acc: 0.933\n",
      "Epoch [741/1000]. Step [1/33]. Loss: 0.09680. Acc: 0.896. Test loss: 0.02809. Test acc: 0.933\n",
      "Epoch [742/1000]. Step [1/33]. Loss: 0.08387. Acc: 0.916. Test loss: 0.02660. Test acc: 0.933\n",
      "Epoch [743/1000]. Step [1/33]. Loss: 0.08144. Acc: 0.920. Test loss: 0.16007. Test acc: 0.933\n",
      "Epoch [744/1000]. Step [1/33]. Loss: 0.09974. Acc: 0.893. Test loss: 0.02626. Test acc: 0.933\n",
      "Epoch [745/1000]. Step [1/33]. Loss: 0.10760. Acc: 0.881. Test loss: 0.02700. Test acc: 0.933\n",
      "Epoch [746/1000]. Step [1/33]. Loss: 0.10204. Acc: 0.889. Test loss: 0.02622. Test acc: 0.933\n",
      "Epoch [747/1000]. Step [1/33]. Loss: 0.09702. Acc: 0.896. Test loss: 0.02674. Test acc: 0.933\n",
      "Epoch [748/1000]. Step [1/33]. Loss: 0.08234. Acc: 0.918. Test loss: 0.02644. Test acc: 0.933\n",
      "Epoch [749/1000]. Step [1/33]. Loss: 0.09144. Acc: 0.904. Test loss: 0.02761. Test acc: 0.933\n",
      "Epoch [750/1000]. Step [1/33]. Loss: 0.08751. Acc: 0.910. Test loss: 0.02694. Test acc: 0.933\n",
      "Epoch [751/1000]. Step [1/33]. Loss: 0.07954. Acc: 0.922. Test loss: 0.02609. Test acc: 0.933\n",
      "Epoch [752/1000]. Step [1/33]. Loss: 0.08324. Acc: 0.916. Test loss: 0.16264. Test acc: 0.933\n",
      "Epoch [753/1000]. Step [1/33]. Loss: 0.08756. Acc: 0.910. Test loss: 0.02694. Test acc: 0.933\n",
      "Epoch [754/1000]. Step [1/33]. Loss: 0.09515. Acc: 0.898. Test loss: 0.02723. Test acc: 0.933\n",
      "Epoch [755/1000]. Step [1/33]. Loss: 0.08981. Acc: 0.906. Test loss: 0.16587. Test acc: 0.933\n",
      "Epoch [756/1000]. Step [1/33]. Loss: 0.10032. Acc: 0.891. Test loss: 0.02688. Test acc: 0.933\n",
      "Epoch [757/1000]. Step [1/33]. Loss: 0.08726. Acc: 0.910. Test loss: 0.02547. Test acc: 0.933\n",
      "Epoch [758/1000]. Step [1/33]. Loss: 0.09922. Acc: 0.893. Test loss: 0.02625. Test acc: 0.933\n",
      "Epoch [759/1000]. Step [1/33]. Loss: 0.07526. Acc: 0.928. Test loss: 0.02622. Test acc: 0.933\n",
      "Epoch [760/1000]. Step [1/33]. Loss: 0.09365. Acc: 0.900. Test loss: 0.02797. Test acc: 0.933\n",
      "Epoch [761/1000]. Step [1/33]. Loss: 0.08306. Acc: 0.916. Test loss: 0.02777. Test acc: 0.933\n",
      "Epoch [762/1000]. Step [1/33]. Loss: 0.08562. Acc: 0.912. Test loss: 0.02629. Test acc: 0.933\n",
      "Epoch [763/1000]. Step [1/33]. Loss: 0.08830. Acc: 0.908. Test loss: 0.02488. Test acc: 0.933\n",
      "Epoch [764/1000]. Step [1/33]. Loss: 0.07630. Acc: 0.926. Test loss: 0.02628. Test acc: 0.933\n",
      "Epoch [765/1000]. Step [1/33]. Loss: 0.09096. Acc: 0.904. Test loss: 0.02501. Test acc: 0.933\n",
      "Epoch [766/1000]. Step [1/33]. Loss: 0.08263. Acc: 0.916. Test loss: 0.02502. Test acc: 0.933\n",
      "Epoch [767/1000]. Step [1/33]. Loss: 0.11070. Acc: 0.875. Test loss: 0.02487. Test acc: 0.933\n",
      "Epoch [768/1000]. Step [1/33]. Loss: 0.09177. Acc: 0.902. Test loss: 0.16166. Test acc: 0.933\n",
      "Epoch [769/1000]. Step [1/33]. Loss: 0.10265. Acc: 0.887. Test loss: 0.02425. Test acc: 0.933\n",
      "Epoch [770/1000]. Step [1/33]. Loss: 0.08537. Acc: 0.912. Test loss: 0.30204. Test acc: 0.933\n",
      "Epoch [771/1000]. Step [1/33]. Loss: 0.09990. Acc: 0.891. Test loss: 0.02508. Test acc: 0.933\n",
      "Epoch [772/1000]. Step [1/33]. Loss: 0.08531. Acc: 0.912. Test loss: 0.02586. Test acc: 0.933\n",
      "Epoch [773/1000]. Step [1/33]. Loss: 0.09728. Acc: 0.895. Test loss: 0.16201. Test acc: 0.933\n",
      "Epoch [774/1000]. Step [1/33]. Loss: 0.08526. Acc: 0.912. Test loss: 0.02431. Test acc: 0.933\n",
      "Epoch [775/1000]. Step [1/33]. Loss: 0.08778. Acc: 0.908. Test loss: 0.30261. Test acc: 0.933\n",
      "Epoch [776/1000]. Step [1/33]. Loss: 0.09727. Acc: 0.895. Test loss: 0.02529. Test acc: 0.933\n",
      "Epoch [777/1000]. Step [1/33]. Loss: 0.09716. Acc: 0.895. Test loss: 0.02430. Test acc: 0.933\n",
      "Epoch [778/1000]. Step [1/33]. Loss: 0.09318. Acc: 0.900. Test loss: 0.02377. Test acc: 0.933\n",
      "Epoch [779/1000]. Step [1/33]. Loss: 0.07829. Acc: 0.922. Test loss: 0.02421. Test acc: 0.933\n",
      "Epoch [780/1000]. Step [1/33]. Loss: 0.07938. Acc: 0.920. Test loss: 0.16182. Test acc: 0.933\n",
      "Epoch [781/1000]. Step [1/33]. Loss: 0.09159. Acc: 0.902. Test loss: 0.02539. Test acc: 0.933\n",
      "Epoch [782/1000]. Step [1/33]. Loss: 0.08905. Acc: 0.906. Test loss: 0.16190. Test acc: 0.933\n",
      "Epoch [783/1000]. Step [1/33]. Loss: 0.09024. Acc: 0.904. Test loss: 0.16341. Test acc: 0.933\n",
      "Epoch [784/1000]. Step [1/33]. Loss: 0.09409. Acc: 0.898. Test loss: 0.02311. Test acc: 0.933\n",
      "Epoch [785/1000]. Step [1/33]. Loss: 0.08214. Acc: 0.916. Test loss: 0.16103. Test acc: 0.933\n",
      "Epoch [786/1000]. Step [1/33]. Loss: 0.10922. Acc: 0.877. Test loss: 0.02395. Test acc: 0.933\n",
      "Epoch [787/1000]. Step [1/33]. Loss: 0.09385. Acc: 0.898. Test loss: 0.02522. Test acc: 0.933\n",
      "Epoch [788/1000]. Step [1/33]. Loss: 0.09804. Acc: 0.893. Test loss: 0.02269. Test acc: 0.933\n",
      "Epoch [789/1000]. Step [1/33]. Loss: 0.08190. Acc: 0.916. Test loss: 0.02683. Test acc: 0.933\n",
      "Epoch [790/1000]. Step [1/33]. Loss: 0.09810. Acc: 0.893. Test loss: 0.02361. Test acc: 0.933\n",
      "Epoch [791/1000]. Step [1/33]. Loss: 0.09949. Acc: 0.891. Test loss: 0.02489. Test acc: 0.933\n",
      "Epoch [792/1000]. Step [1/33]. Loss: 0.10126. Acc: 0.889. Test loss: 0.16361. Test acc: 0.933\n",
      "Epoch [793/1000]. Step [1/33]. Loss: 0.07757. Acc: 0.922. Test loss: 0.30279. Test acc: 0.933\n",
      "Epoch [794/1000]. Step [1/33]. Loss: 0.09695. Acc: 0.895. Test loss: 0.02296. Test acc: 0.933\n",
      "Epoch [795/1000]. Step [1/33]. Loss: 0.09926. Acc: 0.891. Test loss: 0.02310. Test acc: 0.933\n",
      "Epoch [796/1000]. Step [1/33]. Loss: 0.08850. Acc: 0.906. Test loss: 0.16317. Test acc: 0.933\n",
      "Epoch [797/1000]. Step [1/33]. Loss: 0.08562. Acc: 0.910. Test loss: 0.02312. Test acc: 0.933\n",
      "Epoch [798/1000]. Step [1/33]. Loss: 0.10602. Acc: 0.881. Test loss: 0.16364. Test acc: 0.933\n",
      "Epoch [799/1000]. Step [1/33]. Loss: 0.08425. Acc: 0.912. Test loss: 0.02296. Test acc: 0.933\n",
      "Epoch [800/1000]. Step [1/33]. Loss: 0.08015. Acc: 0.918. Test loss: 0.02336. Test acc: 0.933\n",
      "Epoch [801/1000]. Step [1/33]. Loss: 0.08552. Acc: 0.910. Test loss: 0.02186. Test acc: 0.933\n",
      "Epoch [802/1000]. Step [1/33]. Loss: 0.09526. Acc: 0.896. Test loss: 0.02288. Test acc: 0.933\n",
      "Epoch [803/1000]. Step [1/33]. Loss: 0.10766. Acc: 0.879. Test loss: 0.43723. Test acc: 0.933\n",
      "Epoch [804/1000]. Step [1/33]. Loss: 0.09392. Acc: 0.898. Test loss: 0.02323. Test acc: 0.933\n",
      "Epoch [805/1000]. Step [1/33]. Loss: 0.08277. Acc: 0.914. Test loss: 0.02230. Test acc: 0.933\n",
      "Epoch [806/1000]. Step [1/33]. Loss: 0.09356. Acc: 0.898. Test loss: 0.02133. Test acc: 0.933\n",
      "Epoch [807/1000]. Step [1/33]. Loss: 0.08277. Acc: 0.914. Test loss: 0.16217. Test acc: 0.933\n",
      "Epoch [808/1000]. Step [1/33]. Loss: 0.10335. Acc: 0.885. Test loss: 0.02212. Test acc: 0.933\n",
      "Epoch [809/1000]. Step [1/33]. Loss: 0.07989. Acc: 0.918. Test loss: 0.02173. Test acc: 0.933\n",
      "Epoch [810/1000]. Step [1/33]. Loss: 0.09073. Acc: 0.902. Test loss: 0.02122. Test acc: 0.933\n",
      "Epoch [811/1000]. Step [1/33]. Loss: 0.09454. Acc: 0.896. Test loss: 0.02214. Test acc: 0.933\n",
      "Epoch [812/1000]. Step [1/33]. Loss: 0.09639. Acc: 0.895. Test loss: 0.02107. Test acc: 0.933\n",
      "Epoch [813/1000]. Step [1/33]. Loss: 0.09250. Acc: 0.900. Test loss: 0.02176. Test acc: 0.933\n",
      "Epoch [814/1000]. Step [1/33]. Loss: 0.08940. Acc: 0.904. Test loss: 0.16274. Test acc: 0.933\n",
      "Epoch [815/1000]. Step [1/33]. Loss: 0.09808. Acc: 0.893. Test loss: 0.16467. Test acc: 0.933\n",
      "Epoch [816/1000]. Step [1/33]. Loss: 0.10023. Acc: 0.889. Test loss: 0.16088. Test acc: 0.933\n",
      "Epoch [817/1000]. Step [1/33]. Loss: 0.09772. Acc: 0.893. Test loss: 0.16485. Test acc: 0.933\n",
      "Epoch [818/1000]. Step [1/33]. Loss: 0.08529. Acc: 0.910. Test loss: 0.16361. Test acc: 0.933\n",
      "Epoch [819/1000]. Step [1/33]. Loss: 0.09098. Acc: 0.902. Test loss: 0.02163. Test acc: 0.933\n",
      "Epoch [820/1000]. Step [1/33]. Loss: 0.09750. Acc: 0.893. Test loss: 0.02064. Test acc: 0.933\n",
      "Epoch [821/1000]. Step [1/33]. Loss: 0.09349. Acc: 0.898. Test loss: 0.16306. Test acc: 0.933\n",
      "Epoch [822/1000]. Step [1/33]. Loss: 0.09335. Acc: 0.898. Test loss: 0.02051. Test acc: 0.933\n",
      "Epoch [823/1000]. Step [1/33]. Loss: 0.08779. Acc: 0.906. Test loss: 0.02109. Test acc: 0.933\n",
      "Epoch [824/1000]. Step [1/33]. Loss: 0.10716. Acc: 0.879. Test loss: 0.02041. Test acc: 0.933\n",
      "Epoch [825/1000]. Step [1/33]. Loss: 0.07133. Acc: 0.930. Test loss: 0.02023. Test acc: 0.933\n",
      "Epoch [826/1000]. Step [1/33]. Loss: 0.09996. Acc: 0.889. Test loss: 0.16272. Test acc: 0.933\n",
      "Epoch [827/1000]. Step [1/33]. Loss: 0.08516. Acc: 0.910. Test loss: 0.02086. Test acc: 0.933\n",
      "Epoch [828/1000]. Step [1/33]. Loss: 0.08914. Acc: 0.904. Test loss: 0.02033. Test acc: 0.933\n",
      "Epoch [829/1000]. Step [1/33]. Loss: 0.09750. Acc: 0.893. Test loss: 0.16215. Test acc: 0.933\n",
      "Epoch [830/1000]. Step [1/33]. Loss: 0.09051. Acc: 0.902. Test loss: 0.02004. Test acc: 0.933\n",
      "Epoch [831/1000]. Step [1/33]. Loss: 0.08209. Acc: 0.914. Test loss: 0.02189. Test acc: 0.933\n",
      "Epoch [832/1000]. Step [1/33]. Loss: 0.07679. Acc: 0.922. Test loss: 0.02005. Test acc: 0.933\n",
      "Epoch [833/1000]. Step [1/33]. Loss: 0.09151. Acc: 0.900. Test loss: 0.02081. Test acc: 0.933\n",
      "Epoch [834/1000]. Step [1/33]. Loss: 0.09171. Acc: 0.900. Test loss: 0.01972. Test acc: 0.933\n",
      "Epoch [835/1000]. Step [1/33]. Loss: 0.07631. Acc: 0.922. Test loss: 0.02043. Test acc: 0.933\n",
      "Epoch [836/1000]. Step [1/33]. Loss: 0.07101. Acc: 0.930. Test loss: 0.01934. Test acc: 0.933\n",
      "Epoch [837/1000]. Step [1/33]. Loss: 0.07202. Acc: 0.928. Test loss: 0.02091. Test acc: 0.933\n",
      "Epoch [838/1000]. Step [1/33]. Loss: 0.08038. Acc: 0.916. Test loss: 0.01917. Test acc: 0.933\n",
      "Epoch [839/1000]. Step [1/33]. Loss: 0.08035. Acc: 0.916. Test loss: 0.16691. Test acc: 0.933\n",
      "Epoch [840/1000]. Step [1/33]. Loss: 0.07786. Acc: 0.920. Test loss: 0.02012. Test acc: 0.933\n",
      "Epoch [841/1000]. Step [1/33]. Loss: 0.08183. Acc: 0.914. Test loss: 0.02032. Test acc: 0.933\n",
      "Epoch [842/1000]. Step [1/33]. Loss: 0.08465. Acc: 0.910. Test loss: 0.01973. Test acc: 0.933\n",
      "Epoch [843/1000]. Step [1/33]. Loss: 0.08584. Acc: 0.908. Test loss: 0.01996. Test acc: 0.933\n",
      "Epoch [844/1000]. Step [1/33]. Loss: 0.06660. Acc: 0.936. Test loss: 0.16296. Test acc: 0.933\n",
      "Epoch [845/1000]. Step [1/33]. Loss: 0.08718. Acc: 0.906. Test loss: 0.02042. Test acc: 0.933\n",
      "Epoch [846/1000]. Step [1/33]. Loss: 0.09157. Acc: 0.900. Test loss: 0.16353. Test acc: 0.933\n",
      "Epoch [847/1000]. Step [1/33]. Loss: 0.08832. Acc: 0.904. Test loss: 0.01950. Test acc: 0.933\n",
      "Epoch [848/1000]. Step [1/33]. Loss: 0.07886. Acc: 0.918. Test loss: 0.02014. Test acc: 0.933\n",
      "Epoch [849/1000]. Step [1/33]. Loss: 0.07457. Acc: 0.924. Test loss: 0.01900. Test acc: 0.933\n",
      "Epoch [850/1000]. Step [1/33]. Loss: 0.09994. Acc: 0.889. Test loss: 0.01904. Test acc: 0.933\n",
      "Epoch [851/1000]. Step [1/33]. Loss: 0.09152. Acc: 0.900. Test loss: 0.01953. Test acc: 0.933\n",
      "Epoch [852/1000]. Step [1/33]. Loss: 0.08300. Acc: 0.912. Test loss: 0.16486. Test acc: 0.933\n",
      "Epoch [853/1000]. Step [1/33]. Loss: 0.06874. Acc: 0.932. Test loss: 0.16397. Test acc: 0.933\n",
      "Epoch [854/1000]. Step [1/33]. Loss: 0.08867. Acc: 0.904. Test loss: 0.01962. Test acc: 0.933\n",
      "Epoch [855/1000]. Step [1/33]. Loss: 0.11000. Acc: 0.875. Test loss: 0.01859. Test acc: 0.933\n",
      "Epoch [856/1000]. Step [1/33]. Loss: 0.09732. Acc: 0.893. Test loss: 0.16451. Test acc: 0.933\n",
      "Epoch [857/1000]. Step [1/33]. Loss: 0.08584. Acc: 0.908. Test loss: 0.01953. Test acc: 0.933\n",
      "Epoch [858/1000]. Step [1/33]. Loss: 0.09823. Acc: 0.891. Test loss: 0.16577. Test acc: 0.933\n",
      "Epoch [859/1000]. Step [1/33]. Loss: 0.09554. Acc: 0.895. Test loss: 0.01888. Test acc: 0.933\n",
      "Epoch [860/1000]. Step [1/33]. Loss: 0.07729. Acc: 0.920. Test loss: 0.01904. Test acc: 0.933\n",
      "Epoch [861/1000]. Step [1/33]. Loss: 0.10830. Acc: 0.877. Test loss: 0.02004. Test acc: 0.933\n",
      "Epoch [862/1000]. Step [1/33]. Loss: 0.08971. Acc: 0.902. Test loss: 0.02018. Test acc: 0.933\n",
      "Epoch [863/1000]. Step [1/33]. Loss: 0.08659. Acc: 0.906. Test loss: 0.01891. Test acc: 0.933\n",
      "Epoch [864/1000]. Step [1/33]. Loss: 0.08280. Acc: 0.912. Test loss: 0.01790. Test acc: 0.933\n",
      "Epoch [865/1000]. Step [1/33]. Loss: 0.08575. Acc: 0.908. Test loss: 0.01849. Test acc: 0.933\n",
      "Epoch [866/1000]. Step [1/33]. Loss: 0.09381. Acc: 0.896. Test loss: 0.16521. Test acc: 0.933\n",
      "Epoch [867/1000]. Step [1/33]. Loss: 0.10555. Acc: 0.881. Test loss: 0.01816. Test acc: 0.933\n",
      "Epoch [868/1000]. Step [1/33]. Loss: 0.10273. Acc: 0.885. Test loss: 0.01803. Test acc: 0.933\n",
      "Epoch [869/1000]. Step [1/33]. Loss: 0.09576. Acc: 0.895. Test loss: 0.16567. Test acc: 0.933\n",
      "Epoch [870/1000]. Step [1/33]. Loss: 0.11563. Acc: 0.867. Test loss: 0.16410. Test acc: 0.933\n",
      "Epoch [871/1000]. Step [1/33]. Loss: 0.10107. Acc: 0.887. Test loss: 0.01731. Test acc: 0.933\n",
      "Epoch [872/1000]. Step [1/33]. Loss: 0.09863. Acc: 0.891. Test loss: 0.01821. Test acc: 0.933\n",
      "Epoch [873/1000]. Step [1/33]. Loss: 0.08966. Acc: 0.902. Test loss: 0.16667. Test acc: 0.933\n",
      "Epoch [874/1000]. Step [1/33]. Loss: 0.08274. Acc: 0.912. Test loss: 0.01798. Test acc: 0.933\n",
      "Epoch [875/1000]. Step [1/33]. Loss: 0.10558. Acc: 0.881. Test loss: 0.01776. Test acc: 0.933\n",
      "Epoch [876/1000]. Step [1/33]. Loss: 0.09840. Acc: 0.891. Test loss: 0.01770. Test acc: 0.933\n",
      "Epoch [877/1000]. Step [1/33]. Loss: 0.08389. Acc: 0.910. Test loss: 0.01726. Test acc: 0.933\n",
      "Epoch [878/1000]. Step [1/33]. Loss: 0.08963. Acc: 0.902. Test loss: 0.31182. Test acc: 0.933\n",
      "Epoch [879/1000]. Step [1/33]. Loss: 0.08823. Acc: 0.904. Test loss: 0.16419. Test acc: 0.933\n",
      "Epoch [880/1000]. Step [1/33]. Loss: 0.07827. Acc: 0.918. Test loss: 0.01701. Test acc: 0.933\n",
      "Epoch [881/1000]. Step [1/33]. Loss: 0.08384. Acc: 0.910. Test loss: 0.16234. Test acc: 0.933\n",
      "Epoch [882/1000]. Step [1/33]. Loss: 0.08230. Acc: 0.912. Test loss: 0.16486. Test acc: 0.933\n",
      "Epoch [883/1000]. Step [1/33]. Loss: 0.08124. Acc: 0.914. Test loss: 0.16748. Test acc: 0.933\n",
      "Epoch [884/1000]. Step [1/33]. Loss: 0.07097. Acc: 0.928. Test loss: 0.16547. Test acc: 0.933\n",
      "Epoch [885/1000]. Step [1/33]. Loss: 0.08818. Acc: 0.904. Test loss: 0.01671. Test acc: 0.933\n",
      "Epoch [886/1000]. Step [1/33]. Loss: 0.09261. Acc: 0.898. Test loss: 0.01646. Test acc: 0.933\n",
      "Epoch [887/1000]. Step [1/33]. Loss: 0.08106. Acc: 0.914. Test loss: 0.01715. Test acc: 0.933\n",
      "Epoch [888/1000]. Step [1/33]. Loss: 0.08524. Acc: 0.908. Test loss: 0.01782. Test acc: 0.933\n",
      "Epoch [889/1000]. Step [1/33]. Loss: 0.06954. Acc: 0.930. Test loss: 0.01649. Test acc: 0.933\n",
      "Epoch [890/1000]. Step [1/33]. Loss: 0.08082. Acc: 0.914. Test loss: 0.01824. Test acc: 0.933\n",
      "Epoch [891/1000]. Step [1/33]. Loss: 0.10545. Acc: 0.881. Test loss: 0.16674. Test acc: 0.933\n",
      "Epoch [892/1000]. Step [1/33]. Loss: 0.09686. Acc: 0.893. Test loss: 0.01774. Test acc: 0.933\n",
      "Epoch [893/1000]. Step [1/33]. Loss: 0.09699. Acc: 0.893. Test loss: 0.01828. Test acc: 0.933\n",
      "Epoch [894/1000]. Step [1/33]. Loss: 0.10534. Acc: 0.881. Test loss: 0.01649. Test acc: 0.933\n",
      "Epoch [895/1000]. Step [1/33]. Loss: 0.10256. Acc: 0.885. Test loss: 0.01671. Test acc: 0.933\n",
      "Epoch [896/1000]. Step [1/33]. Loss: 0.09260. Acc: 0.898. Test loss: 0.01629. Test acc: 0.933\n",
      "Epoch [897/1000]. Step [1/33]. Loss: 0.07488. Acc: 0.922. Test loss: 0.01648. Test acc: 0.933\n",
      "Epoch [898/1000]. Step [1/33]. Loss: 0.09508. Acc: 0.895. Test loss: 0.01701. Test acc: 0.933\n",
      "Epoch [899/1000]. Step [1/33]. Loss: 0.08361. Acc: 0.910. Test loss: 0.31608. Test acc: 0.933\n",
      "Epoch [900/1000]. Step [1/33]. Loss: 0.09400. Acc: 0.896. Test loss: 0.01604. Test acc: 0.933\n",
      "Epoch [901/1000]. Step [1/33]. Loss: 0.08191. Acc: 0.912. Test loss: 0.01592. Test acc: 0.933\n",
      "Epoch [902/1000]. Step [1/33]. Loss: 0.09260. Acc: 0.898. Test loss: 0.01576. Test acc: 0.933\n",
      "Epoch [903/1000]. Step [1/33]. Loss: 0.09640. Acc: 0.893. Test loss: 0.01783. Test acc: 0.933\n",
      "Epoch [904/1000]. Step [1/33]. Loss: 0.08673. Acc: 0.906. Test loss: 0.01646. Test acc: 0.933\n",
      "Epoch [905/1000]. Step [1/33]. Loss: 0.09218. Acc: 0.898. Test loss: 0.01607. Test acc: 0.933\n",
      "Epoch [906/1000]. Step [1/33]. Loss: 0.09939. Acc: 0.889. Test loss: 0.01643. Test acc: 0.933\n",
      "Epoch [907/1000]. Step [1/33]. Loss: 0.08662. Acc: 0.906. Test loss: 0.16838. Test acc: 0.933\n",
      "Epoch [908/1000]. Step [1/33]. Loss: 0.08519. Acc: 0.908. Test loss: 0.01734. Test acc: 0.933\n",
      "Epoch [909/1000]. Step [1/33]. Loss: 0.08095. Acc: 0.914. Test loss: 0.31147. Test acc: 0.933\n",
      "Epoch [910/1000]. Step [1/33]. Loss: 0.09077. Acc: 0.900. Test loss: 0.31057. Test acc: 0.933\n",
      "Epoch [911/1000]. Step [1/33]. Loss: 0.08066. Acc: 0.914. Test loss: 0.01570. Test acc: 0.933\n",
      "Epoch [912/1000]. Step [1/33]. Loss: 0.08475. Acc: 0.908. Test loss: 0.01580. Test acc: 0.933\n",
      "Epoch [913/1000]. Step [1/33]. Loss: 0.09513. Acc: 0.895. Test loss: 0.16624. Test acc: 0.933\n",
      "Epoch [914/1000]. Step [1/33]. Loss: 0.07897. Acc: 0.916. Test loss: 0.16602. Test acc: 0.933\n",
      "Epoch [915/1000]. Step [1/33]. Loss: 0.08219. Acc: 0.912. Test loss: 0.01521. Test acc: 0.933\n",
      "Epoch [916/1000]. Step [1/33]. Loss: 0.09078. Acc: 0.900. Test loss: 0.01537. Test acc: 0.933\n",
      "Epoch [917/1000]. Step [1/33]. Loss: 0.09122. Acc: 0.900. Test loss: 0.01567. Test acc: 0.933\n",
      "Epoch [918/1000]. Step [1/33]. Loss: 0.07648. Acc: 0.920. Test loss: 0.01574. Test acc: 0.933\n",
      "Epoch [919/1000]. Step [1/33]. Loss: 0.09340. Acc: 0.896. Test loss: 0.16656. Test acc: 0.933\n",
      "Epoch [920/1000]. Step [1/33]. Loss: 0.08052. Acc: 0.914. Test loss: 0.01526. Test acc: 0.933\n",
      "Epoch [921/1000]. Step [1/33]. Loss: 0.10487. Acc: 0.881. Test loss: 0.01604. Test acc: 0.933\n",
      "Epoch [922/1000]. Step [1/33]. Loss: 0.08497. Acc: 0.908. Test loss: 0.01488. Test acc: 0.933\n",
      "Epoch [923/1000]. Step [1/33]. Loss: 0.08348. Acc: 0.910. Test loss: 0.01493. Test acc: 0.933\n",
      "Epoch [924/1000]. Step [1/33]. Loss: 0.09064. Acc: 0.900. Test loss: 0.16424. Test acc: 0.933\n",
      "Epoch [925/1000]. Step [1/33]. Loss: 0.09522. Acc: 0.895. Test loss: 0.16762. Test acc: 0.933\n",
      "Epoch [926/1000]. Step [1/33]. Loss: 0.07893. Acc: 0.916. Test loss: 0.01734. Test acc: 0.933\n",
      "Epoch [927/1000]. Step [1/33]. Loss: 0.08906. Acc: 0.902. Test loss: 0.01642. Test acc: 0.933\n",
      "Epoch [928/1000]. Step [1/33]. Loss: 0.10085. Acc: 0.887. Test loss: 0.01678. Test acc: 0.933\n",
      "Epoch [929/1000]. Step [1/33]. Loss: 0.10252. Acc: 0.885. Test loss: 0.01492. Test acc: 0.933\n",
      "Epoch [930/1000]. Step [1/33]. Loss: 0.09184. Acc: 0.898. Test loss: 0.01438. Test acc: 0.933\n",
      "Epoch [931/1000]. Step [1/33]. Loss: 0.08323. Acc: 0.910. Test loss: 0.01470. Test acc: 0.933\n",
      "Epoch [932/1000]. Step [1/33]. Loss: 0.09798. Acc: 0.891. Test loss: 0.01586. Test acc: 0.933\n",
      "Epoch [933/1000]. Step [1/33]. Loss: 0.11419. Acc: 0.869. Test loss: 0.01546. Test acc: 0.933\n",
      "Epoch [934/1000]. Step [1/33]. Loss: 0.07915. Acc: 0.916. Test loss: 0.01569. Test acc: 0.933\n",
      "Epoch [935/1000]. Step [1/33]. Loss: 0.07293. Acc: 0.924. Test loss: 0.01786. Test acc: 0.933\n",
      "Epoch [936/1000]. Step [1/33]. Loss: 0.08475. Acc: 0.908. Test loss: 0.01570. Test acc: 0.933\n",
      "Epoch [937/1000]. Step [1/33]. Loss: 0.09214. Acc: 0.898. Test loss: 0.16568. Test acc: 0.933\n",
      "Epoch [938/1000]. Step [1/33]. Loss: 0.08606. Acc: 0.906. Test loss: 0.01427. Test acc: 0.933\n",
      "Epoch [939/1000]. Step [1/33]. Loss: 0.09086. Acc: 0.900. Test loss: 0.16728. Test acc: 0.933\n",
      "Epoch [940/1000]. Step [1/33]. Loss: 0.08944. Acc: 0.902. Test loss: 0.01590. Test acc: 0.933\n",
      "Epoch [941/1000]. Step [1/33]. Loss: 0.10978. Acc: 0.875. Test loss: 0.01703. Test acc: 0.933\n",
      "Epoch [942/1000]. Step [1/33]. Loss: 0.09035. Acc: 0.900. Test loss: 0.01501. Test acc: 0.933\n",
      "Epoch [943/1000]. Step [1/33]. Loss: 0.08771. Acc: 0.904. Test loss: 0.16597. Test acc: 0.933\n",
      "Epoch [944/1000]. Step [1/33]. Loss: 0.09207. Acc: 0.898. Test loss: 0.01521. Test acc: 0.933\n",
      "Epoch [945/1000]. Step [1/33]. Loss: 0.10393. Acc: 0.883. Test loss: 0.01484. Test acc: 0.933\n",
      "Epoch [946/1000]. Step [1/33]. Loss: 0.07019. Acc: 0.928. Test loss: 0.16772. Test acc: 0.933\n",
      "Epoch [947/1000]. Step [1/33]. Loss: 0.10060. Acc: 0.887. Test loss: 0.01684. Test acc: 0.933\n",
      "Epoch [948/1000]. Step [1/33]. Loss: 0.10489. Acc: 0.881. Test loss: 0.01491. Test acc: 0.933\n",
      "Epoch [949/1000]. Step [1/33]. Loss: 0.08028. Acc: 0.914. Test loss: 0.01471. Test acc: 0.933\n",
      "Epoch [950/1000]. Step [1/33]. Loss: 0.07883. Acc: 0.916. Test loss: 0.16651. Test acc: 0.933\n",
      "Epoch [951/1000]. Step [1/33]. Loss: 0.08332. Acc: 0.910. Test loss: 0.16778. Test acc: 0.933\n",
      "Epoch [952/1000]. Step [1/33]. Loss: 0.08897. Acc: 0.902. Test loss: 0.01383. Test acc: 0.933\n",
      "Epoch [953/1000]. Step [1/33]. Loss: 0.09346. Acc: 0.896. Test loss: 0.01531. Test acc: 0.933\n",
      "Epoch [954/1000]. Step [1/33]. Loss: 0.09005. Acc: 0.900. Test loss: 0.01504. Test acc: 0.933\n",
      "Epoch [955/1000]. Step [1/33]. Loss: 0.10513. Acc: 0.881. Test loss: 0.16566. Test acc: 0.933\n",
      "Epoch [956/1000]. Step [1/33]. Loss: 0.10992. Acc: 0.875. Test loss: 0.01592. Test acc: 0.933\n",
      "Epoch [957/1000]. Step [1/33]. Loss: 0.08466. Acc: 0.908. Test loss: 0.16529. Test acc: 0.933\n",
      "Epoch [958/1000]. Step [1/33]. Loss: 0.07739. Acc: 0.918. Test loss: 0.01571. Test acc: 0.933\n",
      "Epoch [959/1000]. Step [1/33]. Loss: 0.09162. Acc: 0.898. Test loss: 0.01519. Test acc: 0.933\n",
      "Epoch [960/1000]. Step [1/33]. Loss: 0.08312. Acc: 0.910. Test loss: 0.01660. Test acc: 0.933\n",
      "Epoch [961/1000]. Step [1/33]. Loss: 0.09188. Acc: 0.898. Test loss: 0.01380. Test acc: 0.933\n",
      "Epoch [962/1000]. Step [1/33]. Loss: 0.06078. Acc: 0.939. Test loss: 0.01580. Test acc: 0.933\n",
      "Epoch [963/1000]. Step [1/33]. Loss: 0.10221. Acc: 0.885. Test loss: 0.16756. Test acc: 0.933\n",
      "Epoch [964/1000]. Step [1/33]. Loss: 0.09650. Acc: 0.893. Test loss: 0.01666. Test acc: 0.933\n",
      "Epoch [965/1000]. Step [1/33]. Loss: 0.07698. Acc: 0.918. Test loss: 0.01581. Test acc: 0.933\n",
      "Epoch [966/1000]. Step [1/33]. Loss: 0.07400. Acc: 0.922. Test loss: 0.16799. Test acc: 0.933\n",
      "Epoch [967/1000]. Step [1/33]. Loss: 0.09931. Acc: 0.889. Test loss: 0.01593. Test acc: 0.933\n",
      "Epoch [968/1000]. Step [1/33]. Loss: 0.09028. Acc: 0.900. Test loss: 0.16760. Test acc: 0.933\n",
      "Epoch [969/1000]. Step [1/33]. Loss: 0.09320. Acc: 0.896. Test loss: 0.01425. Test acc: 0.933\n",
      "Epoch [970/1000]. Step [1/33]. Loss: 0.09043. Acc: 0.900. Test loss: 0.01627. Test acc: 0.933\n",
      "Epoch [971/1000]. Step [1/33]. Loss: 0.09484. Acc: 0.895. Test loss: 0.15872. Test acc: 0.933\n",
      "Epoch [972/1000]. Step [1/33]. Loss: 0.08888. Acc: 0.902. Test loss: 0.01671. Test acc: 0.933\n",
      "Epoch [973/1000]. Step [1/33]. Loss: 0.08439. Acc: 0.908. Test loss: 0.16993. Test acc: 0.933\n",
      "Epoch [974/1000]. Step [1/33]. Loss: 0.08888. Acc: 0.902. Test loss: 0.01529. Test acc: 0.933\n",
      "Epoch [975/1000]. Step [1/33]. Loss: 0.09941. Acc: 0.889. Test loss: 0.01395. Test acc: 0.933\n",
      "Epoch [976/1000]. Step [1/33]. Loss: 0.10214. Acc: 0.885. Test loss: 0.01449. Test acc: 0.933\n",
      "Epoch [977/1000]. Step [1/33]. Loss: 0.08288. Acc: 0.910. Test loss: 0.01624. Test acc: 0.933\n",
      "Epoch [978/1000]. Step [1/33]. Loss: 0.09165. Acc: 0.898. Test loss: 0.01486. Test acc: 0.933\n",
      "Epoch [979/1000]. Step [1/33]. Loss: 0.07259. Acc: 0.924. Test loss: 0.01648. Test acc: 0.933\n",
      "Epoch [980/1000]. Step [1/33]. Loss: 0.07985. Acc: 0.914. Test loss: 0.16980. Test acc: 0.933\n",
      "Epoch [981/1000]. Step [1/33]. Loss: 0.08423. Acc: 0.908. Test loss: 0.16627. Test acc: 0.933\n",
      "Epoch [982/1000]. Step [1/33]. Loss: 0.07840. Acc: 0.916. Test loss: 0.16798. Test acc: 0.933\n",
      "Epoch [983/1000]. Step [1/33]. Loss: 0.09624. Acc: 0.893. Test loss: 0.01656. Test acc: 0.933\n",
      "Epoch [984/1000]. Step [1/33]. Loss: 0.07533. Acc: 0.920. Test loss: 0.01453. Test acc: 0.933\n",
      "Epoch [985/1000]. Step [1/33]. Loss: 0.08278. Acc: 0.910. Test loss: 0.16808. Test acc: 0.933\n",
      "Epoch [986/1000]. Step [1/33]. Loss: 0.08314. Acc: 0.910. Test loss: 0.31487. Test acc: 0.933\n",
      "Epoch [987/1000]. Step [1/33]. Loss: 0.08313. Acc: 0.910. Test loss: 0.16880. Test acc: 0.933\n",
      "Epoch [988/1000]. Step [1/33]. Loss: 0.08860. Acc: 0.902. Test loss: 0.01413. Test acc: 0.933\n",
      "Epoch [989/1000]. Step [1/33]. Loss: 0.07982. Acc: 0.914. Test loss: 0.16571. Test acc: 0.933\n",
      "Epoch [990/1000]. Step [1/33]. Loss: 0.07124. Acc: 0.926. Test loss: 0.01475. Test acc: 0.933\n",
      "Epoch [991/1000]. Step [1/33]. Loss: 0.07848. Acc: 0.916. Test loss: 0.01402. Test acc: 0.933\n",
      "Epoch [992/1000]. Step [1/33]. Loss: 0.08306. Acc: 0.910. Test loss: 0.01452. Test acc: 0.933\n",
      "Epoch [993/1000]. Step [1/33]. Loss: 0.07069. Acc: 0.926. Test loss: 0.01447. Test acc: 0.933\n",
      "Epoch [994/1000]. Step [1/33]. Loss: 0.08555. Acc: 0.906. Test loss: 0.16227. Test acc: 0.933\n",
      "Epoch [995/1000]. Step [1/33]. Loss: 0.08260. Acc: 0.910. Test loss: 0.01360. Test acc: 0.933\n",
      "Epoch [996/1000]. Step [1/33]. Loss: 0.07994. Acc: 0.914. Test loss: 0.01261. Test acc: 0.933\n",
      "Epoch [997/1000]. Step [1/33]. Loss: 0.07989. Acc: 0.914. Test loss: 0.01283. Test acc: 0.933\n",
      "Epoch [998/1000]. Step [1/33]. Loss: 0.08463. Acc: 0.908. Test loss: 0.01338. Test acc: 0.933\n",
      "Epoch [999/1000]. Step [1/33]. Loss: 0.08427. Acc: 0.908. Test loss: 0.31723. Test acc: 0.933\n",
      "Epoch [1000/1000]. Step [1/33]. Loss: 0.09638. Acc: 0.893. Test loss: 0.01394. Test acc: 0.933\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "th = 0.5\n",
    "epochs=1000\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):  \n",
    "\n",
    "    model.train()\n",
    "    running_items, running_right = 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # TODO: Performance overhead !!!!\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss = loss.item()\n",
    "        running_items += len(labels)\n",
    "        pred_labels = torch.squeeze((outputs > th).int())\n",
    "        running_right += (labels == pred_labels).sum()\n",
    "        break\n",
    "        \n",
    "    model.eval()\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
    "            f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "            f'Loss: {loss:.5f}. ' \\\n",
    "            f'Acc: {running_right / running_items:.3f}', end='. ')\n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    train_loss_history.append(loss)\n",
    "\n",
    "    # выводим статистику на тестовых данных\n",
    "    test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
    "    for j, data in enumerate(val_loader):\n",
    "\n",
    "        # TODO: Performance overhead !!!!\n",
    "        test_labels = data[1].to(device)\n",
    "        test_outputs = model(data[0].to(device))\n",
    "        test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
    "        test_running_total += len(data[1])\n",
    "        pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
    "        test_running_right += (test_labels == pred_test_labels).sum()\n",
    "    \n",
    "    test_loss_history.append(test_loss.item())\n",
    "    print(f'Test loss: {test_loss:.5f}. Test acc: {test_running_right / test_running_total:.3f}')\n",
    "    \n",
    "    model.train()\n",
    "        \n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6d1695be-641a-4fe1-8399-a60f80a1ea00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACEQklEQVR4nO3deXwTZf4H8E+S3kApZ8tdLgUEyiWIAqJyuyp4LqIcP49VwIVlcZXFCy+8RV0VLzxBWFxlXUWgoKAgct/3fbdQoLSltE2T+f0xTZpjksxMZjKT9PN+vfpqMpl55sk0mfn2+xxjEQRBABEREVGMsBpdASIiIiItMbghIiKimMLghoiIiGIKgxsiIiKKKQxuiIiIKKYwuCEiIqKYwuCGiIiIYgqDGyIiIoopDG6IiIgopjC4IaKoNHr0aFSvXl3WuhaLBc8884y+FSIi02BwQ0RePvvsM1gsFqxfv97oqhhqzpw5mDFjhtHVICIV4oyuABGR3i5duoS4OGWnuzlz5mD79u2YOHGiPpUiIt0wuCGimJeUlGR0FQAA5eXlcDqdSEhIMLoqRDGNzVJEpMqmTZswePBgpKamonr16rjhhhvwxx9/eK1jt9sxbdo0tG7dGklJSahTpw569eqF7Oxs9zo5OTkYM2YMGjdujMTERDRo0AC33HILDh8+LKseJ06cwNChQ1G9enXUq1cPkydPhsPh8FrHt89NYWEhJk6ciMzMTCQmJqJ+/fro378/Nm7cCADo27cvfvzxRxw5cgQWiwUWiwWZmZnu7U+fPo377rsP6enpSEpKQlZWFj7//HOvfR4+fBgWiwWvvfYaZsyYgZYtWyIxMRFr165FtWrVMGHCBL/3cvz4cdhsNkyfPl3WeyciaczcEJFiO3bsQO/evZGamop//OMfiI+PxwcffIC+fftixYoV6NGjBwDgmWeewfTp03H//feje/fuKCgowPr167Fx40b0798fAHDbbbdhx44deOSRR5CZmYnTp08jOzsbR48e9QoopDgcDgwcOBA9evTAa6+9hqVLl+L1119Hy5Yt8fDDDwfc7qGHHsI333yD8ePHo127djh79ixWrlyJXbt2oUuXLpg6dSouXLiA48eP48033wQAd+flS5cuoW/fvti/fz/Gjx+P5s2bY/78+Rg9ejTy8/P9gpZPP/0UJSUlePDBB5GYmIimTZti2LBhmDdvHt544w3YbDb3ul9//TUEQcCIESMU/02IyINAROTh008/FQAI69atC7jO0KFDhYSEBOHAgQPuZSdPnhRq1Kgh9OnTx70sKytLuPHGGwOWc/78eQGA8Oqrryqu56hRowQAwrPPPuu1vHPnzkLXrl29lgEQnn76affzmjVrCuPGjQta/o033ig0a9bMb/mMGTMEAMJXX33lXlZWVib07NlTqF69ulBQUCAIgiAcOnRIACCkpqYKp0+f9ipj8eLFAgDhp59+8lresWNH4dprrw1aLyIKjc1SRKSIw+HAkiVLMHToULRo0cK9vEGDBrj77ruxcuVKFBQUAADS0tKwY8cO7Nu3T7Ks5ORkJCQkYPny5Th//ryq+jz00ENez3v37o2DBw8G3SYtLQ1r1qzByZMnFe9v4cKFyMjIwPDhw93L4uPj8de//hVFRUVYsWKF1/q33XYb6tWr57WsX79+aNiwIWbPnu1etn37dmzduhX33HOP4joRkTcGN0SkyJkzZ1BcXIzLL7/c77W2bdvC6XTi2LFjAIBnn30W+fn5uOyyy9ChQwc8+uij2Lp1q3v9xMREvPzyy/jpp5+Qnp6OPn364JVXXkFOTo6suiQlJfkFDrVq1QoZKL3yyivYvn07mjRpgu7du+OZZ54JGRC5HDlyBK1bt4bV6n36bNu2rft1T82bN/crw2q1YsSIEViwYAGKi4sBALNnz0ZSUhLuuOMOWfUgosAY3BCRbvr06YMDBw5g1qxZaN++PT7++GN06dIFH3/8sXudiRMnYu/evZg+fTqSkpLw5JNPom3btti0aVPI8j37qyhx55134uDBg3jnnXfQsGFDvPrqq7jiiivw008/qSovmOTkZMnlI0eORFFRERYsWABBEDBnzhz86U9/Qs2aNTWvA1FVw+CGiBSpV68eUlJSsGfPHr/Xdu/eDavViiZNmriX1a5dG2PGjMHXX3+NY8eOoWPHjn6zBbds2RJ///vfsWTJEmzfvh1lZWV4/fXXdX0fDRo0wNixY7FgwQIcOnQIderUwQsvvOB+3WKxSG7XrFkz7Nu3D06n02v57t273a/L0b59e3Tu3BmzZ8/Gb7/9hqNHj+Lee+9V+W6IyBODGyJSxGazYcCAAfjvf//rNVw7NzcXc+bMQa9evZCamgoAOHv2rNe21atXR6tWrVBaWgoAKC4uRklJidc6LVu2RI0aNdzraM3hcODChQtey+rXr4+GDRt67bNatWp+6wHAkCFDkJOTg3nz5rmXlZeX45133kH16tVx7bXXyq7LvffeiyVLlmDGjBmoU6cOBg8erOIdEZEvDgUnIkmzZs3CokWL/JZPmDABzz//PLKzs9GrVy+MHTsWcXFx+OCDD1BaWopXXnnFvW67du3Qt29fdO3aFbVr18b69evdQ7ABYO/evbjhhhtw5513ol27doiLi8N3332H3Nxc/PnPf9blfRUWFqJx48a4/fbbkZWVherVq2Pp0qVYt26dV7aoa9eumDdvHiZNmoQrr7wS1atXx0033YQHH3wQH3zwAUaPHo0NGzYgMzMT33zzDVatWoUZM2agRo0asuty99134x//+Ae+++47PPzww4iPj9fjLRNVPUYP1yIic3ENBQ/0c+zYMUEQBGHjxo3CwIEDherVqwspKSnCddddJ/z+++9eZT3//PNC9+7dhbS0NCE5OVlo06aN8MILLwhlZWWCIAhCXl6eMG7cOKFNmzZCtWrVhJo1awo9evQQ/v3vf4es56hRo4Rq1ar5LX/66acF31MbPIaCl5aWCo8++qiQlZUl1KhRQ6hWrZqQlZUlvPfee17bFBUVCXfffbeQlpYmAPAaFp6bmyuMGTNGqFu3rpCQkCB06NBB+PTTT722dw0FDzXMfciQIQIAv2NHROpZBEEQjAmriIho2LBh2LZtG/bv3290VYhiBvvcEBEZ5NSpU/jxxx/ZkZhIY+xzQ0QUYYcOHcKqVavw8ccfIz4+Hn/5y1+MrhJRTGHmhogowlasWIF7770Xhw4dwueff46MjAyjq0QUU9jnhoiIiGIKMzdEREQUUxjcEBERUUypch2KnU4nTp48iRo1agScXp2IiIjMRRAEFBYWomHDhn43rvVV5YKbkydPet33hoiIiKLHsWPH0Lhx46DrVLngxjU1+rFjx9z3v9GK3W7HkiVLMGDAAE6jriMe58jgcY4cHuvI4HGODL2Oc0FBAZo0aSLrFidVLrhxNUWlpqbqEtykpKQgNTWVXxwd8ThHBo9z5PBYRwaPc2TofZzldClhh2IiIiKKKQxuiIiIKKYwuCEiIqKYUuX63BAREenJ4XDAbrcbXQ3D2O12xMXFoaSkBA6HQ9G2CQkJIYd5y8HghoiISAOCICAnJwf5+flGV8VQgiAgIyMDx44dUzyfnNVqRfPmzZGQkBBWHRjcEBERacAV2NSvXx8pKSlVdqJYp9OJoqIiVK9eXVEWxjXJ7qlTp9C0adOwjh+DGyIiojA5HA53YFOnTh2jq2Mop9OJsrIyJCUlKW5iqlevHk6ePIny8vKwhpGzQzEREVGYXH1sUlJSDK5JdHM1Ryntq+OLwQ0REZFGqmpTlFa0On4MboiIiCimMLghIiIiTWRmZuKtt94yuhrsUExERFSV9e3bF506dcKMGTPCLmvdunVITk5GeXl5+BULAzM3RERUZVidZYAgGF2NqCIIguxgpV69eqboVM3ghoiIqobCU7hpy/2wzf2z0TUxjdGjR2PFihV46623YLFYYLFY8Nlnn8FiseCnn35C165dkZiYiJUrV+LAgQO45ZZbkJ6ejurVq+PKK6/E0qVLvcrzbZayWCz4+OOPMWzYMKSkpKB169b4/vvvdX9fDG6IiKhKsG7/Rvx9cJnu+xIEAcVl5Yb8CAoyU2+99RZ69uyJBx54AKdOncKpU6fQpEkTAMDjjz+Ol156Cbt27ULHjh1RVFSEIUOGYNmyZdi0aRMGDRqEm266CUePHg26j2nTpuHOO+/E1q1bMWTIEIwYMQLnzp0L6/iGwj43REREGrtkd6DdU4sN2ffOZwciJUHe5b1mzZpISEhASkoKMjIyAAC7d+8GADz77LPo37+/e93atWsjKyvL/fy5557Dd999h++//x7jx48PuI/Ro0dj+PDhAIAXX3wRb7/9NtauXYtBgwYpfm9yMXNDREREfrp16+b1vKioCJMnT0bbtm2RlpaG6tWrY9euXSEzNx07dnQ/rlatGlJTU3H69Gld6uzCzA0REZHGkuNt2PnsQMP2rYVq1ap5PZ88eTKys7Px2muvoVWrVkhOTsbtt9+OsrKyoOX43kbBYrHA6XRqUsdAGNwQERFpzGKxyG4aMlpCQoKs2x2sWrUKo0ePxrBhwwCImZzDhw/rXDt12CxFRERUhWVmZmLNmjU4fPgw8vLyAmZVWrdujW+//RabN2/Gli1bcPfdd+uegVGLwQ0REVEVNnnyZNhsNrRr1w716tUL2IfmjTfeQK1atXD11VfjpptuwsCBA9GlS5cI11ae6MiZERERkS4uu+wyrF692mvZ6NGj/dbLzMzEzz//7LVs3LhxXs8PHz4Mp9OJgoICAJAclp6fnx9ehWVg5oaIiIhiCoMbIiIiiikMboiIiCimMLghIiKimMLghoiIiGIKgxsiIiKKKQxuiIiIKKYwuCEiIqKYwuCGiIiqCP8J5Sg2MbghIiKimMLghoiIqgiL0RUwpb59+2LixImalTdmzBiMGDFCs/LUYHBDREREMYXBDRERURU1evRorFixAm+99RYsFgssFgsOHz6M7du3Y/DgwahevTrS09Nx7733Ii8vz73dN998gw4dOiA5ORl16tRBv379cPHiRTzzzDP44osvsHDhQthsNlgsFixfvjzi74t3BSciItKaIAD2YmP2HZ8CWOQ1wb311lvYu3cv2rdvj2effVbcPD4e3bt3x/33348333wTly5dwmOPPYY777wTP//8M06dOoXhw4fjlVdewbBhw1BYWIjffvsNgiBg8uTJ2LlzJ86dO4cvvvgCVqsVtWvX1vPdSmJwQ0REpDV7MfBiQ2P2/c+TQEI1WavWrFkTCQkJSElJQUZGBgDg+eefR+fOnfHiiy+615s1axaaNGmCvXv3oqioCOXl5bj11lvRrFkzAECHDh3c6yYnJyMxMREZGRmwWo1pIGJwQ0RERG5btmzBL7/8gurVq/u9duDAAQwYMAA33HADOnTogIEDB2LAgAG4/fbbUatWLQNqK43BDRERkdbiU8QMilH7DkNRURFuuukmvPzyy36vNWjQADabDdnZ2fj999+xZMkSvPPOO5g6dSrWrFmD5s2bh7VvrZiiQ/G7776LzMxMJCUloUePHli7dq2s7ebOnQuLxYKhQ4fqW0EiIiIlLBaxaciIH5n9bVwSEhLgcDjcz7t06YIdO3YgMzMTrVq18vqpVq1axduz4JprrsG0adOwadMmJCQk4LvvvpMszwiGBzfz5s3DpEmT8PTTT2Pjxo3IysrCwIEDcfr06aDbHT58GJMnT0bv3r0jVFMiIqLYk5mZiTVr1uDw4cPIy8vDuHHjcO7cOQwfPhzr1q3DgQMHsHjxYowZMwYOhwNr1qzBiy++iPXr1+Po0aP49ttvcebMGbRt29Zd3o4dO7Bnzx7k5eXBbrdH/D0ZHty88cYbeOCBBzBmzBi0a9cOM2fOREpKCmbNmhVwG4fDgREjRmDatGlo0aJFBGtLREQUWyZPngybzYZ27dqhXr16KCsrw6pVq+BwODBgwAB06NABEydORFpaGqxWK1JTU/Hrr79iyJAhuOyyy/DEE0/g9ddfx+DBgwEA999/P1q3bo3u3bujXr16WLVqVcTfk6F9bsrKyrBhwwZMmTLFvcxqtaJfv35YvXp1wO2effZZ1K9fH/fddx9+++23oPsoLS1FaWmp+3lBQQEAwG63ax5NusozIkqtSnicI4PHOXJ4rCNDcDhhq3isx/lfEAQ4nU44nU5Ny9Zbq1atJAOQb775xm+ZIAi4/PLLsXDhQr/XXO+7bt26+Pbbb1GjRg1YKprI5B4Tp9MJQRBgt9ths9m8XlPyNzM0uMnLy4PD4UB6errX8vT0dOzevVtym5UrV+KTTz7B5s2bZe1j+vTpmDZtmt/yJUuWICUlvE5XgWRnZ+tSLnnjcY4MHufI4bHWV6vcvbii4rHUxTkccXFxyMjIQFFREcrKyjQtO1oVFhYq3qasrAyXLl3Cr7/+ivLycq/XiovlzxsUVaOlCgsLce+99+Kjjz5C3bp1ZW0zZcoUTJo0yf28oKAATZo0wYABA5Camqpp/ex2O7Kzs9G/f3/Ex8drWjZV4nGODB7nyOGxjgxh5T6gYgDTkCFDNC27pKQEx44dQ/Xq1ZGUlKRp2dFGEAQUFhZ6ZW7kKikpQXJyMvr06eN3HF0tL3IYGtzUrVsXNpsNubm5Xstzc3Pdkwl5OnDgAA4fPoybbrrJvcyV6oqLi8OePXvQsmVLr20SExORmJjoV1Z8fLxuJxE9y6ZKPM6RweMcOTzW+nLYKruZan2cHQ4HLBYLrFarYRPXmYXruuw6HkpYrVZYLBbJ74KSv5mhf4GEhAR07doVy5Ytcy9zOp1YtmwZevbs6bd+mzZtsG3bNmzevNn9c/PNN+O6667D5s2b0aRJk0hWn4iIiEzI8GapSZMmYdSoUejWrRu6d++OGTNm4OLFixgzZgwAYOTIkWjUqBGmT5+OpKQktG/f3mv7tLQ0APBbTkRE5E3Qfw+C/vuIZVodP8ODm7vuugtnzpzBU089hZycHHTq1AmLFi1ydzI+evRolU/xERGRubmaTIqLi5GcnGxwbaKXqzO270gppQwPbgBg/PjxGD9+vORroW6V/tlnn2lfISIiikHKOrcqYbPZkJaW5p6ANiUlRXFn2ljhdDpRVlaGkpISRckJp9OJM2fOICUlBXFx4YUnpghuiIiIop1rIEyoGfZjnSAIuHTpEpKTkxUHeFarFU2bNg07MGRwQ0REpAGLxYIGDRqgfv36VXpCRrvdjl9//RV9+vRRPCotISFBk64oDG6IiIg0ZLPZwu4zEs1sNhvKy8uRlJRk2NQG7KlLREREMYXBDREREcUUBjdEREQUUxjcEBERUUxhcENEREQxhcENERERxRQGN0RERBRTGNwQERFRTGFwQ0REVQTv2F1VMLghIiKimMLghoiIqoiqeZfuqojBDRERVRFslqoqGNwQERFRTGFwQ0REVQSbpaoKBjdERFRFsFmqqmBwQ0RERDGFwQ0REVURbJaqKhjcEBERUUxhcENEREQxhcENERERxRQGN0RERBRTGNwQERFRTGFwQ0RERDGFwQ0RERHFFAY3REREFFMY3BARURXB2y9UFQxuiIiIKKYwuCEioiqCt1+oKhjcEBFRFcFmqaqCwQ0RERHFFAY3RERURbBZqqpgcENERFUEm6WqCgY3REREFFMY3BARURXBZqmqgsENERERxRQGN0RERBRTGNwQERFRTGFwQ0RERDGFwQ0RERHFFAY3REREFFMY3BAREVFMYXBDREREMYXBDRERVRG8/UJVweCGiIiIYgqDGyIiqiJ4+4WqgsENERFVEWyWqioY3BAREVFMYXBDRERVBJulqgoGN0REVEWwWaqqYHBDREREMYXBDRERVRFslqoqGNwQEVEVwWapqoLBDREREcUUBjdERFRFsFmqqmBwQ0RERNoQBKDkgtG1YHBDRERkSqVFwIXjRtdCmX+PRPzrLZFWfNDQajC4ISIiMqPXWgNvXgGcP2J0TfyVlwGntoiZGk+7vgcAtDi92IBKVWJwQ0REZEb2YvH3kVXG1kPKf+4DPugD/P6O0TWRxOCGiIiIlKnI0GD1v4ytRwAMboiIqIowyTw3F44DnwwAtv9H2XZlxcCKV4HTu/WpVwxhcENERBRJC/8BHFsDfPN/yrbbsxD45XngvR5inxcKiMENERFVESaZ56YkX912xWcrH+ebsJOxiTC4IdKLIACf/QmYc5fRNSEiAKZpllIbZMUlaVuNGBZndAWIYtb5w8Dh38TH9hIgnicmItKI7xBs8sLMDRERVREmaZayqK0HAxq5TBHcvPvuu8jMzERSUhJ69OiBtWvXBlz322+/Rbdu3ZCWloZq1aqhU6dO+PLLLyNYWyIiik6xFBzE0nvRnuHBzbx58zBp0iQ8/fTT2LhxI7KysjBw4ECcPn1acv3atWtj6tSpWL16NbZu3YoxY8ZgzJgxWLzY2NkQiYLjiYhIM2XFgKMcOLwKWP1e4CaaAz8DC8YCJQWRrZ9ezNgUZcY6wQR9bt544w088MADGDNmDABg5syZ+PHHHzFr1iw8/vjjfuv37dvX6/mECRPw+eefY+XKlRg4cGAkqkwkj+rUMxEFVFoETG8EpDWrHDFUuwVw+SD/db8cJv5OTAUGvwTTNEtpwaRBhVkYmrkpKyvDhg0b0K9fP/cyq9WKfv36YfXq1SG3FwQBy5Ytw549e9CnTx89q0oUHp6IiLRxarP423Mo9PlDwbe5cKzigcf30MjvJPvc6M7QzE1eXh4cDgfS09O9lqenp2P37sAzMF64cAGNGjVCaWkpbDYb3nvvPfTv319y3dLSUpSWlrqfFxSI6Um73Q673a7Bu6jkKk/rcslb1Bzn8nLEVzy028sAS3zQ1c0mao5zDOCxls9SXu534XI4HHBKHDvXN84pCHDY7RAcTtgqltntdsOyqzZBcGcWgv3NXfUvdzgg2O2wOhyV9S+3AwZ+Xlx1EwCUe9TD8yyn1zVWDsObpdSoUaMGNm/ejKKiIixbtgyTJk1CixYt/JqsAGD69OmYNm2a3/IlS5YgJSVFl/plZ2frUi55M/txTik9A1fIvXjxYjhs0TkU3OzHOZbwWIdWp3A3evks27lzJw7mLfRb95aK3zk5OVi3cCFa5e7DFRXLFi78EbAY03hxdd5Z1HPXw7/eLq76b92yBceOpyIzbzuyKpb99uuvKEw+qGc1g3LVrbS0FIs93sMtHuto/XkuLi6Wva6hwU3dunVhs9mQm5vrtTw3NxcZGRkBt7NarWjVqhUAoFOnTti1axemT58uGdxMmTIFkyZNcj8vKChAkyZNMGDAAKSmpmrzRirY7XZkZ2ejf//+iI+Prv/So0nUHOf8o8BO8eHAAf2BxBrG1kehqDnOMYDHWj7LkZrAfu9l7dq1Q5vuQ/xX3iT+yshogCFDhkBYuRc4KS4bMmSIYcGNbfbHQJFHPQKpqH/HrCx06DgE1g25QEULW+/evYH6bfWtaDAVdUtMTPR+D5sqH2r9eXa1vMhhaHCTkJCArl27YtmyZRg6dCgAwOl0YtmyZRg/frzscpxOp1fTk6fExEQkJib6LY+Pj9ftJKJn2VTJ9MfZo27xcTav59HE9Mc5hsT0sXb1cQm3KSjO/7Jls9lgC3LcrFYLrPHxcNgqg5n4uHjAalC3U4/9yvl7x9kqzh9e9Y8zxTnFYrEEfA9af56VlGV4s9SkSZMwatQodOvWDd27d8eMGTNw8eJF9+ipkSNHolGjRpg+fToAsZmpW7duaNmyJUpLS7Fw4UJ8+eWXeP/99418G0TBsUMxVWVOJ/BJPyC5FnCPwjtha0IqoIr272S0119fhgc3d911F86cOYOnnnoKOTk56NSpExYtWuTuZHz06FFYPaLcixcvYuzYsTh+/DiSk5PRpk0bfPXVV7jrLt6/h8yMJyKqws7uA05sEB87nZHPmJhuWgaV9eE/SbIZHtwAwPjx4wM2Qy1fvtzr+fPPP4/nn38+ArUi0hBPSkQGsvj8jgE8pwRl+AzFRLErhk6kRDEh2ue5IbkY3BBFAv/LIqrA74I2eByDYXBD0efcAVgEh9G1UIgnIiLDWMzWLMU+N3pjcEPRZet8xL/fA1cefNvomigjOI2uAVHklV30X2boBVoI8DgKMdAJisENmZdDYqrt38WgpkHBJv/XTMck7ftERlg8FXixIXDoN6NrAvNkbCrw3lK6Y3BD5nThOPBCA2DBWO/l0ZQBEWLov0QipVb/S/y99GmfF4z8LpgsyAkLzynBMLghc1r7IeC0A5tney+PpuCGmRsimCKgcGdKzPKdZJ8bvTG4oegSVcGNJ56UiADwAq0VHsegGNxQdImm4EYwy3+JRAby618S5ndB1XfJZKOl2OdGdwxuKLpEU3ATSyMziGJCLH0no73++mJwQ9ElmoIbr8xNFNWbSFM+WYpws5hqsh6mmxGYfW70xuCGoosz2ibvq8CTEikRrZ9zKaYKLDzqEu3fyWivv84Y3FB0idovdLTWmyLuzF7gxUbAz7F6g2AjvgsSo6WMxD43umNwQ9Elmpp32KGY1Fg2DSi/BPz6qtE10YiZMjexhOeUYBjcUHSJpuAmpjovEmnEiEBfMlPCeW5iGYMbii5RFdx44EmJqipT9bmJITylBMXghqJLNAU3DGiIJBjZ58YkgRb73OiOwQ1Fl2gKbkwz1TuRkSzG9z8z3e0XtBDt9dcXgxuKLkIUDZHlPDdEJmmWMkMdPLHPjd4Y3FB0idoggSclqsK8Apwo7MhrRgx0gmJwQ9Elqr7QsZQCJ1LLBAGFVLOUkUEW+9zojsENRZdoytwIJjmREpkJA32N8DgGw+CGoktUnRiZuSEyV58bM9QlDDyPyMbghqJLNGVuvPCkpLu8fcDH/YC9S4yuCQVl5Hchhv7hiPb664zBDUWXqB0txROR7uaPAY6vA+bcYXRNyJMZMjcmqIIX9rnRHYMbii5RlbnhUHBNCQLwn/uBpdOkX790LrL1IXUMDfTNFuWEg4FOMAxuKLpEU5DADsXaOrkJ2DYfWPmG0TUhRXwDCpM0S0XjkHQzZoDNWCcwuKFoE03BTSy175uBo8zoGpAZqPouxVLGpgLPKUExuCGKCJ6IiACYp1nKyHqwz43uGNwQ6YUdiolM0qFYahK/aBdL70V7DG6IdGOW9n0iI5kguDGdGOpzY1IMbjS0+VAuiuxG14JMwytzY1w1iAyldeZGVXlS20T5l5KBTlAMbjTy+84jSJ09GCU7/ovCS+z4SL54IiICwIsyEFt9bszQ7CiBwY1GWp7JxuWWo7hP+A+sb7ZDyZkjRleJDGfQPDendwMr3wQKTooXkgXjgOUvR27/euFFMUqZ4OJn0gtwePh9CIbBjUbSr70fOVmPAADShHwkvdsRF86fMbhWZCivLjcRPBG91wNY+gzwRltxXpjNXwHLX4zc/omCMslF2SyjtgKRqp9JDl00YHCjoTpDpno9f2XWXJzIvyRv47JiYO1HQP4xHWpGxlDRoVgQgLz9gFOj20xs/EKbcswgJv/7roIMCSpi8LPDTGZQDG60ZI1DdrtX3U8H5s/D5x+/Bcc39wMnNwffdtk0YOFk4KPr9K0jRY6zvPKx3BPRxi+Af3UF/nOfPnUiijSLxUQXYpMEOXICdcljZpbjaH4MbjRWnJgOx/VPAQD62Lbhn0XTYds+H/jwWuDHvwfecF+2+PuijKas3QuBN9sDX90OzOgAFOYAO7/n3ZAj4dJ58TYAoRz9A5g10GOBzJPSb6+Lv3d8p7hqkmI122GaiyWFZoHh0yJIznMT7Z+haK+/vhjc6MB55V+Aywb5v7DuY+C8Bh2N5w4HLhwD9mcD+UeBhY8C/75XvBtyoOaMkgtis1cR+wGF5e3OwId9gYMrgq+3YKz3c9kXY61PWDEa3FD0MEWAbYY6eJJTH6k+Nwxo5GJwo4e4RODOL4GaTfxeOnJoD7B4KrDzvz6vhPGhLTxV+ThQcPPf8WKz15w71O/n9G5g45eAU+bIn5ICYM9PQHmp+n3KsW+pODpI6Rf/93eAefcAjvLQ67pcOi/+3rsoxIq+dZHb50Z+VWTxvLDE0okxlt5LVWD0bN3u74HZgpww8DsQVJzRFYhZcQnA2NViU9TWee7F6xb8C82sK4DVAEZ+D9RuDqQ1DW9fXn07AgQ3u74Xf8tpUgnkvR7i77hEoOOdodf/ejhwZCVw1Vhg0HR5+xAEYP5oYOcC+fWafZv4O70D0Lqf/O2WPCH+3v0/4Iph8reTw/fEI3souI4nLEEwyX/RWuCJPXqY6TNnkluisM+N7lRlbo4dO4bjx4+7n69duxYTJ07Ehx9+qFnFYkJiDeDWD4HLBrsXdcK+yte/uFnsM2OXOaIqEM/gxqkgC6GW3ADpyErx96av5Jd96byywMZTwfHQ60gpK1a3XVC+wY2C0VKa8szcRNMd1UPgf61Rxui+LmYKsLTC70AwqoKbu+++G7/88gsAICcnB/3798fatWsxdepUPPvss5pWMCbc+Lr7YSvrSf/XX8gAzh1UX75nU1QkghuLjq2ZRlyA9Xg/fu9DbnCj8fu3xFBww4CGwmaWIId9bvSm6qy+fft2dO/eHQDw73//G+3bt8fvv/+O2bNn47PPPtOyfrGhZiPgweXy11c6x4lX5kaj+VGCibngRocTnl+XGxN0KI724MYLT/JRw3couKF9bmLoc8NAJyhVVym73Y7ExEQAwNKlS3HzzTcDANq0aYNTp04F27TqatgZuG5q6PUA4IM+QPE5+WWXl1Q+jvrMjREnPj3ej9oOxRq//1jK3MRq5+iY5/vPQ5h/u1j427PPje5UndWvuOIKzJw5E7/99huys7MxaJA47PnkyZOoU6eOphWMKdf+A+g3LfR6udu9OiGH5DkaKRLBjdWmX9mGXID1yNyo7HPDzI1MPMlHDYvvPDeGVMLnN2IjSKKAVAU3L7/8Mj744AP07dsXw4cPR1ZWFgDg+++/dzdXUQC9JgJ3ypgS/2Je5eNQX8KYytzESLMUMzfaM7ppg9Qzzd/OLJ8bLfrcmOW9mJOqoeB9+/ZFXl4eCgoKUKtWLffyBx98ECkpKZpVLmZdfiMQl+QdlPgqKxJ/7/oBmDcCiEsGHlkP1Gzsv65X5oZ9bhTTpc+Nb+ZG9oYaVySGghuKUiboxBszUyCQXKquUpcuXUJpaak7sDly5AhmzJiBPXv2oH79+ppWMCbZ4oC/bg66SlFBvvhg3gjxd/kl4MtbgU+H+K8c8cyNjs1ShkzNHoHRUnIDC2ZuAvO6QPG/1uhixoxDlM9zw+xlUKrO6rfccgu++EJsWsnPz0ePHj3w+uuvY+jQoXj//fc1rWDMSm0ATAk8L8vvuw7j170+t0rI2wMcWRW83Ij0uYlw5kbiSyxo+t+giZqldM3cxNDJMJbeS6wzRdbEDHWgSFJ1ldq4cSN69+4NAPjmm2+Qnp6OI0eO4IsvvsDbb7+taQVjWmINYPx66ZccxRg5a63yMmOxz41kcBNmHTzLjEizlFGT+HkVrmPZEcD+BtFLyz43pgiWwsU+N3pTdYUoLi5GjRo1AABLlizBrbfeCqvViquuugpHjmhwY8iqpG5r4C+/+S2uHV+mrjy9ghvP+0lFfCi4RHAT7gnOs2+SmYaCa37C8ryoRHmzFJGWmP2LaarO6q1atcKCBQtw7NgxLF68GAMGDAAAnD59GqmpqZpWsEpo0BF4ZKPXoivqWJGWEq+8rEv52tTJl2fQpGefG6kTjmuZ12thBjde9+CK4cyNEEPBDee5iU5+Q8ENmOfGbNkeTfrcaFabmKQquHnqqacwefJkZGZmonv37ujZsycAMYvTuXNnTStYZdRpCQysvLmk9cxOLP3rVcrL+epW4Mhq4PCq8O9Z5clpr3wc6XluXMs8si1hZ24892OmoeC63jgzyoMbLzyzRy0GphQBqoaC33777ejVqxdOnTrlnuMGAG644QYMG6bx3ZWrkp5jgcbdgE/6AwDqLrhbXTmfipMqol5bYOQCoEZG+HVzeAQ3ejZLSV60XJkbz2xLmHXQu1lKdeZG84p4PIyh4IYXyChi0fjvpSYLapHY1MjPEPvc6E31WT0jIwOdO3fGyZMn3XcI7969O9q0aaNZ5aqkxleKN9q0xgOH/fviKHJmF/D65cCen8KvV1jBgILMSLAOxZ6ZG9M3S6kcCq71CSuWmqV4Yo8REfrbMQCu0lQFN06nE88++yxq1qyJZs2aoVmzZkhLS8Nzzz0HpzPKT6BGs1iAK+8HBk0Pva5cX//Z+7maif48m6X0PGlIXoBdwU1lv5+YbZbS/NjGUHBD0Unr2y/IzoLq/R0Pg6zEDee5CYeqZqmpU6fik08+wUsvvYRrrrkGALBy5Uo888wzKCkpwQsvvKBpJaukK+8HLp0HftHhWH49HLjrKyAuQf42ns1Sel4kg2VutMy2eAXhMXxX8FjK3LBDcZSy+PQnjtTfjsFBVaYquPn888/x8ccfu+8GDgAdO3ZEo0aNMHbsWAY3WrBYxBttNuwMzL5du3JticC+xcCeH4ErFPSPckYquAlyQvIISASLNbyQRND7NhVmzNzE0sk8lt4LKaPiu2S2zA373OhOVbPUuXPnJPvWtGnTBufOnQu7UuShdX+geR9tyup0D3DZQPGx5405D/0KnD0QfFvPpiw9AwPZmZsweTXN6XCSUN2hWOPAMZYyN6a5+SIpovVQcNlC7YefoVimKrjJysrCv/71L7/l//rXv9CxY8ewK0U+Rn4PNOoafjlxCYCtoinK1cyUuwP4/CbgnS7AgnFAeYDJA41slnJnbiSCG7UXOc/9qCoj1H9eZhkKzoCAYoyqOaMsEssMpLqJld9nuVQ1S73yyiu48cYbsXTpUvccN6tXr8axY8ewcOFCTStIEL8I/7cE+GEisOlL9eXYEj2Cm4og5tTWytc3fwXUSAfO7BGf3/QWUK2u+DhSzVLBUrGemRv3MpV18SpLTRkhTiycxE97pmtaIHl8hoIb2ufGhARB+rPN4CUsqjI31157Lfbu3Ythw4YhPz8f+fn5uPXWW7Fjxw58+WUYF18KzBYH3PIv4E8zwigjXvwBvDMxnn57Hdj9g/jz4ySgpAAoOg04PGYo1nNEnOQMxa5J/CrrYHHPfaPyBKB7s5TaY8TRUrLwxB89NA9Kw+lzY5bMh8o73Juxz41Jv4uqMjcA0LBhQ7+Ow1u2bMEnn3yCDz/8MOyKUQBdRwNpTcWZiBXKKwFspUAtoDJzE8yZPcBLTQEIwPB5lctN1SylNnMTbrNUyB0E3l/QzZi5CciMJ3aSwaCh4NHyGQn4fqKk/ial51SzpAeLBWh1A5ClfPbiz9acwn+2nBafyAluALi/YKc2eywyaii452uCz+8w9qPH+1HbLMXbL1Csi9R/+lrei05rFpWZG9NknsyPwU20+tObwOBXFG1iRxzsrmSdu1kqyBfE88vjeePMiA8Fd9WhMnPjPjWorYvezVJmGQoeS5kbTzyxRxcjbr8QLUOpAx0bfsbDwuAmWsUnAT3+AnQZKXuTMsShrCK4+XzlXlz32nIUlwUZXu3Z6dYruKlYXlIAfDkMWPsRsOt/QMkFJe8gwD5lDgWXvFO4kv1IlKUlZm50YMILE4Vm1FDwqJnnJsr73JiUoj43t94avJ9Hfn5+OHUhNW56G0ipC6x8I+SqZYhHmSB2KI5HOQ7lXcSTC7bj9UATFXsGNFJDwX9/Bzjws/gDAJm9gVH/A8pLgPhkFW8GAS7AUn1uwhwt5Qx3tFQoJsncxFIam/PcEKDgmh4lnxH2udGFosxNzZo1g/40a9YMI0fKzyS4vPvuu8jMzERSUhJ69OiBtWvXBlz3o48+Qu/evVGrVi3UqlUL/fr1C7p+zLNYgH5PA/2fC7nqPde0QuO6qQCABIuMCfG8RkhJBAOXznuvf/g34Kd/AC82An78e+jyJQVJJXuNlgqyvqzdSPXf0ZBZMjcx1SzF/1qjk0FDwSX73JgkQFbd58ZzM34HglGUufn00081r8C8efMwadIkzJw5Ez169MCMGTMwcOBA7NmzB/Xr1/dbf/ny5Rg+fDiuvvpqJCUl4eWXX8aAAQOwY8cONGrUSPP6RY2rHwESUoIGFW0b10Pb2lZgEVAvxQJcAKyWIBc8z7ltvB4HCYyOrhabfNZ97L1cEMTtbCE+csEyN1IBiSbz3Kg5SYRIc/vVy6gTEQMCMphRQ8Gj5fPOPje6MLzPzRtvvIEHHngAY8aMQbt27TBz5kykpKRg1qxZkuvPnj0bY8eORadOndCmTRt8/PHHcDqdWLZsWYRrbjKuu4nfPT/wOrYE9zw3HTNSAAAJKA+8vmdTVHlp5WPXl07qpGWxSZf175HAG22B0sLA+wOC97mRbJZSO89NuEPBQ22jcii41mIpc8NmqSjFPjeaYZ8b2QwNbsrKyrBhwwb069fPvcxqtaJfv35YvXq1rDKKi4tht9tRu3ZtvaoZXS4bAPSbJv1aXOUMxakJ4hcjDkGyMJ59bspLKh+7LpJSF5hAWZ1d3wMXTwN7fgq8P8+yvRdW/HL4LdJknptInCSMuhjrPeQ9onhiJ4T3XTJlcGCWesQW1ZP4aSEvLw8OhwPp6eley9PT07F7925ZZTz22GNo2LChV4DkqbS0FKWllVmHgoICAIDdbofdHmCWXpVc5WldrmI9xsGSmIa4Hyd4LS4XrABsiANgcZTh1dvaY8+CHwMWIzjs7saX8pIi94fF4bDDabfD6nTCN08jOMr8GmwECJXlOMoh+Bwfy4mNEJJrArVbwlJe7vehtJeVAXY7LPZS92sWCCiz2wG7HfHush1+ZQfiWVZ5uV32dq59OZwOOINsE+/zXOp9h9pO7efIswyn4HT/B1NuL5P9Pj33b/jnuYKl3D2RgVgnn3rFCZWfM7PUWS7PY21zVv7Nou19eHJ9Dp2CE84QfzslLA7/c4TDIfF9tJd5fF8FOO12CE6H+5xlLy8Pqx7hsDqFynrYywCLxKgOiXOb1Vnu3q68XN45RS+uugkAyj3qocU5LBAl5Rka3ITrpZdewty5c7F8+XIkJSVJrjN9+nRMm+afyViyZAlSUlJ0qVd2drYu5SpTC0lXvIn+OyfDWpHx+GP9JiSWX8CVAM6ePoWEmpsxqGEZcEa6BEd5mfsDsvfwcbSreHz08CFsXbgQHY4dQQufbS4WXkB1n2Xl5eXuD/yWzVtw/Gg192vJZXkYsGNS5T4t/h/Jn39ehpKE2qhbuAPXeCzPzs5Ggr0Agyueb9+2DUdOybu3WZ3CXehV8Xjr5s04dsy31tJuqfh9+NBhbA9yH7VbfJ7LrZvndmrv0+ZZRv7583DlNNf8sRp5O5QP1zfH5xlef/+ff/4ZJQne2doBJSVwjdGL1nvcZWdno3tuLhpUPI/W9wFBcH8Oj584gaMlf7i/b7/9ugKFyQdUF51+YTOu8lm2c+dOHMzzPlae54b9+/djd/FCXJZzAG0rlv3y8zJcSqiruh7h6HjsCJpXPF6yeDHKbf6jSxPKC93137plC44dT0X744fRsmLZxo0bcOqgcY0vrr9vaWkpFnt8Tj3PP1qfO4qLi2Wva2hwU7duXdhsNuTm5notz83NRUZGRtBtX3vtNbz00ktYunRp0DuRT5kyBZMmVV48CwoK0KRJEwwYMACpqanhvQEfdrsd2dnZ6N+/P+Ljff93N4ZjyK2wvN0BKCtCj4F3wJKzDTj8HuqkpWLIkCGw/ro9YHDj2WRVWGp3N2I2bdoEjQcPgXXRCiDPe5tqyUlAqfeyuLg4uIrK6pSFju2HuF+zHFwO7Khc1yb49wG6/rprgZpNYDmQBOx3LRXE41yWD2wXl7Rv3x5XdBnit70Uy6Hq7rI6ZnVEh47ytsMm8Vdm8+Zo2j/INpu8n3Zof4W8unlsN2SIzDoFKSMtrSZQcT7o0b07hOZ9ZBdjts+z59/s+uuvA1K9BxDE7X8cqPjHTvWxM4jnsU5aMBeoiEGj7X24CU5gs/iwcaPGaJjVA9gnPu/dpw9Qr43qoi374oCD3svatWuHNt19jtXFM+5zQ6tWrdGi7xAIy7cBp8Rl1113PVCzsep6hMO6aLn73DlgwAAgsYb/SsVngW3iw45ZWejQcQisS1a5z9ddunSB0MbAz0fFeSYxMdH7c+px/tH63OFqeZHD0OAmISEBXbt2xbJlyzB06FAAcHcOHj9+fMDtXnnlFbzwwgtYvHgxunXrFnQfiYmJSExM9FseHx+v2wlbz7IVi08D/rYDKMpFfN2WwHnx6mB12mGNjwcgrx9GskfEsnTHKcRfdg7X2/w7D1sE/z43Fo/OfHG2OMDz2MQF6IDs+Rb+Mwb4ywqg/GJlmRDE4+yo3D7OZvUuOxibR52sCrZzbW61wqZgG6XrA9DkM+T5f12czaL4fbrqYYrPs63y3cTbbP7vxeNzZor6qhAfHw+r1er1PCp59L2zWm2wxlVeaiT/dkpInHdsNpv/98tjPZtN/P45PD9DcXHh1SMcnn/juADHw+OYxbmOmcd2ceEeR41YLJaAn1Otzx1KyjJ8tNSkSZPw0Ucf4fPPP8euXbvw8MMP4+LFixgzZgwAYOTIkZgyZYp7/ZdffhlPPvkkZs2ahczMTOTk5CAnJwdFRUVGvQXzS0oF6rYWH7vuCu6ao0bmPaaSUbne+Yul+L/P1qOwRKL9M9DdxsNxajNQmAN8M6ZymeD3QFmHWWekO9qaYCg4OxRTpHh+1iwWgzrUhxpdZ+RnyKNnoqJjwxGDchne5+auu+7CmTNn8NRTTyEnJwedOnXCokWL3J2Mjx496vWfzPvvv4+ysjLcfvvtXuU8/fTTeOaZZyJZ9egUX9HP6PwhYMWr3kO8g0jyCG6sFV+wbzcexyjfT5BTYmi5Fjew2/2D11MrHMDXdwCNrwywnxAEve8t5bs/E5yIzFCHcHAoePTw+85rGZiqme07zKkjdMV5bvRgeHADAOPHjw/YDLV8+XKv54cPH9a/QrGsUVeg7c3i0Oxfnpe9Wf0UAagYDW4LOvGfRHDjtUztzL3+rAd/AQ7+Urlg4WSgaU8go33ojZ06T+Lny7Ch4LGUuaHoYYYLsxnqEIBFZebGlEPZzcnwZimKMFs8cPss4Oq/Ktos0VmZ4bEE+VLZyyWapaQCHqXkngBmXgOcPwLsXRJ8m4jP/2KGZqloPxnyxB41gt1+JNzPodztJfcZTd8HE9fVbPWRwOCmKrLFA/2fBbrdJ38be+UQPGuQTsjlEvMQOIPdrkEPb3UE5twB7F/qvfzCicq+NmqapcL5r4mZm/B5HX7zn1yrNs/ZgXUsW5P1jBDlfW6i4PtnimYpMoDFAtz4OtAgC/ifjCyORzBgqwhuaiTFw/fuDVIzHlslRlAppmb69KOrgdb9xcc7vgPmj658Lc5jXiS5F/2wvtBmyNxEeXDDzE308PuuGHz7BVN/XuT0uTFb/c1WH3/M3FRlFgvQdRQw6ofQ63puVvHBHniF/1xE8XLuNm6EX1/zfu55O4kf/w7s/hG4lB+8DK/gIFr63Hg+jvLgJgr+W6QKwb4rkWqWkroAmzFgiMY+N1HwXWRwQ0Dz3sATp4EmPWSt3iMzDe/e3QXVEkLPUePrVP5FHDl7MfSKvvTu9Dv3buC1y4CzB8Th7MfXAw7fvkLM3JhGFJxcqzbPZimDhoJHzei6QHWLxjqbB4MbEsUlAnd+ATTsHHLVetXicWPHBqoulu8s3Y1rX12O/acr7g6u6wVX4RfQUQqc2AD8bwLw8Q3Ac3WANR8AP0wCTm4K7wTJPjcaMP8JlSoEnf4hQkPBTf15URh4ma1DtKmDRRGDG6pUIwN44Beg+bXB13NdJJ3KJ+xzVmRDfthaMQe6FiOptOR0AJtnVz7/6R/A+k+AD/vC68Tyx7tilidvH7D2o9CTFxoWWMRQcBM1/4mTf2BhcOYGJgsOvETjPDdmrpuIHYrJm8UCjPoe2PCZmMGQ4g5ulPevcXU4PpR3EYIgwCK3DDUditUIFgD4nmxm9gbsFU1s9kvANcE6Zpshc2P+E1Jw0V7/KsQMQ8HN/HlRfDwEBetGgFnqEQQzNySt62jgoVXSr7mDG+VZF9cw8v9uPoleL/+CwkslIbaIsGAju3wDH7tH36Fja0KUyz432jL/ybVq8+lzY0gVoiWwZ58bPTC4ocAy2gMPrwaq+4yKcmVbVNxHKs5jjpwT+Zew71S+vA0jNvFXsABAgw7FTgdwelfkTrax1Ocmai5WZIrbL4Tc1MjPEPvc6I3BDQWX3g546Dcga3jlshPrAXuJqsyNDQ50b17b/XzNwTNa1FI7wZrJwupQXBFYrPsYeO8q4Lu/iI/n3AWc3q2+3NA7DvA4GsXSe4lxgskyN6b+vLDPjR4Y3FBo1esDw2YCo38Un5dcAObcCRTlKi7qod7N8PUDV2HygMsAAPvlZm7CJfcEq1fmxnWi2pct/t46D1g6Ddi7CHivB7BlHvBMTe9tTm4Sf587CJTLu3t7wP0CzNxQBPn2ufF8bJI+N2bJfKjuc2OS+psUgxuSL7MXcOeXQFwycGhF6H4mEuqk2GCzWnDtZfUBANZgN+H0cKpA3t3Lvan4jzFoh+IwggPXySChWuUyz4kEv3vQf5vPbwGOrQXe7gzMvh345j4g+2mlO/Z4GOXBDUUPXYeCq6iDVLOOabDPjR4Y3JAy7W4GxvwI1L1c3fYVzT4dGtfE+if6Sd6uQcrWY+fV7U8p3ZqlXOV6lFGjQfBtSi8AexeLjw+tALZ/A6yaAax6u3Kdwlxg+7di/ydHOVDuEwTGUuaGzVJRxPdvpeXfKwZGS7HPje4Y3JByjboC9y0B6rRSvq1HP5261RPxUJ9MWZut3J+nfF+ejO5QLFWunGHwNRv5L8t+svLxB32Ab8YAv78tNm+96vs38ajzkd+B4nMVi81/cvLDZqnoEezvE6k/XdR8RtjnRg8Mbkid5DRxJJWSO4sDfp2Qm6UlytrMFuRO5JoKOhRc6+BGRodsv1tA+CjKEX/v+Qk4ux8oLQi87tZ5wCvNgT9mir8Prwy9f1Nh5iZ6+ASiWl6oNbu3lIHY50Z3DG5IvbgE4E9viLMay+V7QZc5iV/YwY3cDsUqJiaUxR3ceNRDTnAjd0RaoJON1PJFjwGXzgOz7xSfXzwLfHmr2KF57gigrFjePiMtCk6oVMEvmDfgouxZB1N/dsxcNwBFZ4BfXgTOHxGbvzd+AZw7YHStQmJwQ+Fr1AX45ykgpU7odZ0+Jz2ZF29rxDI3OnUolgqatAxuVHVKrHht/SzgwDLx8e4fgN9eAwQBth8moHXO9z71cYqZn+MbZNZLJ6a+WJG+GQa5TcxS65mlaVNOPSSyX57ZVr3r78oafzMGWPEy8NmNYvb3+0eAj67Xd98aYHBD2khIASbtAga9DHS4I/B6fpkbeRfvOBXBzeerD+PKF5biwJki+Rspuf2CEu5yPcqQkyWSnbkJUG85dS7J935+ehdwYgOsW2aj3alvvF/b8a2Y+fm44uR2aivw1W3AkieAbx8E/ngfmHcPkLdffL28DDi6RqOMmElS8iSD71BwI4IKnT4vZRcr+66p4fv+13wAbPP4ngVqit6XHTxj4nSIt8z5Y6b/aznbgc1fi/vevRD47E9ieR/dIDZpe1r9HvBKS/HGwW92AA7/Ji6/cAw4syf0+zEJ3luKtBOXCFz1kHhDyW3zpdfxvVgH6+PiwSZzVJWngpJynCkvxQ2vr8CaWiVIl7NRRDsUy5jhWW5QELDeckZiSGxrD9A0dXqn9/MPeou/9y8Vf2+dJ/7O3Qk8sAxY8ap4k9HWA4Fr/wEUnBDn92l3C9B3CpC3Vwym2t8GWEP8r8UOxdFDi7/V+cNAwUmg2dWBy1a6TAsvNgIgAFOOA4k1pPd7ciNQvx0Qn1y57MJx4NCv4j8CniMl134g/rTuDxxeBcy9Gxj6vs/7FoD92d77+e9YoEY6cGQ1cOBn4Mr7xHsCAuJ52MVhB2ZeIz4+swtY9Zb42BW0/PA3IP0KIK2pGFgtnlK57YWj3vuUGkRy8bR4bz3XezUJBjekvTotgbF/iDPx+lLZ5ybBovxWD57OXSxDupw8pW5DwSW2lXP7irD73MjZViK4CffCcO4A8GrrygBu32Lxx2XlG+KPa2r+JVOBxlcCjbsBl98I1LvMvz7B/jahOl5ThPl+flRkUd7KEn8/tEq8FUw4dZCc58bjcf5RYO1H4rmry6gQffQqtsvbK44cddkyF0hMFT/nGz4Dml0DjFkofRPiSxKZn0O/illPAFjwEDBha9B3B8EJfDms8vmZADOdf35z5WNXYOOp8BQwo4P4+JGNwfcZnyK9/L2ewITNwbeNMAY3pI/6bYHHDgMLxgF7fqxcnn/Eez2ZwU2zmvHAxdDreVJ1eVZy40xV5VoklgURbnCjNnOjBTmZKVf9inLF/j67fwCWPgM8c8F7tbkjvD9HS54Ajq8HRv4XqJUJvNtd+oJx7pC43PMiBIgdqgUBSKntv43ke3GGzixRpWB9bpQGzqc2ywhuKso88DNQu4X4mfDcz7E/gCVPwHL+qOTWeLtL5edVEIBOd4uZ6FBObABObQHa3izeUsXTkYobD/sGNoEUnPJZoDD7VRag+f3o7/L2DwA/PRZihQD1OH9I/j4ihN9W0k9yLWD4HDHF6nJwudjG7CLz4j2orcyLULgi2SwlRyT63Ehta9T9gALxDGwAcVJD+0Xgk37iY6nABhDv3fXR9cCuH8TnZ/YAOxYA710NvNZavJWIS3lZZbBdfE5sUss/KgZbr2SKo0X2ZYufYTWcTqDotLptlTh/RH0ma/dC4MfJ4gg6X0puA+I7Usnzc7j9G7F+gUbl2S8Bc/4sr2zPfax6W8xkfH23a2Hl6yc3Ab+/A+uu/1Yu2zpP/HucP+IdiP8wEXj9cmDlDOCDa8XRQZfO++9z2bPiZ+uHvwGbvgpc32gSqDnaJdj5ZO9iYNf/tK1PGJi5If11uhtoeYN40tizUPzvwF4MXDVOdp+bRCg/WTdOSwGUzv2nRbOUZPu/RIdiWfUJM7gxMnMTKad3BX4tr6ID5JqZQNs/iRkeT9u+EfsqlJeKF7Tq6cC4NeJ/4fuWAL88X7nu4n+KmSUAGPYBkLdPvIVGl5HA1n+LgdC2f4uvd74XyNkK3PWV2JfhyO9ikHR8HdBzvHgBX/cRMOB54Kqx4jZS88FcOi/+kwAAB1eI/yF3ugewVZy6188S93vNRPE4FJ8F5o0Q63TzO8CeRcCRlcB1TwDxSYGPU0mB2GF0bsUNci0W4KqHxcfWODEonH07kHU3MMzjn5XSQsCWUJnlcNjFsjw/d76BwdoPgcIcYNf3QOsBQFwSMPhlILVhxXv6FNjr08nVRRCAbx/wX75sGuCoCLxO7xBvRhvq+/rrq+Lf7SaJpppL54GlT4uPv39EbHIas9B7Hc8gN2db8H3JEmaGSwsh9xnk9Tl3alqVcDG4ociokQ78eQ6wYCywZY54ol/zoXjXcTkcyu8tNTQrA2lNumHOmmOAzGkZDucVIjPgq3KDG6n/LJ2BXwsmIpmbEOuYvvOujPoFClovVkS/Z3aLFzTXhVgqO+N5kfZsglj9L/91N30p/p7RAfjbDuDTwZWv/e5x+4wlTwA7vwdG/oir978E25xPgKTUytc/vxl4qKLj5xcVfSf+NwF4cLnYRyP7KXHZyje997/xCyClbkW/JgC/vyN2BrXYxICvy0hg8KuVAc+rLSuDA0AMQNZ+WPncFWBtmQP0fRyo1Uy8oM/sLXaOHb8OSKwO/Huk+B98v2cqt3U1N3raVTHFwL4llc9v/xRof2vwiSgDNb04fDJK7/UAHvg5cDku+Ucg6/PjamIKSIPviCm+Z9F+LqjEZimKHIsF+NOblf+pFp6sHGUTipzOtz6scOL6NunolllL9jbLduYEfG3XqQsBX/MSNLiJcOZGTjAVskOxyU9oco6pkc1sS54I/vrxtUBRDuoV7YL18K/ApfzK13ICdCr9sG9lYBOIK7BxObu/MpO18Qvg5+cqX/MNDnx5BnZvd66o2zYAgvg9dvWl27NQzMZ63iJErm/GiL+1uoDKLUbJ/pRMlqlYkE7YkQoqwsncmAyDG4qs+CRg0HTg73uAavXlb+d7Q0g5Kpq8UpPiZW8SbLLABz5fJ68QyQn7KpZFPHOjMrjxet3kJzStm9UCvl+VAVLRGRnrRKAvjq9zKjuBCg7AXhIFQ/NlRzcKigyj477qsiOJmRui8NTIENPttVvKWz/Uf5ZSKmZDvrVLI9SqliBrk+AzIYfTLCUEfi0YuR1DwwpuJN6XZ6bD9H1ywjnhRnB+lCAsvqMII8FqU79tcR5UDe+WQ6ssWzh95AKvrEEZMsv2zZ5G4nPJzA2RBmpkAOPWAv2mhV5XTXBTcVFOircho0b4N+i0aNHnRulMvabI3Jg8uAlriL7UtgYEN0ZkbsIa/edzsTXlf/Q6BDdVPXMTRRjckLFscUCvicDjAeafcFEV3Cif1ThY5kb2/5OGdCgO9B+lmuDG4nPhMvkNCLWeXFHzYE5O/QwIIMP6WwrQLXOjlXDuHq50XV363PiUH4l+Y1E/uKASgxsyh6Sa4nTmmb2lX5c7v4YnzyyJzBODNcgJJljg46zY7L+bT+D291b6r1ARaAlaBTe+J5lwRksFnU02SNlmEfZF2qcMQ4bgmvwY+zIqc6NFE1I4ZVb5zI0Z6igPgxsyj8QawOgfgMePAdUzvF8rOKm8PBWZmzu6NAz4WrDw6JfduThdWIIJczdj/2n/oazlDgfu+mA1NhyWmBwtmIDBjTP481DLFa3jcUIz2+R+AMJrXgmSZYukqAuoBJ/tI1V/LQKRMMo0ss9NJDBzQ6SjpFTxDuOek2v53sBNDhV3orZZAn95g/W5KXcKmLF0HwDp7M+Jcxex5tA5lNkVTkYY6D3oHdx4dSg2+QktrD43Fe/NK2jT8b/zwBWJ0H48dxNuc16kMjdqP4uRzNxowBTfM2ZuiPRltQJdRwNjFokzvKqhpq9IkIAoWHAjwII5a8QATKpT8vYT58XXLFo1S0Uwc2P2JpOwLtJKbhqqY9bK67MaqeMdZnOeIU15VShzY8Z5bkwRgMnD4IbMrVlP4K+bgYEvKt9WReZGTVOWL6kgyFaxTPaIqwpl9gB9jXQNboJ0KDajcJtXNC1PioygyPT9V6S2jVS2Se2xYZ8b5Zi5IYocqw3oOQ544gzw103ytxOUdygOdmEL1tnYez3/MlzL5JbhsuFQgAngNAluLDLWkfG63tTOvaH2pqGan8Dl1MOIkUdhBjdGd8IORfbn1qSZG/a5CQuDG4oecQlA7RZwXD1R3vpqMjdBtrmzayNZRUgFMK6MTfBJAqXKkhm0qApuJEYKuZeb6MKldgZltffVCucmpGp5BuIRy9xomfEyycVXzbrM3Hhg5obIMM7rnsCGZn8JvaKak3eQbR7o3Tzk5pen14BVol+N1R3cKDs5xEE62Hrm+22Yv/6Y+3nAIeZqZyg2U7NUyP8mw3jvUvvQ/P5BcpqlDOhzE26zlCHzH+nQLGXWzI0RgUTI2IbBDZGujte+BvapecCV9wdeSc1/w8EuLEHKGHRFOpZP7osXb20vGcC4Ohkr7XNjCxDcfLvhGB79pvKmiqUBR2Fp0DRjeHCjttlMTsCiZCi42hO7jO3UZBnDpmGH4ohlblQGrFqsF3RdLTI3avartegJXkJhcEPRbchr4p3GpThVXJSDXWRCnFgz61ZDl6a1MKan/+guV/NSsNs7SIkPENz4BlAORxgXR4kOxYLTiP/KA1AyD4/XYgXNUnL6ZOk6DNgzEI+SzI1eTZfBytKjQ7FZMzeGzH3EPjdE5mCxAN3+D3g6H7hqrPdre34EcrYrK09OH5Wg1bFgdM8m/stVNksFCoZ8y1Farhef97ztRD6e+G6rxxKjAx0NmqUCBS9KhoKrDTrkHDNniGYpXY57mJ8Zs3eCjrrMTdDUjYZlhYPBDVFkWSzAoOnAxG3esxt//idg63zIHuIdbD2ZTQcWiRNLcrx4cbUozNwE6nOjTXAjPVrq1IUSnMwvrlxg9H9rIZulFL/gv46sPkY6Nkt5fS6UdHIOQ9gdinVqugyWRatKmZtwR7NpUgetyo08BjcUW9KaAn/bDrTqJz6/dB749n7gzG552wc7ScvtFyFRRqdGNbDwr73Rsm6KvDIqBOpz4xskKQ2avPmfsLxGacnJgOhJzw7F7nVkZCHUntjl1MMZon+YHheVsDsU69QsFXzH2q+q900vZRehVXMcoLo+aqddMCEGNxR7bPHAPf8Bxv4BdLhD2bbBAhjZd+j2LyPOArRrmIoEhd+4uABBi29zlbrMjbiN1C0hvEIYs3co1qLPjZzRSno2S4Xs/G62i4pP5saMQ8H1qJOuQZyGfW6YuWFwQzGsflvgto/FTsc1GsjbJuhoKfWZG/cyhTMg2yz6NUsJArDp6Hnsy/W/0WfAzI0Zb/Ao4/5bgiDg1IVLgdfxuk5r3a9CTnATqlnKZBfqaBgKrkefG8PKYOZGKQY3FPu6PyDeiHPkf0OvG7RZKkjmJlSfDfdFVKPRUj43+PR9LscluwPD3vsdBcX+t3jwGrIeMJNhkgtawICxcruDeRfRc/rPgdeRlbnRsVkqVBOPLtkzif5GSrY14wy63itrvF6w/bPPjdkwuKGqwWIBWvQF/nkSSA0y03DQZqlgw8RDDOV1va7wIiW3z004gk06KPJ47HW3cJMMWZaRuckrKg1Rtpw+N3qOlvJ8DxFqlnIH3CrKFpzwqpNZAl2vVfXI3OjYoZh9bjTF4IaqloRqwIStwKgfgFve9X9d7Wgpzwuf1Pw6KjM3NROlv6JDs2Q2swXhOk1JTSzoGdx8uOIgBEHA+DkbsWzXaY8CdAxulHRWDfQ3k7ythO8iiQu8Ic1SRnYoVhPcMHOjugy59WCfm7AwuKGqxxYHNO8NdBoBDHrZ+7UTGwJvF7RZKtQ8Jer+S7YFuHCP79tCUTnBSAU3nssWbD6B4+cv4Yetp7A750LlSroGNwpuRxBoskafYy09O7RZmqVC7V+Pi0qYzVLM3KgsQ009mLlRisENVV0WC3DVQ8DoH4G2N4VeP1hw4wzVLOX0X0+OAPtMtIU/JNtVglRnZM9lVjiRU1DiX4CuM/YqyArI6HMDBOh0rahZSq8LBmAJ1Sylyzw34WRuAEXZNa2YNnOjBQ373GhWB9+XGdwQRY/MXsBdXwEPrgDqtwu8XrAmK6//vCXWc6prlgoYUAlOVE+MU1ZWANJ3MXd6vX7HzNXibhGZPjf5xSVwOiWyKlJk9LmxQJDO3CgZCh6p0VKRapaKmg7FnoF8Fc3cKC1ft0CcwQ1R9GnYCfjLb0DX0dKvy+1zo+FoqcD9SZyY/1BPZWUFINU52TPgCXSzz0tldk32L6X7C0sx89cD4pOQMxT7H6PisnJM+U/lLSQsEAJkbhT0udF1nhsDmqXUfiaBivfEzI2qMrSoh25lMXNDFJtsccBNbwGjF/q/9t1fAm+nV3ATZH9tG6RqUpTURb9aQuV/y4GCm2f/p/C+XQpYIOCVRXvEJypGS3266jCW7spxP7cGytxI9rmJfLOUd4AWBR2Ko2EouOzMjZLvZAQzN+Ec3ygKQvTC4IZISuY1wDMXgL9uAqrVE5dp0qFYu+AmXDar+PWXCm56tqjtftyxYXXJ7X/YcjLsOgRihRNNaieLT0JmbvxfP36+2C/7FLRZStZsuzo2S4W8/YLJ5rnRcyi4Zh1rdWiWMjJzE4nZmdksRVRF1G4BPLpfHDrueUNOXyGHgju8f4fL767MqgoB4J+ZEWBBr1Z13M/r10jA4ZduxH29mnutp+VcO74sAGqnJOBQ3kWUO4IfM0Ei6Px67TGv9xUwc6OoWUrPzI2C0WFaifWh4LLXNWufmzCCRw4FZ3BDJEvz3uINOQc8L/263NFSWp0cBGfYF0FrxYR8vpmbOtXiUTPR5n5+RYaYuXnyT+3wQO/KAEfd/axk1g1ObDl+Ade9thz3fbY26LpnCyVuqwD/iQil6+vfLHXi/EXpHanuc6NwKHikmqXMOhTc7+asKoMouX8v02RutKQ2ENepXAMwuCGSyxYPXP0I8NR5YOCL3q+dWA9sniNmbSLSLCWEXVZcxXBy34xGVuM0r7KvbV2ZxUm0VZ4yAvXF0YLn5e1QXlHQdY+dlX5dUebG47XRn66FU/IipmOzlFfmJsTrWpG8I7rcbX0/fybM3OjRoTjm+9yEytyoLNYADG6IlLJagZ7jgL/vBXr9rXL5goeBTwcBl875byM15DgcGmRuLAB2PTsIDVITvJbH2SxeZdsC3LdKz8yNZ5NXqCDKGqB5zOJR78CjpfyzF1Y44ZAcsBRrt19w/VbzvnyapSJ253g9OhSbJXMTogy/jFYYZQXcjH1uiKhGOtDvGWBqDnDt44AtETi2RgxyfLkuXiYKbgAgOcGGmkk2r2UWeAc3gR7rG9xUCrUfW6DgxqtDMSDd3OPfXGjxrUC4ZDVLGXD7hbA6FEs0S0WiP4aex0HWH92oPjfhliV7Q53KjTwGN0Thik8GrpsC3D038DpqZygOVl7YwY2lsiyvxT4n+QDBjZ7NUlYFmZtAwY33LMuB+9wIggC7o9xj3UC3X1B7vOU0S4XKguiRuQmnQ7Fvh/YIBTd6Zm4sMi6HUTPPjdoqxE7mRpspTokIaHk9cP/PwP5s4NxBYOu8yteKcsT7Vpksc+MuK9gyQ4Ib7yal4OvKydwEHgr+4JcbUP3wFrzpXjcAPUdLeY34CtY3SENhdXKX6lBstsyNwvpYrAg9mjF6+tzkF5fhx22nMELZhiHLjRYMboi01Lir+AMAcUnAxs8rX/voeu32o2lwI3FSldFZ1OzNUr4BklQ5guBE9s5c9LPaAXfXI0E6wFEd3IT+O607dBY9gu1H1+YYNZv6ZmqYuQmflsdPwMNfbcTqg2cxIknJZrGTuWGzFJFebnoLeHA5cM0E7cuOaOZGuskkYPONBkb1bIpfJvcFoGXmxl9Rqd2vjEDBlKDyxH6uuCzkOg5HiKkE9GyWUt2h2PczEq2ZGwXBTcAi9O5zozxzs/rgWTWVCFlutGBwQ6QXiwVo2Bno/yzw0Cqg5Q3ala3hJH4hZ8QN8HjK4MvC3H9gTWoloXndagC06VAcaCj4mgN5Fet6b+dw+q9bVKLuXlrFpaG3s3qNSIvCDsURytzkFkjPaSRJaebGagu+XtAyzZe5UbcZMzdEpERGe+Deb4Epx4FhH4Zfnp6ZG4slcAdXj8d/6tBAm/1LcN3w/PHBbVArJXjruc0SKLjxfCwd3Fg8XncJFEwVl4bOwEjXI/QFwSv75PP3WLIjB2XlGnVE95Bz4RIE1RkXn2BGg3mX5Hj5p90K1tYjcxPJPjcy9iu3LPkb6lRu5DG4IYqkxBpA1l3AY0eALqOADneqK0fP0VK+FyoZTVRaS6yYYPCha1tizn1XBl03cJ8b787PUkGGax3fJizp8tSd2OUEN17vwecC8uCXG/D57wdV7TuY4lI7Dpy5GEbmptIvu3OhxX/1pSGCuOPni2WXdfBM8Mkf3dx9bmQMBVeYuZn2vx3y6hCkDHWYuWFwQ2SE5DTg5reBYR8AA6cHv2+VFF373Ej1p5BYV8f/4pLiPO9KHlzgZinPx9Idil3ryBmdZVE0iZp0PQLxvVWEr4XbtL9JqQUCrBbp/YVSVFLm9fdfsOk4bn9/Vdh1mvD15qCfK2uALJ2UvMISmWtqkbmRXvzpqsMy6xCiUN5bSjEGN0RGslqBnmOByXuAv+0EMjrI207L4Mb3hOZbdsCbOup3oqudEh9gn/7kdCgO1OdGSebGpvL9yul47bmOvdx//TgtJxWsYAFQ5lD3OXpv+X7A65gBO05eCLtOi3bk+C/0uKDK6BXj5pToNyXJLKOlfMrek1MQTmGa1EGzcg1geHDz7rvvIjMzE0lJSejRowfWrg18k7wdO3bgtttuQ2ZmJiwWC2bMmBG5ihLprWYj4KGVwOiFQL02wdfVM3Pj21k5UECjY7NUveoet4QIccKtnSx9yfPNxtSvES+53o0dG8jK3FgD3IYiFDlxiWf2qbjMvwOyHidqCwTYy9V1BN59qsBru0Cj0bThEdwoOBBCyDlrfMo3us+NT9mP/2drGEWpq0/IEYHM3Mgzb948TJo0CU8//TQ2btyIrKwsDBw4EKdPn5Zcv7i4GC1atMBLL72EjAyFaXyiaJF5DfDgCmDMT0CXkdLr6B7cyGmW0i+4qZXs2Yk4+AnVGnDodOV2KQlWzLgry28tCwTUqZbgtW6gvjVqJy2U16HYOwviq7BEXWfmYCwQxMyNivdl8Wm6DDhJogp+f03P+34paBqUGvEmuT+nguAmgpmbcMo/HujO9iHrEOo7zeBGljfeeAMPPPAAxowZg3bt2mHmzJlISUnBrFmzJNe/8sor8eqrr+LPf/4zEhMTI1xbogiKTwKaXQ3c/A7w6EGg6dXer6/5ANixQJt9SXUo9jqJyWmi0pZVSYYowH/onmXUq5aAzNrJkus0rZ3idWG+sWMG4qz+F1GnU937VTpaSmr9Erv2o6WsFgG3vf87dp1S3pzke68uC7SbsfqS33v1bJaSvw9BZpYh50JFJ2WTZW7COZ53zlwdbmUkLd8jnXgwI8OCm7KyMmzYsAH9+vWrrIzVin79+mH1an3+MERRqVodYMxC8dYOdVqJyw7/BmQ/qU35ijI3kWmWUtSZUuJ+XX6ZhADzAmXWScYdXZtgQLt67mWjrmoKq0Rwo2fmxuY1iaD/cdXzVhePzt+ieBsrvI+nxaJds1RRSbnX83yPSRCVNEudypc3ssoVBF0qD7GiuLLkYocW34Vgn3OFwZPaz0uogDC8fkCRZdjtF/Ly8uBwOJCenu61PD09Hbt3K5nLILjS0lKUlpa6nxcUiH8cu90Ou13dpFyBuMrTulzyVmWPc3pH4KE/YN0wC5Zt82E9sS6s4gQA5XY74gSn14XJ6XRAKC93d950lNshVBxrm9Ph/o/IXlYK6V4s4bPby4CKfVrKy4KeqATB4XdhtQAYfEU9YL9rHSfK7WV+9W2QmgBHPDCwbX33uuXldsmOq2ov3sozN+rKUMpVZn5xGaAwEW4BUFZe7r5jhZbNUgWXyuB5VXhl0W482KYAjdKSFfV72nwsH3fK+IA6K4Ljs8V2NA7yR7bb7UC5XfIzf/B0EVqHmSpwOp0Bsw0OpwPHzxahmcyyLBaoa0EKEdwo/Q7odY2VI+bvLTV9+nRMmzbNb/mSJUuQkpKiyz6zs7N1KZe8Vd3jnAHUfwT1krai+8G3ESeo64/hcJRj4cKFGGL3PmGfzTuD85f2wjX/8LatW3DimNik0+XYMTSpWP77yl9xrer3ENxvK1agMFmMNuoU7UavIOsKjnK/k+7wFuW4TKgcPl1Scgm/r1gB3zmiz507i1ULF6LJ2c3oUrFs7R9/oIfT6RfgqL14y5kfxxoyc6M91/uxqLqNhoD/bTqG2zzK0iq4OXTsJFp7PLdAwPD3f8XjWQ7YS0tlHwy59Tl65DCaAHAKlqBlL1y4EKnFR3CdxGta3Irk2LGjAYOX/fv2YfWJEoyWfcVW97coL7cjIcjrSv7GFgian6OLi+XPc2RYcFO3bl3YbDbk5uZ6Lc/NzdW0s/CUKVMwadIk9/OCggI0adIEAwYMQGpqqmb7AcSoMjs7G/3790d8vF7/0xKPs8sQCMJjsJcWwLr1a9iyn1C0tc0WhyFDhiBuu82rW02d2rVQu3ELoOKr2aH9FcjKGiJu89/vgfPi8mt6XgXs1eJ9+OvduxdQvy0AwHKkJrAv8LpSF5ZnRg2C5eRG4ID4PCkxAX369AZ2ea9Xu1YtDBkyBJYt+cBRcVn37t1hPWwFfFq7ItUsJT2Tsh6ZG+/fSre9VC64ryBa9rlJqVkH8Jh/zwIBp4otGDJkCLJ3fgCUBt7Wu47y6hNfsz5wFgicNxENGTIEyNkK7JG3f5H8Y9KkcWPgXOVzz/pXr98EOBHkS+BD7d/CZrVJ9OhWV25+qUXzc7Sr5UUOw4KbhIQEdO3aFcuWLcPQoUMBiGm5ZcuWYfz48ZrtJzExUbLzcXx8vG4XRj3Lpko8zhUS6gLXPCLOl7P4n8CambI2s0A8hr59Z6wWi9dsrTarBXESx1mq061W4m1WwLVPJR0tXNvHxQG2ytyLBUC8zb+xyQrAGh8PeLyXuAD7Uz9DcWiezS1S+9HjDuxSc/zI5TspYo1EK2o4lcxCE1iJxDw/gPhZVfKZk/u+lu85g+7xgDPEXyo+Pt7rMyVnX0qObbCRYN9uOoEasksKJ9On3ecs9xJwucbnaCVlGTpaatKkSfjoo4/w+eefY9euXXj44Ydx8eJFjBkzBgAwcuRITJkyxb1+WVkZNm/ejM2bN6OsrAwnTpzA5s2bsX//fqPeApF5WG3A4JeBqbniEPIrhsnbLlSHYu8XKx865fTAVEtBh2LJzQX4jewKdrftQJ2mPSSqnElPaZ8b30zUO8M7Y9RVTVXtO3i9XL9VDgX32O62zo1wsUSbz0O5Q3rUkCAIUBJPy31friLldYlWFsQo+8RoN1pK9bYa9rlROy+UVgztc3PXXXfhzJkzeOqpp5CTk4NOnTph0aJF7k7GR48ehdVaGX+dPHkSnTt3dj9/7bXX8Nprr+Haa6/F8uXLI119InOKTxKHkANA53uA/KPAD38LvH7I0VIBHusZ3IQ95FyQCFgkTrbusj1fkz4p21T+O6x0nhubz0WhR/PaqF+/CbBJ3f5D1UvN27L6hAJxNotmzVLlPkPuXcdm7rpjii6Yct+XK5gM1SwFIODFP9C+lByTk/nFaKhBOWrWrxQquJFfrtrvi1YM71A8fvz4gM1QvgFLZmam7LkLiAhAq4qpFhp0Ag7+AhxeCRz4WVxmvwjMHw04fUYgBJuh2Oux9nOvVJatwZBzOZkb137kBFMq65FgswTtxwAEvj8WANRPTQKK9Bh2L753NZ1hfTsQx1ktmnV63pdbBM8e7q79vL5kL3rFya+r0sxNqGapR+dvwU31zqCPxGtybgESyh8Hz+JWj1avcI6n2m3t5Y6gQUk0BTeG336BiCKgUReg99+Be78DbnqrcvmO7/zXlZ250XGem3DvYeWXqRGk/+t27UdGs5Tq4EbGWTZ0gKFfh2K123puH28FBrevH2aNAKn36bqg5hWVIrdA7s0wlQQ34nqhgpv5G47jo18PBCgjUNnyBatvpDI3WsYjvhnISGNwQ1TVdB0NTM0BbnwdaHszYPVJ4J7YAKx5v/J5oAn9dG2WCrPPjc/tAcTHUuXon7mRE5iE7DCsQ8Y6nA7F8M3cWARMu+kKDeokwOJzUbR4va4kcyNzvYr9CTIuh4WXpOdZ8a1zZR2UDZ1W8lxJWfJp1yxldHBh9P6JyAjxycCV9wN3fQn84xDw2BGg2/9Jrmr7/W3AXvEfs1fQoWOzlCYdij3LQIBmqSCdjGWtK7MuIQRrlqooRN2+gwhvKLjg1f8lMd6qSQfSUMPgtcqEeK8nCpW5UVKmmvWD7T1SLTyh6qusWYqZGyIyUlIqkJwG/OlN4M9z/F625B8GZrQHzh7waZZSGdzIukGhFvew8um3I9ksJZW50fikLKP+1RJCXL50yNxUdihWM1rKe7vkOKsmdZSuixDi9UDkriuuFx8Xeii7FkO+5ZYdXrOhPs1SykZLqaqCZgzvUExEJtLmRuCZC8CJjXDsWQRh5VuIc5YAF88AM3sBdo8ZQtU2S1msoS/4XhdKDZqlAva5Ebx/A2EEU4GqEro8I5qlxOwLMKpnM2Cjsm3F5iGPzE2c2vn+fevkfwG1eD3WfrSUq0yHoP5qrEXQo22fG3ViKXPD4IaI/DXqAmf9DlhYeAVuzMpAXPY/gRPrvdc5tkZl4TJOveFmbgTBpz9xiD43MoaCqyan+S7ke9T+QpEcb8N7d3TBoLp5ioMb3yDEAmiYuQnc10TPZqmaKYnARW3KVLO+X1DnExx0a1YLOKH9fpVsp2xSQlVV0AybpYgoKKFRF+C+bGDIa94vrP1QXYFymqV8m5QU8+1Q7JvJ8Vjuuw9d73YeQKgmPh0yNwlWYFD7BqrKFu8C7tsvSpvgJlhHWj061brWa5AW+l6DSifrC2cSP99yMmomyy7JDM1SSQZHFwxuiCg0qxXo/gDwz1Ni35wW1/mPspJLcZ8bDUZ+BOxzo2AouJ5CZXd0Cbikslby+AchAZr9VAjWLKWkrkqbpaxWOX1ugpchd7mcdf2eB7k9g39Z6oTqFK7k/aQYfGccBjdEJF9CijiqauQCcYTVPf8BUhspK0POSVqTZinfPjfBbr9gbObGYkCzlGR/IwW8/ooaZW4e6NU8ROZGPqXNUnKCbqVBjFZ9hKolWFEzWX600DajOn7++7XQ/nOjoDyDJ9xlcENE6iRWF2dAnrQTuOU9cVlC9dDbycrcaNGh2LdpK0jmRo/gQUu6XCjCy9x4zTkTKDOm0OQBrYOOGlISLEzq31rWekmue4bJCm60WS69buD3NrxHU9gUdGKJs1qQFG/TZBSXJ4O70SjC4IaIwtd5hDjK6p8ngKsfCb6u54irQLTO3Cjqc2PGQEfPzI2a2y9INBdpkfESBPRpXddnX+r63CTInP9/aKeKOzrJyCgGnqwv/NsvBNu70nu2ds+shcQ4q+bBiD5D8fXB4IaItDXgeeDpfOAvvwKdRvi/LusiqEUfGBl9QiT73BjQoTgUPerkfu/KN/UdCq5dQCigQ8NUv2Uuii7WMo9ZbVfnkDCapQIN5bcpuMJqmWUZ2rkR0lISmLkhItKUxQI0yAKGvgc8cVq85YOL5+NAws6k+GZuAtw4MxJDwbVgumYpICnO8/KhUYdiieZDtc1S8utTsZ6sUXzSAgU3s/+vh+wygnYoVnhs461Q1Iwll9bBkp44zw0R6SsuUbxZZ99/AhdPA3VaAd3/ArzfM/A24WZSfG+/EKgcswwFD8lcHYqnDL4cKcdOA3s8y9IiuPH/u7kuqN+NvRrnNuQAW2SWJXcGbUFecNP38noo2xcocyP9mWnXsIa8OkDrrIhQUabWmRvtR6vphZkbIoqMGulARgfxvlb12gD9pgGXDRIf+5p9O3DpfMUTlSdo3yAl2L2lvBI3Jvzv1GRDwWsk2nyaXLQaCu4fJN17VVNk/60POjethRvaKLjzuNJjFiK4aVIrJeDFPWCfGEXHxHvdxwddrmBb6f1q3ufG6IhFAWZuiCjyrFag10QAE4EDvwBzRwB2n+lhvxgKtLg2jAu7jMyNSYaCh6RHwBVGh2L/G5Pql7lJr5GI9PSKDIiSuspd17W/EPPcpKcm4lCA16olWIEyycLl1QH+WZGOjWrK3jbQfu/o0gjYGUYxPqKpQzGDGyIyVsvrgCnHxYDn9C5g+UvAzgXAqc3ijxpSzVJSzRSCVPbChJkbXZqlJDpTK9reJ7jRKgDzK0dl3xPZgZC8Zqm61RMDX9wD7UtBff2TImEc34pVnxt6habBzYB29SubIk2OzVJEZDxrxamoflvgzs/FeXNaDwBsCSoLlOpzEyS48evAbLL8uy7xlvpmKf+OvxpmbvwybioDT6WZmxDBzU1ZDXFNyzoK9yW/vtUSQl2OlWdNZI6Gl61GopJ8CIeCExF56zwCGDEfeGQD0O0+oP4VyraXukhKZm4CDQU3UfYm0Bw9WpavZhu/zI0WdZTKUEQqcxM8EqiWGIeH+rRQti8F9fVrhvIN6hS9d/WdxWWVGwXYLEVE5pXWFPjTG+JjewlQWgB8fhNwZnfobf06FEuNnomCZik9gy3VfWV8t9OoWUoyc+NzGw3ZZWmbuQm6fw0yNyk6ZG60/9wobxozCoMbIooO8Uniz7g14nOnE8h+ElgzE3CWe6/7Wiv/7YNmbkzcoVjL/ixala1Xh2LJ5kS1mRu56yoIbgKVqUHmJmTGygyZmyjCZikiik5WKzDwBWDidvHnskHB1z/yu/8yqYuA6S4IWgUOUkUHmtww5Ib+GRW9MjdaTQUQdJ8ALKHvCq5n5ib0uibI3CjqIM0+N0RE6qU2ANKaAHfPA256O/B66z+RWBigQ7GZAhzVAYiswqGuQ7HPdpoNBZe4AafqzI22o6UU71/p+n7vW4OyNP8cm+h7EQKbpYgodnQdJf4AQM524H8TgBPrA69vv1QxWaAOI3+0YspmKd8gRKs6hsrc6NHnpmK9cPrcaLJ+sHWVfiaNz9wY/R1icENEsSmjPfDAMqAwB8g/Bmz52j97U1YEvJzpvUzv0UmK6RlsadShWKtOz5K3zVCbudH29guK9690/WB9btSWxcwNEVGMqpEh/jS5Ehj0ErDjO6BmY7Ez8okN/usveizydQxGz2BLqhlI1nYSHYqjNXOj6MaZSoMbJX+3IGUrbvYzQ+bGWOxzQ0RVR1wCkHUXkHkNcP8yYOT3RtcoNLUBiKyy1QYlvhdbDTsUR7rPjTtzI2PGO8WZGyW3iwiRqVEU2zBzw8wNEVVNFot476pnLojPL54F1n0kDi1337TTDEzYLKXnUPAqm7kJtV8T9HfhaCkioihTrQ7Q93HgscPA2DVAy+uBuGSja2XODsV6DgWP9Dw37HOjADM3RETRq34b4N7vxMdlF4F59wIHlhlUGT07OKvN3PjO/qxh5ibYe9XzruCGZ25irM+NwXEQgxsiomASqgH3fiuOujqzG1gwFig4Ebn963pfKbUdiuGznYaZm4jfOFPBUHA9+9yE2pcpMjfRg8ENEZEcrlFXE7YA1jigKBdYOQNY876++9W7WUqToeBaZm6k9uW5H7lFRdk8N0HfWxRmbtjnhogoitjixc7INTKAwS+JHZIfPwr0+QcweqFOO9WxQ7Ga7IJeQ8GrdOaGfW60xOCGiChcSTWB66eKQ8zHrQOuGqdd2XrefkHLoeB6TeKnNnMjdaNUyX3qmLkJZyi432vRlbnhaCkiolhS7zJg0IvAP08BU44DfacANZuIr11+IwAZ86l40v1eV2qHgvvej0uLAMzIzI3B89yEk6kJVFQVztywzw0RkR4SUsTffR8Huo4Gdv0P6DQCuHQOWPshsOotmQVp1Z9Fqmi1HYp1ureUlpkbXfrcKKRV5kbx8TU+c2M0BjdERHqrkQF0f0B8nJAC9H9WDHS2/hu4eBrY+EXgbd/pBlh1SrKbsUOxZpkbmetGS58bNe+9Cmdu2CxFRGSEepcDNzwJ3PwO7H8/iP31BkKo3cJ/vdILOs6YrFGH4iqTuVEa3GgUjClumjRD5sbYQIiZGyIioyWlYkfjEWg2ZAjinaXiMPM6LYEDvwBfDtVhhxa4AxItOhRHLHOjpCgz3BVcyz43zNwoweCGiMhMEquLPwDQ8jrgr5uA/KNAci1g7xLgl+fD34fFWnHxVxmUMHOjbR0A9rnRGIMbIiIzq91C/AGABllA53uAHyaKt4U4sRGwX1RepsUiXvccdpVNXr6jpZzQL3Pjcw8r2UXF2Dw3UZa5sRgcCDG4ISKKJqkNgLvnVT7/431g7UdAn8niBbpGBrDuE2DX90EKqRj2vGQqsPO/yuvg2wyl5SR+mt04M4YyN1HZ58ZYDG6IiKLZVQ+LP54SagD7lwXO6rjmdFET2ADQbSi4ZDOZ2tFScoObir45ZsvcsM9NWBjcEBHFmsZdgb/vFoOYi2eA7KeA5NrAxs+BG54G1s8CLhwLYwc6dSiWmo3ZK3OjVR8Wn30C8ibxq+p9bqIIgxsioliUlCr+TqwB3PWV+Pjmt8XfVwwFNn0FpNQRR2bJnlCwwsWzQFmxx4Iq0qE4on1uwqBX5oZDwYmIyLRqtwBueKry+fVPApu+FO+RdfQPcQblYLbM8X6u61DwgE9CFCU3uFEwFFzXzE2QBar73GgtejJBDG6IiKo6WzzQ7f/Ex+1vA/o/B7zbHcg/Im/7TV8CezS4I7qRmRurTca6SoMbLQMSFX1utBZFHYo5QzEREXmLTwLG/ARk9gaa9QKGfQA8fhQY/GrgbYrParBjiYun3jfOdMrsUKwmOxVOn5uwOmzr1aE4ejBzQ0RE/mo2Akb/4L2sx4PAlfcDuduBLXPFWZR/eREoztNmnwLM2+dGzXB3TfvcqMncGNfnxsI+N0REFDWsVqBBR/EHALqOAfYtBjZ+CTS5ErhsMLD9P0DJBWDtBwoLl8iOOMqAU1uB+m39XwtalNYdiiOcufEK6qReD1pYgDLDFT2ZIAY3RESkntUKXD5Y/HG5fqp4YW3aQ14HZZd59wCFp7yXbf+P+NOqP9Dsavn1OrlJ3nrM3KgoV9bK2u5bIQY3RESkPYtF7Jzc/jZxNNau/wGXDQKWvwhs/ELMyNRo4B3M+AY2nvZniz9aM2vmRotJEpm5ISIi0klSKtB5hPj4xtfFH5eNXwDfP+K/TVwSUF6if91Mm7kJY4bisLYJVlw4Q9sji8ENEREZp8tIoNM94kzK8cliUJO3B0hvD6x4GcjbC2TdDcy+TZ/9y57nRk3mRKvMjcRzOWVpPomfkmDNWAxuiIjIWFYrUCO98nlGB/F338crl03YIl5cj28Adv8A9JoozrJ8cpN4d/TuD8jv2+Mpd5v4O1RwU14a2Xlu/G4YaoLbLygIbjhaioiIKJRameLv2i2AjneIjxt2Fn+XFoq3mWh7E3DgZyBvH5B/FBj+NfDz88ChX4GCE8HLtyUEf/2lJjJnMfZQWiB/3VA3ymTmRhEGN0REFN0Sa4i/m/cRfzwNmyn+FgQ4Vr2DzftOoHPSMVj3/Fi5Tnw1oFW/0PtRenH/4W8KVvYNZpw+r0VX5sboTjcMboiIKPZZLHD2eBjHzy5Ex8GDYY2LAwQHcPYAUL0+kFIbmLQb+N9fgX1LIl+/0iLv5xc9JkYsOg0Un5Nflitj4ygLv15e5TJzQ0REZE4Wi9jPB1agfpvK5akNgBHzvdd1lIvrH/ldvHt6zlZg6HuAxQY06gIsngpsng20Hijei+v0TnG75FrApfPy63TxtPfzJVMrHx9Ypujt4cAyoNNwYNmzyrYLJYpu58DghoiIKBBbxWWyeW/xx9ct/xJ/ADEQungaSG0oPt+zCFj3kdhsdmKD2A8oErbNB5zlwMHl2pabu13b8nTE4IaIiEgLtrjKwAYALh8k/gBi1uP8IaBWc7Gj8bmDQO4OoOX1wNJngJ3fixmiP70JbPtGesLCxFSxb9COb0PXZcd3mrwltThaioiIKNZZLOJILwBIqimO9HKN9rr1Q/HHJevP4t3KLVbx9hV5e4AmV4mBk8UCNOkBXDgGHFoBJNcWfwNA/SuAP70BzBqovH4tb6hs/sq6W8xA7V8qPk9rJja5AUDzawFrnPKmsghjcENERGQ2Vpv4u1lP8cfTVQ95PxcE4MJxsWN0XCIw4htx8sNu/yf2DVo+Xcz4NL1KvKGp1Qac3g38/jZQfBa451sgIQVYMFa8SenglwFbPPDLC0DrAUDZRWDZc8DV48XbaTjswO4fgfgk4Lc3xDqc2uxVJbstRZ/jIhODGyIiomhmsQBpTSqft+4v/rj0e7rycUpt8XfTHkDT2d7lDH3P+/mA5ysfe94YNS4RyLpLfNzuFvF3aREw+3agvAT2IW/ijw1HMUTdu9EEgxsiIiIKT2J14P8WiY/tdgAR6jwdgMLpFomIiIjMjcENERERxRQGN0RERBRTGNwQERFRTDFFcPPuu+8iMzMTSUlJ6NGjB9auXRt0/fnz56NNmzZISkpChw4dsHDhwgjVlIiIiMzO8OBm3rx5mDRpEp5++mls3LgRWVlZGDhwIE6fPi25/u+//47hw4fjvvvuw6ZNmzB06FAMHToU27dHz7TQREREpB/Dg5s33ngDDzzwAMaMGYN27dph5syZSElJwaxZsyTXf+uttzBo0CA8+uijaNu2LZ577jl06dIF//rXvyJccyIiIjIjQ+e5KSsrw4YNGzBlyhT3MqvVin79+mH16tWS26xevRqTJk3yWjZw4EAsWLBAcv3S0lKUlpa6nxcUFAAA7HY77HZ7mO/Am6s8rcslbzzOkcHjHDk81pHB4xwZeh1nJeUZGtzk5eXB4XAgPT3da3l6ejp2794tuU1OTo7k+jk5OZLrT58+HdOmTfNbvmTJEqSk6DM9dHa2xA3PSHM8zpHB4xw5PNaRweMcGVof5+LiYtnrxvwMxVOmTPHK9BQUFKBJkyYYMGAAUlNTNd2X3W5HdnY2+vfvj/j4eE3Lpko8zpHB4xw5PNaRweMcGXodZ1fLixyGBjd169aFzWZDbm6u1/Lc3FxkZGRIbpORkaFo/cTERCQmJvotj4+P1+3DrWfZVInHOTJ4nCOHxzoyeJwjQ+vjrKQsQzsUJyQkoGvXrli2rPLW6U6nE8uWLUPPnj0lt+nZs6fX+oCY+gq0PhEREVUthjdLTZo0CaNGjUK3bt3QvXt3zJgxAxcvXsSYMWMAACNHjkSjRo0wffp0AMCECRNw7bXX4vXXX8eNN96IuXPnYv369fjwww+NfBtERERkEoYHN3fddRfOnDmDp556Cjk5OejUqRMWLVrk7jR89OhRWK2VCaarr74ac+bMwRNPPIF//vOfaN26NRYsWID27dsb9RaIiIjIRAwPbgBg/PjxGD9+vORry5cv91t2xx134I477lC1L0EQACjrmCSX3W5HcXExCgoK2J6rIx7nyOBxjhwe68jgcY4MvY6z67rtuo4HY4rgJpIKCwsBAE2aNDG4JkRERKRUYWEhatasGXQdiyAnBIohTqcTJ0+eRI0aNWCxWDQt2zXM/NixY5oPM6dKPM6RweMcOTzWkcHjHBl6HWdBEFBYWIiGDRt6dVeRUuUyN1arFY0bN9Z1H6mpqfziRACPc2TwOEcOj3Vk8DhHhh7HOVTGxsXwe0sRERERaYnBDREREcUUBjcaSkxMxNNPPy05IzJph8c5MnicI4fHOjJ4nCPDDMe5ynUoJiIiotjGzA0RERHFFAY3REREFFMY3BAREVFMYXBDREREMYXBjUbeffddZGZmIikpCT169MDatWuNrlJUmT59Oq688krUqFED9evXx9ChQ7Fnzx6vdUpKSjBu3DjUqVMH1atXx2233Ybc3FyvdY4ePYobb7wRKSkpqF+/Ph599FGUl5dH8q1ElZdeegkWiwUTJ050L+Nx1saJEydwzz33oE6dOkhOTkaHDh2wfv169+uCIOCpp55CgwYNkJycjH79+mHfvn1eZZw7dw4jRoxAamoq0tLScN9996GoqCjSb8XUHA4HnnzySTRv3hzJyclo2bIlnnvuOa/7D/FYK/frr7/ipptuQsOGDWGxWLBgwQKv17U6plu3bkXv3r2RlJSEJk2a4JVXXtHmDQgUtrlz5woJCQnCrFmzhB07dggPPPCAkJaWJuTm5hpdtagxcOBA4dNPPxW2b98ubN68WRgyZIjQtGlToaioyL3OQw89JDRp0kRYtmyZsH79euGqq64Srr76avfr5eXlQvv27YV+/foJmzZtEhYuXCjUrVtXmDJlihFvyfTWrl0rZGZmCh07dhQmTJjgXs7jHL5z584JzZo1E0aPHi2sWbNGOHjwoLB48WJh//797nVeeukloWbNmsKCBQuELVu2CDfffLPQvHlz4dKlS+51Bg0aJGRlZQl//PGH8NtvvwmtWrUShg8fbsRbMq0XXnhBqFOnjvDDDz8Ihw4dEubPny9Ur15deOutt9zr8Fgrt3DhQmHq1KnCt99+KwAQvvvuO6/XtTimFy5cENLT04URI0YI27dvF77++mshOTlZ+OCDD8KuP4MbDXTv3l0YN26c+7nD4RAaNmwoTJ8+3cBaRbfTp08LAIQVK1YIgiAI+fn5Qnx8vDB//nz3Ort27RIACKtXrxYEQfwyWq1WIScnx73O+++/L6SmpgqlpaWRfQMmV1hYKLRu3VrIzs4Wrr32Wndww+Osjccee0zo1atXwNedTqeQkZEhvPrqq+5l+fn5QmJiovD1118LgiAIO3fuFAAI69atc6/z008/CRaLRThx4oR+lY8yN954o/B///d/XstuvfVWYcSIEYIg8FhrwTe40eqYvvfee0KtWrW8zhuPPfaYcPnll4ddZzZLhamsrAwbNmxAv3793MusViv69euH1atXG1iz6HbhwgUAQO3atQEAGzZsgN1u9zrObdq0QdOmTd3HefXq1ejQoQPS09Pd6wwcOBAFBQXYsWNHBGtvfuPGjcONN97odTwBHmetfP/99+jWrRvuuOMO1K9fH507d8ZHH33kfv3QoUPIycnxOs41a9ZEjx49vI5zWloaunXr5l6nX79+sFqtWLNmTeTejMldffXVWLZsGfbu3QsA2LJlC1auXInBgwcD4LHWg1bHdPXq1ejTpw8SEhLc6wwcOBB79uzB+fPnw6pjlbtxptby8vLgcDi8TvQAkJ6ejt27dxtUq+jmdDoxceJEXHPNNWjfvj0AICcnBwkJCUhLS/NaNz09HTk5Oe51pP4OrtdINHfuXGzcuBHr1q3ze43HWRsHDx7E+++/j0mTJuGf//wn1q1bh7/+9a9ISEjAqFGj3MdJ6jh6Huf69et7vR4XF4fatWvzOHt4/PHHUVBQgDZt2sBms8HhcOCFF17AiBEjAIDHWgdaHdOcnBw0b97crwzXa7Vq1VJdRwY3ZDrjxo3D9u3bsXLlSqOrEnOOHTuGCRMmIDs7G0lJSUZXJ2Y5nU5069YNL774IgCgc+fO2L59O2bOnIlRo0YZXLvY8u9//xuzZ8/GnDlzcMUVV2Dz5s2YOHEiGjZsyGNdhbFZKkx169aFzWbzG02Sm5uLjIwMg2oVvcaPH48ffvgBv/zyCxo3buxenpGRgbKyMuTn53ut73mcMzIyJP8OrtdIbHY6ffo0unTpgri4OMTFxWHFihV4++23ERcXh/T0dB5nDTRo0ADt2rXzWta2bVscPXoUQOVxCnbeyMjIwOnTp71eLy8vx7lz53icPTz66KN4/PHH8ec//xkdOnTAvffei7/97W+YPn06AB5rPWh1TPU8lzC4CVNCQgK6du2KZcuWuZc5nU4sW7YMPXv2NLBm0UUQBIwfPx7fffcdfv75Z79UZdeuXREfH+91nPfs2YOjR4+6j3PPnj2xbds2ry9UdnY2UlNT/S40VdUNN9yAbdu2YfPmze6fbt26YcSIEe7HPM7hu+aaa/ymMti7dy+aNWsGAGjevDkyMjK8jnNBQQHWrFnjdZzz8/OxYcMG9zo///wznE4nevToEYF3ER2Ki4thtXpfymw2G5xOJwAeaz1odUx79uyJX3/9FXa73b1OdnY2Lr/88rCapABwKLgW5s6dKyQmJgqfffaZsHPnTuHBBx8U0tLSvEaTUHAPP/ywULNmTWH58uXCqVOn3D/FxcXudR566CGhadOmws8//yysX79e6Nmzp9CzZ0/3664hygMGDBA2b94sLFq0SKhXrx6HKIfgOVpKEHictbB27VohLi5OeOGFF4R9+/YJs2fPFlJSUoSvvvrKvc5LL70kpKWlCf/973+FrVu3CrfccovkUNrOnTsLa9asEVauXCm0bt26Sg9PljJq1CihUaNG7qHg3377rVC3bl3hH//4h3sdHmvlCgsLhU2bNgmbNm0SAAhvvPGGsGnTJuHIkSOCIGhzTPPz84X09HTh3nvvFbZv3y7MnTtXSElJ4VBwM3nnnXeEpk2bCgkJCUL37t2FP/74w+gqRRUAkj+ffvqpe51Lly4JY8eOFWrVqiWkpKQIw4YNE06dOuVVzuHDh4XBgwcLycnJQt26dYW///3vgt1uj/C7iS6+wQ2Pszb+97//Ce3btxcSExOFNm3aCB9++KHX606nU3jyySeF9PR0ITExUbjhhhuEPXv2eK1z9uxZYfjw4UL16tWF1NRUYcyYMUJhYWEk34bpFRQUCBMmTBCaNm0qJCUlCS1atBCmTp3qNbyYx1q5X375RfKcPGrUKEEQtDumW7ZsEXr16iUkJiYKjRo1El566SVN6m8RBI9pHImIiIiiHPvcEBERUUxhcENEREQxhcENERERxRQGN0RERBRTGNwQERFRTGFwQ0RERDGFwQ0RERHFFAY3RFTlWSwWLFiwwOhqEJFGGNwQkaFGjx4Ni8Xi9zNo0CCjq0ZEUSrO6AoQEQ0aNAiffvqp17LExESDakNE0Y6ZGyIyXGJiIjIyMrx+XHcFtlgseP/99zF48GAkJyejRYsW+Oabb7y237ZtG66//nokJyejTp06ePDBB1FUVOS1zqxZs3DFFVcgMTERDRo0wPjx471ez8vLw7Bhw5CSkoLWrVvj+++/1/dNE5FuGNwQkek9+eSTuO2227BlyxaMGDECf/7zn7Fr1y4AwMWLFzFw4EDUqlUL69atw/z587F06VKv4OX999/HuHHj8OCDD2Lbtm34/vvv0apVK699TJs2DXfeeSe2bt2KIUOGYMSIETh37lxE3ycRaUST228SEak0atQowWazCdWqVfP6eeGFFwRBEO8Y/9BDD3lt06NHD+Hhhx8WBEEQPvzwQ6FWrVpCUVGR+/Uff/xRsFqtQk5OjiAIgtCwYUNh6tSpAesAQHjiiSfcz4uKigQAwk8//aTZ+ySiyGGfGyIy3HXXXYf333/fa1nt2rXdj3v27On1Ws+ePbF582YAwK5du5CVlYVq1aq5X7/mmmvgdDqxZ88eWCwWnDx5EjfccEPQOnTs2NH9uFq1akhNTcXp06fVviUiMhCDGyIyXLVq1fyaibSSnJwsa734+Hiv5xaLBU6nU48qEZHO2OeGiEzvjz/+8Hvetm1bAEDbtm2xZcsWXLx40f36qlWrYLVacfnll6NGjRrIzMzEsmXLIlpnIjIOMzdEZLjS0lLk5OR4LYuLi0PdunUBAPPnz0e3bt3Qq1cvzJ49G2vXrsUnn3wCABgxYgSefvppjBo1Cs888wzOnDmDRx55BPfeey/S09MBAM888wweeugh1K9fH4MHD0ZhYSFWrVqFRx55JLJvlIgigsENERlu0aJFaNCggdeyyy+/HLt37wYgjmSaO3cuxo4diwYNGuDrr79Gu3btAAApKSlYvHgxJkyYgCuvvBIpKSm47bbb8MYbb7jLGjVqFEpKSvDmm29i8uTJqFu3Lm6//fbIvUEiiiiLIAiC0ZUgIgrEYrHgu+++w9ChQ42uChFFCfa5ISIiopjC4IaIiIhiCvvcEJGpseWciJRi5oaIiIhiCoMbIiIiiikMboiIiCimMLghIiKimMLghoiIiGIKgxsiIiKKKQxuiIiIKKYwuCEiIqKYwuCGiIiIYsr/AxcrFfhl2SgPAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('Loss history')\n",
    "plt.grid(True)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(train_loss_history, label='train')\n",
    "plt.plot(test_loss_history, label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9db7ea-7efd-4218-a3b2-c3ca86b969e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
