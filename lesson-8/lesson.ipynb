{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a12917-ec3a-4985-b465-b1dde00954ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tripplet loss -> calculating special characteristics space in which the similar images will have the long distance\n",
    "\n",
    "# Contrasitive loss -> calculating the most different images with maximization by the special characteristic spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "29ba1660-7cd2-4544-809d-a0127ee6a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import (Input, Conv2D, Conv2DTranspose, MaxPooling2D,GlobalMaxPooling2D, BatchNormalization,\n",
    "Flatten, Dropout, Dense, GlobalAveragePooling2D, Activation, LeakyReLU, Reshape)\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98ac88ce-5887-45da-a595-d873b8f23882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "print (x_train.shape)\n",
    "print (y_train.shape)\n",
    "print (x_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6f55771-f798-4e4c-99a7-f6984eaa4ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)/255\n",
    "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)/255\n",
    "\n",
    "y_train = to_categorical(y_train,10)\n",
    "y_test = to_categorical(y_test,10)\n",
    "\n",
    "print (x_train.shape)\n",
    "print (y_train.shape)\n",
    "print (x_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80234fad-95ea-4927-b3c4-2e86dab230a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  (None, 28, 28, 16)        64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 14, 14, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 14, 14, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, 14, 14, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 7, 7, 32)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, 7, 7, 64)          256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 3, 3, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_24 (Ba  (None, 3, 3, 64)          256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 3, 3, 64)          0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 1731      \n",
      "                                                                 \n",
      " batch_normalization_25 (Ba  (None, 3)                 12        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                40        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25783 (100.71 KB)\n",
      "Trainable params: 25425 (99.32 KB)\n",
      "Non-trainable params: 358 (1.40 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(28,28,1))\n",
    "\n",
    "x = Conv2D(filters=16, kernel_size=(3,3), padding='same',activation='relu')(input)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=(3,3), padding='same',activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=(3,3), padding='same',activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "output = Dense(10,activation='softmax')(x)\n",
    "\n",
    "softmax_model = Model(input,output)\n",
    "\n",
    "softmax_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer = Adam(),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "softmax_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ffadeee-9da2-4a05-8beb-c9d8543fdc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "120/120 [==============================] - 35s 289ms/step - loss: 0.6420 - accuracy: 0.9233 - val_loss: 0.5853 - val_accuracy: 0.9553\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 34s 285ms/step - loss: 0.5178 - accuracy: 0.9485 - val_loss: 0.4536 - val_accuracy: 0.9632\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 35s 288ms/step - loss: 0.4235 - accuracy: 0.9585 - val_loss: 0.3603 - val_accuracy: 0.9666\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 34s 283ms/step - loss: 0.3541 - accuracy: 0.9639 - val_loss: 0.3076 - val_accuracy: 0.9671\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 34s 285ms/step - loss: 0.3003 - accuracy: 0.9667 - val_loss: 0.2157 - val_accuracy: 0.9747\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 34s 286ms/step - loss: 0.2576 - accuracy: 0.9700 - val_loss: 0.1992 - val_accuracy: 0.9757\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 35s 292ms/step - loss: 0.2264 - accuracy: 0.9717 - val_loss: 0.1865 - val_accuracy: 0.9745\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 34s 286ms/step - loss: 0.1997 - accuracy: 0.9735 - val_loss: 0.1388 - val_accuracy: 0.9782\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 34s 284ms/step - loss: 0.1794 - accuracy: 0.9752 - val_loss: 0.1319 - val_accuracy: 0.9807\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 34s 285ms/step - loss: 0.1607 - accuracy: 0.9766 - val_loss: 0.1265 - val_accuracy: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f8194c484d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_model.fit(x_train,y_train, validation_data=(x_test,y_test),batch_size=500,epochs=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "283f28b8-a00b-4b7c-855a-d15ec1ca5a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'keras-arcface'...\n",
      "remote: Enumerating objects: 36, done.\u001b[K\n",
      "remote: Total 36 (delta 0), reused 0 (delta 0), pack-reused 36\u001b[K\n",
      "Receiving objects: 100% (36/36), 450.70 KiB | 1.02 MiB/s, done.\n",
      "Resolving deltas: 100% (15/15), done.\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/4uiiurz1/keras-arcface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "19a55108-9e6c-410e-9239-497b2f10d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/tf/notebooks/AiLearning/NeuralNetworks/lesson-8/keras-arcface')\n",
    "from metrics import ArcFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d440338-83df-48e8-b187-b4c389b66723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.path = [\n",
      "    '/tf/notebooks/AiLearning/NeuralNetworks/lesson-8',\n",
      "    '/usr/lib/python311.zip',\n",
      "    '/usr/lib/python3.11',\n",
      "    '/usr/lib/python3.11/lib-dynload',\n",
      "    '/usr/local/lib/python3.11/dist-packages',\n",
      "    '/usr/lib/python3/dist-packages',\n",
      "]\n",
      "USER_BASE: '/root/.local' (exists)\n",
      "USER_SITE: '/root/.local/lib/python3.11/site-packages' (doesn't exist)\n",
      "ENABLE_USER_SITE: True\n"
     ]
    }
   ],
   "source": [
    "!python -m site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7224f5-0ffe-4ca2-b2c5-da381223da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "924d6af6-2fe7-43d3-9054-f615febde996",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 64\n",
    "(x_train, _),(x_test, _) = keras.datasets.fashion_mnist.load_data()\n",
    "x_all = np.concatenate([x_train,x_test])\n",
    "x_all = x_all.astype('float32')/255\n",
    "x_all = np.reshape(x_all,(-1,28,28,1))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x_all)\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8f81ec95-ab43-4d7d-9e99-808aca9a631d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 14, 14, 64)        640       \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " global_max_pooling2d_1 (Gl  (None, 128)               0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74625 (291.50 KB)\n",
      "Trainable params: 74625 (291.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "    Input(shape = (28,28,1)),\n",
    "    Conv2D(filters=64,kernel_size=(3,3),strides=(2,2),padding=\"same\"),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Conv2D(filters=128,kernel_size=(3,3),strides=(2,2),padding=\"same\"),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    GlobalMaxPooling2D(),\n",
    "    Dense(1)\n",
    "    ],\n",
    "    name = \"discriminator\"\n",
    ")\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "188c2717-6a38-484e-a44f-30830233b514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 6272)              809088    \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 6272)              0         \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTr  (None, 14, 14, 128)       262272    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2D  (None, 28, 28, 256)       524544    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 28, 28, 1)         12545     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1608449 (6.14 MB)\n",
      "Trainable params: 1608449 (6.14 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "\n",
    "generator = Sequential(\n",
    "    [\n",
    "        Input(shape=(latent_dim,)),\n",
    "        Dense(7*7*128),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Reshape((7,7,128)),\n",
    "        Conv2DTranspose(filters=128,kernel_size=(4,4),strides=(2,2),padding=\"same\"),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Conv2DTranspose(filters=256,kernel_size=(4,4),strides=(2,2),padding=\"same\"),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Conv2D(filters=1,kernel_size=(7,7),activation=\"sigmoid\",padding=\"same\"),\n",
    "    ],\n",
    "    name='generator'\n",
    ")\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0a8ba1fd-c00b-45ea-8717-ffcc3d995ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gan (Model):\n",
    "    def __init__(self,discriminator,generator,latent_dim):\n",
    "        super(Gan,self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self,dis_opt,gen_opt,loss_funct):\n",
    "        super(Gan,self).compile()\n",
    "        self.dis_opt=dis_opt;\n",
    "        self.gen_opt=gen_opt;\n",
    "        self.loss_funct = loss_funct;\n",
    "\n",
    "    def train_step (self,real_images):\n",
    "        if isinstance(real_images, tuple):\n",
    "            real_images = real_images[0]\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(batch_size, self.latent_dim)\n",
    "        )\n",
    "        # generating image:\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "        # making discriminator input vector:\n",
    "        combined_images = tf.concat([generated_images,real_images],axis=0)\n",
    "        # making discriminator output vector:\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size,1)),tf.zeros((batch_size,1))],axis=0\n",
    "        )\n",
    "        # correcting discriminator:\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_funct(labels,predictions)\n",
    "        grads = tape.gradient(d_loss,self.discriminator.trainable_weights)\n",
    "        self.dis_opt.apply_gradients(\n",
    "            zip(grads,self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(batch_size, self.latent_dim)\n",
    "        )\n",
    "        misleading_labels = tf.zeros((batch_size,1))\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_funct(misleading_labels,predictions)\n",
    "        grads = tape.gradient(g_loss,self.generator.trainable_weights)\n",
    "        self.gen_opt.apply_gradients(\n",
    "            zip(grads,self.generator.trainable_weights)\n",
    "        )\n",
    "        return {\n",
    "            \"d_loss\": d_loss,\n",
    "            \"g_loss\": g_loss\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "47f46941-23f9-4eab-847f-307c1c419d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GanMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self,num_img=3, latent_dim=128):\n",
    "        self.num_img=num_img\n",
    "        self.latent_dim =latent_dim\n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(self.num_img,self.latent_dim)\n",
    "        )\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        fig,ax = plt.subplots(1,self.num_img)\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "            ax[i].imshow(img,cmap='gray')\n",
    "            img.save(\"gen_{}_{}.png\".format(i,epoch))\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "111311d3-bf1a-473f-8a3c-5937352686d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1094/1094 [==============================] - ETA: 0s - d_loss: 0.0067 - g_loss: 6.8783"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1094/1094 [==============================] - 3049s 3s/step - d_loss: 0.0067 - g_loss: 6.8798\n",
      "Epoch 2/3\n",
      "1094/1094 [==============================] - ETA: 0s - d_loss: 9.1062e-04 - g_loss: 8.8506"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1094/1094 [==============================] - 3040s 3s/step - d_loss: 9.0999e-04 - g_loss: 8.8518\n",
      "Epoch 3/3\n",
      " 112/1094 [==>...........................] - ETA: 45:23 - d_loss: 3.9003e-04 - g_loss: 9.7166"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m gan \u001b[38;5;241m=\u001b[39m Gan(discriminator\u001b[38;5;241m=\u001b[39mdiscriminator,generator\u001b[38;5;241m=\u001b[39mgenerator,latent_dim\u001b[38;5;241m=\u001b[39mlatent_dim)\n\u001b[1;32m      4\u001b[0m gan\u001b[38;5;241m.\u001b[39mcompile(dis_opt \u001b[38;5;241m=\u001b[39m Adam(),gen_opt \u001b[38;5;241m=\u001b[39m Adam(),loss_funct\u001b[38;5;241m=\u001b[39mBinaryCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m----> 5\u001b[0m \u001b[43mgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mGanMonitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_img\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs=3\n",
    "\n",
    "gan = Gan(discriminator=discriminator,generator=generator,latent_dim=latent_dim)\n",
    "gan.compile(dis_opt = Adam(),gen_opt = Adam(),loss_funct=BinaryCrossentropy(from_logits=True))\n",
    "gan.fit(\n",
    "    dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[GanMonitor(num_img=3, latent_dim=latent_dim)]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970a5a73-3669-43d1-ad3f-ebc79c83dfea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6f6860-78c4-4c6d-8b6b-c33fe6829009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
