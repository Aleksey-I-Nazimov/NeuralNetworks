{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705ad93c-c094-42db-848b-44fbf4f55c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv(\"/home/alex/dev/AiLearning/DataSetStore/text_classification_1/train.csv\")\n",
    "df_valid = pd.read_csv(\"/home/alex/dev/AiLearning/DataSetStore/text_classification_1/val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed4089aa-9523-474b-862a-8f98344dd014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 181467 entries, 0 to 181466\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   id      181467 non-null  int64 \n",
      " 1   text    181467 non-null  object\n",
      " 2   class   181467 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "605316c7-0530-4aba-83a3-3d3097c78c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f49d21b7-01f3-420f-bf0d-8f58c4a592d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22683 entries, 0 to 22682\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      22683 non-null  int64 \n",
      " 1   text    22683 non-null  object\n",
      " 2   class   22683 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 531.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_valid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86aa55d3-adb8-4880-a7e2-07ac1b8dd49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>181467</td>\n",
       "      <td>RT @TukvaSociopat: Максимальный репост! ))) #є...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181468</td>\n",
       "      <td>чтоб у меня з.п. ежегодно индексировали на инд...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181469</td>\n",
       "      <td>@chilyandlime нехуя мне не хорошо !!! :((((</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181470</td>\n",
       "      <td>@inafish нее , когда ногами ахахах когда?ахаха...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181471</td>\n",
       "      <td>Хочу сделать как лучше,  а получаю как всегда. :(</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  class\n",
       "0  181467  RT @TukvaSociopat: Максимальный репост! ))) #є...      1\n",
       "1  181468  чтоб у меня з.п. ежегодно индексировали на инд...      0\n",
       "2  181469        @chilyandlime нехуя мне не хорошо !!! :((((      0\n",
       "3  181470  @inafish нее , когда ногами ахахах когда?ахаха...      0\n",
       "4  181471  Хочу сделать как лучше,  а получаю как всегда. :(      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e9b773-eca2-4460-9395-5bada22185b2",
   "metadata": {},
   "source": [
    "# Message cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54a1e776-a032-4d1f-a42f-8267a61f670c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/alex/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk import tokenize as tknz\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Just copy from the homework of the lesson -1\n",
    "class MessageCleaner:\n",
    "    \n",
    "    def __init__(self,message=None):\n",
    "        self._message= message\n",
    "        self.tokens=[]\n",
    "\n",
    "    def set_message(self,msg):\n",
    "        self._message = msg;\n",
    "        return self\n",
    "\n",
    "    def get_message(self):\n",
    "        return self._message\n",
    "\n",
    "    def remove_users(self,replace=\" \"):\n",
    "        xtr = re.sub(pattern=\"@[\\w]*\",repl=replace,string=self._message)\n",
    "        self._message = xtr\n",
    "        return self\n",
    "    \n",
    "    def remove_punctuation(self,replace=\" \"):\n",
    "        xtr = re.sub(pattern=r'[^\\w\\s]',repl=replace,string=self._message)\n",
    "        self._message = xtr\n",
    "        return self\n",
    "\n",
    "    def remove_en_special_sym(self,replace=\" \"):\n",
    "        xtr = re.sub(pattern=r'[^a-zA-Z0-9]',repl=replace,string=self._message)\n",
    "        self._message = xtr\n",
    "        return self\n",
    "\n",
    "    def remove_ru_special_sym(self,replace=\" \"):\n",
    "        xtr = re.sub(pattern=r'[^а-яА-Я0-9]',repl=replace,string=self._message)\n",
    "        self._message = xtr\n",
    "        return self\n",
    "    \n",
    "    def remove_en_numbers(self,replace=\" \"):\n",
    "        xtr = re.sub(pattern=r'[^a-zA-Z]',repl=replace,string=self._message)\n",
    "        self._message = xtr\n",
    "        return self\n",
    "\n",
    "    def remove_ru_numbers(self,replace=\" \"):\n",
    "        xtr = re.sub(pattern=r'[^а-яА-Я]',repl=replace,string=self._message)\n",
    "        self._message = xtr\n",
    "        return self\n",
    "\n",
    "    def clean_by_regexp(self,regexp: str):\n",
    "        pattern = re.compile(regexp)\n",
    "        xtr = pattern.subn(' ', self._message)[0]\n",
    "        self._message = xtr\n",
    "        return self\n",
    "\n",
    "    def to_lower (self ):\n",
    "        self._message = self._message.lower();\n",
    "        return self;\n",
    "\n",
    "    def replace_by_dicts (self,dictionary: map):\n",
    "        for key in dictionary:\n",
    "            self._message = self._message.replace(key,dictionary[key])\n",
    "            #re.sub(pattern=key,repl=dictionary[key],string=self._message)\n",
    "        return self\n",
    "\n",
    "    def escape_single_symbol_words (self):\n",
    "        self._message=\" \".join([word for word in self._message.split() if len(word)>1])\n",
    "        return self\n",
    "\n",
    "    def nltk_word_tokenize(self):\n",
    "        self.tokens=tknz.word_tokenize(self._message)\n",
    "        return self\n",
    "\n",
    "    def nltk_word_punc_tokenize(self):\n",
    "        self.tokens = tknz.wordpunct_tokenize(self._message)\n",
    "        return self\n",
    "\n",
    "    def nltk_tok_tok_tokenizer(self):\n",
    "        self.tokens = tknz.ToktokTokenizer().tokenize(self._message)\n",
    "        return self\n",
    "        \n",
    "    def nltk_tweet_tokenizer(self):\n",
    "        self.tokens = tknz.TweetTokenizer().tokenize(self._message)\n",
    "        return self\n",
    "\n",
    "    def nltk_with_regexp_tokenizer (self,regexp):\n",
    "        self.tokens = tknz.RegexpTokenizer(regexp).tokenize(self._message)\n",
    "        return self\n",
    "\n",
    "    def nltk_sentence_tokenizer (self):\n",
    "        self.tokens = nltk.sent_tokenize(self._message)\n",
    "        return self\n",
    "\n",
    "    def tokenize (self,tokenizer):\n",
    "        self.tokens=tokenizer(self._message)\n",
    "        return self\n",
    "\n",
    "    def remove_stopwords_from_tokens (self,lang=None,is_new=True):\n",
    "        if lang is None:\n",
    "            sw = set(stopwords.words(\"english\"))\n",
    "        else :\n",
    "            sw = set(stopwords.words(lang))\n",
    "        tks = [token for token in self.tokens if token not in sw]\n",
    "        if is_new:\n",
    "            self.tokens_without_stops = tks\n",
    "        else :\n",
    "            self.tokens = tks\n",
    "        return self\n",
    "\n",
    "    def stemme_tokens (self,stemmer=None,is_new=True):\n",
    "        if stemmer is None:\n",
    "            stemmer = PorterStemmer()\n",
    "        xtr = [stemmer.stem(token) for token in self.tokens]\n",
    "        if is_new :\n",
    "            self.stem_tokens = xtr\n",
    "        else :\n",
    "            self.tokens = xtr\n",
    "        return self\n",
    "\n",
    "    def lematize_tokens (self,lematizer=None,is_new=True):\n",
    "        if lematizer is None:\n",
    "            lematizer = WordNetLemmatizer()\n",
    "        xtr = [lematizer.lemmatize(token) for token in self.tokens]\n",
    "        if is_new:\n",
    "            self.lem_tokens = xtr\n",
    "        else :\n",
    "            self.tokens = xtr\n",
    "        return self\n",
    "\n",
    "    def process_each_token(self,function):\n",
    "        xtr = [function(token) for token in self.tokens]\n",
    "        self.tokens = xtr\n",
    "        return self\n",
    "\n",
    "    def replace_message_by_sorted_tokens(self,token_array=None):\n",
    "        if token_array is None:\n",
    "            token_array = self.tokens\n",
    "        xtr = \" \".join(sorted(token_array))\n",
    "        self._message = xtr\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50dd26e6-f45e-4f18-8c04-d564e9354e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import Segmenter,MorphVocab,Doc,NewsMorphTagger,NewsEmbedding\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_tagger = NewsMorphTagger(NewsEmbedding())\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "def make_natasha_tokens(text,\n",
    "                        morphology_filter_set=None,\n",
    "                        token_length_limit=None,\n",
    "                        empty_token=\"empty\",\n",
    "                        verbose=False):\n",
    "    \n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "\n",
    "    selected_tokens=[]\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "        if verbose:\n",
    "            print (\" >> Input {} \".format(token))\n",
    "        new_token = None\n",
    "        if morphology_filter_set is None:\n",
    "            new_token = token.lemma\n",
    "        else:\n",
    "            if token.pos in morphology_filter_set:\n",
    "                new_token = token.lemma\n",
    "        if new_token is not None and token_length_limit is not None:\n",
    "            if len(new_token)<token_length_limit:\n",
    "                new_token = None\n",
    "        if new_token is not None:\n",
    "            selected_tokens.append(new_token)\n",
    "        if verbose:\n",
    "            print (\" >> Output {} \".format(new_token))\n",
    "    if len(selected_tokens)==0 :\n",
    "        selected_tokens.append(empty_token)\n",
    "\n",
    "    del doc\n",
    "    return selected_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b409248d-64bd-40f5-a348-cffbf24e2088",
   "metadata": {},
   "source": [
    "# Message cleaner with Natasha and Nltk based approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2414a6f-f0f8-40d0-b8f6-a6dd98b9f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def natasha_message_cleaner (text: str):\n",
    "    return MessageCleaner()\\\n",
    "    .set_message(msg=text)\\\n",
    "    .to_lower()\\\n",
    "    .tokenize(tokenizer=lambda txt: make_natasha_tokens(text=txt,\\\n",
    "                                                        morphology_filter_set=('NOUN','VERB','ADJ','PUNCT','PRON'),\\\n",
    "                                                        token_length_limit=None))\\\n",
    "    .tokens\n",
    "\n",
    "def nltk_message_cleaner(text: str):\n",
    "    return MessageCleaner()\\\n",
    "    .set_message(msg=text)\\\n",
    "    .nltk_word_tokenize()\\\n",
    "    .lematize_tokens(is_new=False)\\\n",
    "    .remove_stopwords_from_tokens(lang=\"russian\",is_new=False)\\\n",
    "    .tokens\n",
    "    \n",
    "\n",
    "# .nltk_word_tokenize()\\\n",
    "# .remove_punctuation()\\   \n",
    "# .remove_ru_numbers()\\\n",
    "# .remove_ru_special_sym()\\\n",
    "# .remove_ru_special_sym()\\\n",
    "# .lematize_tokens(is_new=False)\\\n",
    "# .remove_stopwords_from_tokens(lang=\"russian\",is_new=False)\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93d8a84-adda-4fb7-941e-1dba6acd8067",
   "metadata": {},
   "source": [
    "# Just testing keras tokenizer with the Natasha-analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45ebd0be-702a-4377-96d0-2d7cde6a3491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 04:57:34.248376: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-04 04:57:34.249634: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-04 04:57:34.269592: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-04 04:57:34.269612: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-04 04:57:34.269627: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-04 04:57:34.273424: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-04 04:57:34.273822: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-04 04:57:34.743582: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"class_name\": \"Tokenizer\", \"config\": {\"num_words\": null, \"filters\": null, \"lower\": null, \"split\": null, \"char_level\": false, \"oov_token\": null, \"document_count\": 0, \"word_counts\": \"{}\", \"word_docs\": \"{}\", \"index_docs\": \"{}\", \"index_word\": \"{}\", \"word_index\": \"{}\"}}\n",
      "Document numbre =  4\n",
      "Word counter:  OrderedDict([('что', 1), ('сказать', 1), (',', 1), ('я', 2), ('видеть', 1), ('кто-то', 1), ('наступить', 1), ('грабли', 1), ('ты', 2), ('разочаровать', 1), ('натравить', 1)])\n",
      "Word into docs counter:  defaultdict(<class 'int'>, {'сказать': 1, 'я': 2, 'что': 1, 'видеть': 1, ',': 1, 'наступить': 1, 'грабли': 1, 'кто-то': 1, 'разочаровать': 1, 'ты': 2, 'натравить': 1})\n",
      "Index docs:  defaultdict(<class 'int'>, {4: 1, 1: 2, 3: 1, 6: 1, 5: 1, 8: 1, 9: 1, 7: 1, 10: 1, 2: 2, 11: 1})\n",
      "Index word:  {1: 'я', 2: 'ты', 3: 'что', 4: 'сказать', 5: ',', 6: 'видеть', 7: 'кто-то', 8: 'наступить', 9: 'грабли', 10: 'разочаровать', 11: 'натравить'}\n",
      "Word index:  {'я': 1, 'ты': 2, 'что': 3, 'сказать': 4, ',': 5, 'видеть': 6, 'кто-то': 7, 'наступить': 8, 'грабли': 9, 'разочаровать': 10, 'натравить': 11}\n",
      "[[3, 4, 5, 1, 6, 7, 8]]\n"
     ]
    }
   ],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "\n",
    "\n",
    "#num_words \tthe maximum number of words to keep, based on word frequency. Only the most common num_words-1 words will be kept.\n",
    "#filters \ta string where each element is a character that will be filtered from the texts. The default is all punctuation, plus tabs and line breaks, minus the ' character.\n",
    "#lower \t    boolean. Whether to convert the texts to lowercase.\n",
    "#split \t    str. Separator for word splitting.\n",
    "#char_level if True, every character will be treated as a token.\n",
    "#oov_token \tif given, it will be added to word_index and used to replace out-of-vocabulary words during text_to_sequence calls\n",
    "#analyzer \tfunction. Custom analyzer to split the text. The default analyzer is text_to_word_sequence \n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=None,\n",
    "                      filters=None,\n",
    "                      lower=None,\n",
    "                      split=None,\n",
    "                      char_level=False,\n",
    "                      oov_token=None,\n",
    "                      analyzer=natasha_message_cleaner)\n",
    "\n",
    "print(tokenizer.to_json())\n",
    "\n",
    "tokenizer.fit_on_texts([\"Ну что сказать, я вижу\",\"Кто-то наступил на грабли\", \"Ты разочаровал меня\", \"ты был натравлен\"])\n",
    "print(\"Document numbre = \",tokenizer.document_count)\n",
    "print(\"Word counter: \",tokenizer.word_counts)\n",
    "print(\"Word into docs counter: \",tokenizer.word_docs)\n",
    "print(\"Index docs: \",tokenizer.index_docs)\n",
    "print(\"Index word: \",tokenizer.index_word)\n",
    "print(\"Word index: \",tokenizer.word_index)\n",
    "\n",
    "print(tokenizer.texts_to_sequences([\"Ну что сказать, я вижу кто-то наступил\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c784e7b9-b40d-4782-a95b-e7f53254651c",
   "metadata": {},
   "source": [
    "# Calculating X,Y with the Natasha tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e88442e-5d66-4ce0-9471-0476f2debcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 93277\n",
      "(181467, 130)\n"
     ]
    }
   ],
   "source": [
    "train_messages = df_train['text'].values\n",
    "valid_messages = df_valid['text'].values\n",
    "\n",
    "ANALYZER = natasha_message_cleaner\n",
    "\n",
    "tokenizer = Tokenizer(num_words=None,\n",
    "                      filters=None,\n",
    "                      lower=None,\n",
    "                      split=None,\n",
    "                      char_level=False,\n",
    "                      oov_token=None,\n",
    "                      analyzer=ANALYZER)\n",
    "\n",
    "tokenizer.fit_on_texts(train_messages)\n",
    "\n",
    "train_vectors = tokenizer.texts_to_sequences(train_messages)\n",
    "valid_vectors = tokenizer.texts_to_sequences(valid_messages)\n",
    "\n",
    "max_vector_length = max([len(ANALYZER(train_message)) for train_message in train_messages])\n",
    "dictionary_size_plus_1 = len(tokenizer.index_word) + 1\n",
    "\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences\n",
    "# just adding zeroes to vectors with small sizes\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x_train = pad_sequences(train_vectors, maxlen=max_vector_length)\n",
    "x_valid = pad_sequences(valid_vectors, maxlen=max_vector_length)\n",
    "y_train = df_train['class'].values\n",
    "y_valid = df_valid['class'].values\n",
    "\n",
    "print (max_vector_length,dictionary_size_plus_1)\n",
    "print (x_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bfb1d5-dbaf-4b61-b27a-996978210f46",
   "metadata": {},
   "source": [
    "# Just testing keras embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96241524-0fe0-4da1-93d9-b4d2dfc6880d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 622us/step\n",
      "(130, 130)\n",
      "(130,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 05:18:22.478710: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-04 05:18:22.491210: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# https://keras.io/api/layers/core_layers/embedding/\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Sequential\n",
    "\n",
    "#    input_dim: Integer. Size of the vocabulary, i.e. maximum integer index + 1.\n",
    "#    output_dim: Integer. Dimension of the dense embedding.\n",
    "#    embeddings_initializer: Initializer for the embeddings matrix (see keras.initializers).\n",
    "#    embeddings_regularizer: Regularizer function applied to the embeddings matrix (see keras.regularizers).\n",
    "#    embeddings_constraint: Constraint function applied to the embeddings matrix (see keras.constraints).\n",
    "#    mask_zero: Boolean, whether or not the input value 0 is a special \"padding\" value that should be masked out. This is useful when using recurrent layers which may take variable length input. If this is True, then all subsequent layers in the model need to support masking or an exception will be raised. If mask_zero is set to True, as a consequence, index 0 cannot be used in the vocabulary (input_dim should equal size of vocabulary + 1).\n",
    "\n",
    "embedding = Embedding(\n",
    "    input_dim=dictionary_size_plus_1,\n",
    "    output_dim=max_vector_length,\n",
    "    embeddings_initializer=\"uniform\",\n",
    "    embeddings_regularizer=None,\n",
    "    embeddings_constraint=None,\n",
    "    mask_zero=True\n",
    ")\n",
    "model = Sequential()\n",
    "model.add(embedding)\n",
    "\n",
    "print (model.predict(x_train[0]).shape)\n",
    "print (x_train[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773d275c-e2ab-4614-96fc-5d9841a512e0",
   "metadata": {},
   "source": [
    "# RNN-based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47d2405f-1c05-4eae-bba7-664c79cbd9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 130)         12126010  \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 130)               33930     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 96)                12576     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 96)                384       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 96)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 96)                9312      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 96)                384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 96)                9312      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 96)                384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 96)                9312      \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 96)                384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 97        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12202085 (46.55 MB)\n",
      "Trainable params: 12201317 (46.54 MB)\n",
      "Non-trainable params: 768 (3.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN,Dropout,Dense,BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.losses import MeanSquaredError\n",
    "\n",
    "#https://keras.io/api/layers/recurrent_layers/simple_rnn/\n",
    "\n",
    "rnn = Sequential()\n",
    "rnn.add(Embedding(\n",
    "    input_dim=dictionary_size_plus_1,\n",
    "    output_dim=max_vector_length,\n",
    "    embeddings_initializer=\"uniform\",\n",
    "    embeddings_regularizer=None,\n",
    "    embeddings_constraint=None,\n",
    "    mask_zero=True))\n",
    "\n",
    "rnn.add(SimpleRNN(units=max_vector_length,dropout=0.25,recurrent_dropout=0.4))\n",
    "rnn.add(Dense(96, activation='relu'))\n",
    "rnn.add(BatchNormalization())\n",
    "rnn.add(Dropout(0.75))\n",
    "rnn.add(Dense(96, activation='tanh'))\n",
    "rnn.add(BatchNormalization())\n",
    "rnn.add(Dropout(0.5))\n",
    "rnn.add(Dense(96, activation='relu'))\n",
    "rnn.add(BatchNormalization())\n",
    "rnn.add(Dropout(0.25))\n",
    "rnn.add(Dense(96, activation='tanh'))\n",
    "rnn.add(BatchNormalization())\n",
    "rnn.add(Dropout(0.15))\n",
    "rnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "rnn.compile(optimizer='adam', loss=MeanSquaredError(), metrics=['accuracy'])\n",
    "rnn.summary()\n",
    "\n",
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "early_stopping=EarlyStopping(monitor='val_accuracy',\n",
    "                             baseline=0.70,\n",
    "                             patience=20,\n",
    "                             restore_best_weights=True,\n",
    "                             start_from_epoch=3,\n",
    "                             mode='max',\n",
    "                             verbose=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bda238ce-c0d4-419d-ab65-ae7aecc7dd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "73/73 [==============================] - 36s 469ms/step - loss: 0.2600 - accuracy: 0.5674 - val_loss: 0.0906 - val_accuracy: 0.8941\n",
      "Epoch 2/50\n",
      "73/73 [==============================] - 34s 468ms/step - loss: 0.0713 - accuracy: 0.9043 - val_loss: 0.0461 - val_accuracy: 0.9515\n",
      "Epoch 3/50\n",
      "73/73 [==============================] - 34s 467ms/step - loss: 0.0256 - accuracy: 0.9684 - val_loss: 0.0420 - val_accuracy: 0.9561\n",
      "Epoch 4/50\n",
      "73/73 [==============================] - 34s 468ms/step - loss: 0.0177 - accuracy: 0.9788 - val_loss: 0.0245 - val_accuracy: 0.9743\n",
      "Epoch 5/50\n",
      "73/73 [==============================] - 34s 468ms/step - loss: 0.0139 - accuracy: 0.9836 - val_loss: 0.0222 - val_accuracy: 0.9764\n",
      "Epoch 6/50\n",
      "73/73 [==============================] - 34s 469ms/step - loss: 0.0119 - accuracy: 0.9861 - val_loss: 0.0182 - val_accuracy: 0.9808\n",
      "Epoch 7/50\n",
      "73/73 [==============================] - 34s 468ms/step - loss: 0.0101 - accuracy: 0.9883 - val_loss: 0.0181 - val_accuracy: 0.9806\n",
      "Epoch 8/50\n",
      "73/73 [==============================] - 34s 467ms/step - loss: 0.0088 - accuracy: 0.9898 - val_loss: 0.0139 - val_accuracy: 0.9849\n",
      "Epoch 9/50\n",
      "73/73 [==============================] - 34s 465ms/step - loss: 0.0081 - accuracy: 0.9905 - val_loss: 0.0183 - val_accuracy: 0.9804\n",
      "Epoch 10/50\n",
      "73/73 [==============================] - 34s 465ms/step - loss: 0.0073 - accuracy: 0.9915 - val_loss: 0.0152 - val_accuracy: 0.9836\n",
      "Epoch 11/50\n",
      "73/73 [==============================] - 34s 464ms/step - loss: 0.0066 - accuracy: 0.9923 - val_loss: 0.0128 - val_accuracy: 0.9859\n",
      "Epoch 12/50\n",
      "73/73 [==============================] - 34s 463ms/step - loss: 0.0060 - accuracy: 0.9931 - val_loss: 0.0144 - val_accuracy: 0.9844\n",
      "Epoch 13/50\n",
      "73/73 [==============================] - 34s 464ms/step - loss: 0.0057 - accuracy: 0.9935 - val_loss: 0.0130 - val_accuracy: 0.9859\n",
      "Epoch 14/50\n",
      "73/73 [==============================] - 34s 464ms/step - loss: 0.0055 - accuracy: 0.9936 - val_loss: 0.0136 - val_accuracy: 0.9855\n",
      "Epoch 15/50\n",
      "73/73 [==============================] - 34s 464ms/step - loss: 0.0051 - accuracy: 0.9941 - val_loss: 0.0161 - val_accuracy: 0.9825\n",
      "Epoch 16/50\n",
      "73/73 [==============================] - 34s 465ms/step - loss: 0.0048 - accuracy: 0.9944 - val_loss: 0.0144 - val_accuracy: 0.9845\n",
      "Epoch 17/50\n",
      "73/73 [==============================] - 34s 464ms/step - loss: 0.0044 - accuracy: 0.9949 - val_loss: 0.0113 - val_accuracy: 0.9877\n",
      "Epoch 18/50\n",
      "73/73 [==============================] - 34s 465ms/step - loss: 0.0042 - accuracy: 0.9952 - val_loss: 0.0130 - val_accuracy: 0.9859\n",
      "Epoch 19/50\n",
      "73/73 [==============================] - 34s 466ms/step - loss: 0.0040 - accuracy: 0.9955 - val_loss: 0.0124 - val_accuracy: 0.9867\n",
      "Epoch 20/50\n",
      "73/73 [==============================] - 34s 468ms/step - loss: 0.0037 - accuracy: 0.9957 - val_loss: 0.0123 - val_accuracy: 0.9868\n",
      "Epoch 21/50\n",
      "73/73 [==============================] - 34s 467ms/step - loss: 0.0037 - accuracy: 0.9957 - val_loss: 0.0118 - val_accuracy: 0.9874\n",
      "Epoch 22/50\n",
      "73/73 [==============================] - 34s 468ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 0.0118 - val_accuracy: 0.9871\n",
      "Epoch 23/50\n",
      "73/73 [==============================] - 34s 467ms/step - loss: 0.0036 - accuracy: 0.9957 - val_loss: 0.0182 - val_accuracy: 0.9806\n",
      "Epoch 24/50\n",
      "73/73 [==============================] - 34s 468ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 0.0131 - val_accuracy: 0.9859\n",
      "Epoch 25/50\n",
      "73/73 [==============================] - 34s 467ms/step - loss: 0.0033 - accuracy: 0.9962 - val_loss: 0.0115 - val_accuracy: 0.9876\n",
      "Epoch 26/50\n",
      "73/73 [==============================] - 34s 466ms/step - loss: 0.0034 - accuracy: 0.9960 - val_loss: 0.0112 - val_accuracy: 0.9878\n",
      "Epoch 27/50\n",
      "73/73 [==============================] - 34s 466ms/step - loss: 0.0033 - accuracy: 0.9963 - val_loss: 0.0128 - val_accuracy: 0.9861\n",
      "Epoch 28/50\n",
      "73/73 [==============================] - 34s 465ms/step - loss: 0.0032 - accuracy: 0.9963 - val_loss: 0.0128 - val_accuracy: 0.9864\n",
      "Epoch 29/50\n",
      "73/73 [==============================] - 34s 465ms/step - loss: 0.0029 - accuracy: 0.9967 - val_loss: 0.0138 - val_accuracy: 0.9853\n",
      "Epoch 30/50\n",
      "73/73 [==============================] - 34s 465ms/step - loss: 0.0028 - accuracy: 0.9969 - val_loss: 0.0115 - val_accuracy: 0.9877\n",
      "Epoch 31/50\n",
      "73/73 [==============================] - 34s 465ms/step - loss: 0.0027 - accuracy: 0.9970 - val_loss: 0.0129 - val_accuracy: 0.9861\n",
      "Epoch 32/50\n",
      "73/73 [==============================] - 34s 465ms/step - loss: 0.0028 - accuracy: 0.9968 - val_loss: 0.0133 - val_accuracy: 0.9857\n",
      "Epoch 33/50\n",
      "73/73 [==============================] - 34s 465ms/step - loss: 0.0028 - accuracy: 0.9968 - val_loss: 0.0126 - val_accuracy: 0.9863\n",
      "Epoch 34/50\n",
      "73/73 [==============================] - 34s 466ms/step - loss: 0.0025 - accuracy: 0.9972 - val_loss: 0.0121 - val_accuracy: 0.9871\n",
      "Epoch 35/50\n",
      "73/73 [==============================] - 34s 466ms/step - loss: 0.0023 - accuracy: 0.9975 - val_loss: 0.0127 - val_accuracy: 0.9864\n",
      "Epoch 36/50\n",
      "73/73 [==============================] - 34s 466ms/step - loss: 0.0025 - accuracy: 0.9972 - val_loss: 0.0134 - val_accuracy: 0.9858\n",
      "Epoch 37/50\n",
      "73/73 [==============================] - 34s 466ms/step - loss: 0.0024 - accuracy: 0.9973 - val_loss: 0.0124 - val_accuracy: 0.9868\n",
      "Epoch 38/50\n",
      "73/73 [==============================] - 34s 466ms/step - loss: 0.0024 - accuracy: 0.9974 - val_loss: 0.0117 - val_accuracy: 0.9873\n",
      "Epoch 39/50\n",
      "73/73 [==============================] - 34s 467ms/step - loss: 0.0024 - accuracy: 0.9973 - val_loss: 0.0135 - val_accuracy: 0.9855\n",
      "Epoch 40/50\n",
      "73/73 [==============================] - 34s 467ms/step - loss: 0.0023 - accuracy: 0.9974 - val_loss: 0.0139 - val_accuracy: 0.9854\n",
      "Epoch 41/50\n",
      "73/73 [==============================] - 34s 467ms/step - loss: 0.0024 - accuracy: 0.9974 - val_loss: 0.0135 - val_accuracy: 0.9857\n",
      "Epoch 42/50\n",
      "73/73 [==============================] - 34s 465ms/step - loss: 0.0024 - accuracy: 0.9974 - val_loss: 0.0125 - val_accuracy: 0.9866\n",
      "Epoch 43/50\n",
      "73/73 [==============================] - 34s 465ms/step - loss: 0.0024 - accuracy: 0.9974 - val_loss: 0.0131 - val_accuracy: 0.9859\n",
      "Epoch 44/50\n",
      "73/73 [==============================] - 34s 465ms/step - loss: 0.0023 - accuracy: 0.9974 - val_loss: 0.0135 - val_accuracy: 0.9856\n",
      "Epoch 45/50\n",
      "73/73 [==============================] - 34s 466ms/step - loss: 0.0022 - accuracy: 0.9975 - val_loss: 0.0137 - val_accuracy: 0.9856\n",
      "Epoch 46/50\n",
      "73/73 [==============================] - 34s 466ms/step - loss: 0.0024 - accuracy: 0.9973 - val_loss: 0.0110 - val_accuracy: 0.9879\n",
      "Epoch 47/50\n",
      "73/73 [==============================] - 34s 466ms/step - loss: 0.0023 - accuracy: 0.9975 - val_loss: 0.0136 - val_accuracy: 0.9855\n",
      "Epoch 48/50\n",
      "73/73 [==============================] - 34s 465ms/step - loss: 0.0022 - accuracy: 0.9975 - val_loss: 0.0132 - val_accuracy: 0.9858\n",
      "Epoch 49/50\n",
      "73/73 [==============================] - 34s 465ms/step - loss: 0.0021 - accuracy: 0.9977 - val_loss: 0.0126 - val_accuracy: 0.9863\n",
      "Epoch 50/50\n",
      "73/73 [==============================] - 34s 465ms/step - loss: 0.0021 - accuracy: 0.9976 - val_loss: 0.0123 - val_accuracy: 0.9867\n"
     ]
    }
   ],
   "source": [
    "history = rnn.fit(x_train, y_train,\n",
    "                    batch_size=2000,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6152bee-0543-4280-b71a-5a36e4abca94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 2s 35ms/step - loss: 0.0128 - accuracy: 0.9862\n",
      "[0.012773622758686543, 0.9862452149391174]\n",
      "Test score: 0.012773622758686543\n",
      "Test accuracy: 0.9862452149391174\n"
     ]
    }
   ],
   "source": [
    "score = rnn.evaluate(x_valid, y_valid, batch_size=512, verbose=1)\n",
    "print (score)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4db4e77-8608-456f-ab21-7cbb0a7d9377",
   "metadata": {},
   "source": [
    "# LSTM -based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de0ba756-55c9-45c6-b4a1-af0b8d47b575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 130)         12126010  \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 130)               135720    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 96)                12576     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 96)                384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 96)                9312      \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 96)                384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 96)                9312      \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 96)                384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 96)                9312      \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 96)                384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 97        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12303875 (46.94 MB)\n",
      "Trainable params: 12303107 (46.93 MB)\n",
      "Non-trainable params: 768 (3.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dropout,Dense\n",
    "\n",
    "# https://keras.io/api/layers/recurrent_layers/lstm/\n",
    "\n",
    "lstm = Sequential()\n",
    "lstm.add(Embedding(\n",
    "    input_dim=dictionary_size_plus_1,\n",
    "    output_dim=max_vector_length,\n",
    "    embeddings_initializer=\"uniform\",\n",
    "    embeddings_regularizer=None,\n",
    "    embeddings_constraint=None,\n",
    "    mask_zero=True))\n",
    "\n",
    "lstm.add(LSTM(units=max_vector_length,dropout=0.3,activation=\"tanh\",\n",
    "    recurrent_activation=\"tanh\",recurrent_dropout=0.3))\n",
    "lstm.add(Dense(96, activation='relu'))\n",
    "lstm.add(BatchNormalization())\n",
    "lstm.add(Dropout(0.65))\n",
    "lstm.add(Dense(96, activation='tanh'))\n",
    "lstm.add(BatchNormalization())\n",
    "lstm.add(Dropout(0.45))\n",
    "lstm.add(Dense(96, activation='relu'))\n",
    "lstm.add(BatchNormalization())\n",
    "lstm.add(Dropout(0.20))\n",
    "lstm.add(Dense(96, activation='tanh'))\n",
    "lstm.add(BatchNormalization())\n",
    "lstm.add(Dropout(0.15))\n",
    "lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "lstm.summary()\n",
    "\n",
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "early_stopping=EarlyStopping(monitor='val_accuracy',\n",
    "                             baseline=0.70,\n",
    "                             patience=20,\n",
    "                             restore_best_weights=True,\n",
    "                             start_from_epoch=3,\n",
    "                             mode='max',\n",
    "                             verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd1d35a3-5309-4100-8c4e-09c2038dda03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "73/73 [==============================] - 97s 1s/step - loss: 0.2064 - accuracy: 0.8994 - val_loss: 0.7218 - val_accuracy: 0.5070\n",
      "Epoch 2/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0379 - accuracy: 0.9868 - val_loss: 0.9230 - val_accuracy: 0.5070\n",
      "Epoch 3/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 1.1741 - val_accuracy: 0.5071\n",
      "Epoch 4/50\n",
      "73/73 [==============================] - 94s 1s/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.9820 - val_accuracy: 0.5129\n",
      "Epoch 5/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.7139 - val_accuracy: 0.5656\n",
      "Epoch 6/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.3206 - val_accuracy: 0.8279\n",
      "Epoch 7/50\n",
      "73/73 [==============================] - 94s 1s/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0759 - val_accuracy: 0.9770\n",
      "Epoch 8/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0478 - val_accuracy: 0.9861\n",
      "Epoch 9/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0535 - val_accuracy: 0.9867\n",
      "Epoch 10/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0544 - val_accuracy: 0.9871\n",
      "Epoch 11/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0557 - val_accuracy: 0.9878\n",
      "Epoch 12/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0629 - val_accuracy: 0.9877\n",
      "Epoch 13/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0614 - val_accuracy: 0.9877\n",
      "Epoch 14/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0669 - val_accuracy: 0.9870\n",
      "Epoch 15/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0664 - val_accuracy: 0.9877\n",
      "Epoch 16/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0686 - val_accuracy: 0.9869\n",
      "Epoch 17/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0720 - val_accuracy: 0.9871\n",
      "Epoch 18/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0732 - val_accuracy: 0.9875\n",
      "Epoch 19/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0819 - val_accuracy: 0.9868\n",
      "Epoch 20/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0656 - val_accuracy: 0.9884\n",
      "Epoch 21/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0670 - val_accuracy: 0.9883\n",
      "Epoch 22/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0677 - val_accuracy: 0.9886\n",
      "Epoch 23/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0756 - val_accuracy: 0.9879\n",
      "Epoch 24/50\n",
      "73/73 [==============================] - 94s 1s/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0664 - val_accuracy: 0.9886\n",
      "Epoch 25/50\n",
      "73/73 [==============================] - 94s 1s/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0714 - val_accuracy: 0.9879\n",
      "Epoch 26/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0690 - val_accuracy: 0.9880\n",
      "Epoch 27/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0704 - val_accuracy: 0.9883\n",
      "Epoch 28/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0711 - val_accuracy: 0.9881\n",
      "Epoch 29/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0678 - val_accuracy: 0.9891\n",
      "Epoch 30/50\n",
      "73/73 [==============================] - 94s 1s/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0628 - val_accuracy: 0.9886\n",
      "Epoch 31/50\n",
      "73/73 [==============================] - 94s 1s/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0685 - val_accuracy: 0.9883\n",
      "Epoch 32/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0688 - val_accuracy: 0.9888\n",
      "Epoch 33/50\n",
      "73/73 [==============================] - 94s 1s/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0627 - val_accuracy: 0.9891\n",
      "Epoch 34/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0684 - val_accuracy: 0.9881\n",
      "Epoch 35/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0664 - val_accuracy: 0.9887\n",
      "Epoch 36/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0656 - val_accuracy: 0.9878\n",
      "Epoch 37/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0651 - val_accuracy: 0.9888\n",
      "Epoch 38/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0711 - val_accuracy: 0.9878\n",
      "Epoch 39/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0674 - val_accuracy: 0.9892\n",
      "Epoch 40/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0682 - val_accuracy: 0.9891\n",
      "Epoch 41/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0704 - val_accuracy: 0.9894\n",
      "Epoch 42/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0719 - val_accuracy: 0.9888\n",
      "Epoch 43/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0706 - val_accuracy: 0.9886\n",
      "Epoch 44/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0683 - val_accuracy: 0.9893\n",
      "Epoch 45/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0698 - val_accuracy: 0.9883\n",
      "Epoch 46/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0683 - val_accuracy: 0.9891\n",
      "Epoch 47/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0681 - val_accuracy: 0.9893\n",
      "Epoch 48/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0654 - val_accuracy: 0.9896\n",
      "Epoch 49/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0727 - val_accuracy: 0.9894\n",
      "Epoch 50/50\n",
      "73/73 [==============================] - 93s 1s/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0810 - val_accuracy: 0.9865\n"
     ]
    }
   ],
   "source": [
    "history = lstm.fit(x_train, y_train,\n",
    "                    batch_size=2000,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a965fef-6fba-464b-8f26-a225ab1b467e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 3s 76ms/step - loss: 0.0821 - accuracy: 0.9862\n",
      "[0.08211026340723038, 0.9862452149391174]\n",
      "Test score: 0.08211026340723038\n",
      "Test accuracy: 0.9862452149391174\n"
     ]
    }
   ],
   "source": [
    "score = lstm.evaluate(x_valid, y_valid, batch_size=512, verbose=1)\n",
    "print (score)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e99cb9-bd9d-40d5-b4b1-ed1da246b533",
   "metadata": {},
   "source": [
    "# Just testing convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bcee6b0-b78d-4cc6-87aa-b6c1a66fbe88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[ 0.7524413   0.2218785   0.0165498  -0.37880778  0.37230915]]\n",
      "[array([[[-2.07834870e-01],\n",
      "        [ 3.66568565e-04],\n",
      "        [-3.01807165e-01],\n",
      "        [ 4.93916273e-01],\n",
      "        [ 4.03601766e-01]],\n",
      "\n",
      "       [[ 4.05539751e-01],\n",
      "        [ 4.73249197e-01],\n",
      "        [-2.38217086e-01],\n",
      "        [ 2.89316595e-01],\n",
      "        [-1.21607125e-01]],\n",
      "\n",
      "       [[ 3.37714434e-01],\n",
      "        [ 3.46901536e-01],\n",
      "        [-4.35358286e-02],\n",
      "        [ 2.54400313e-01],\n",
      "        [-3.66317213e-01]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv1D,Flatten\n",
    "\n",
    "#filters:       int, the dimension of the output space (the number of filters in the convolution).\n",
    "#kernel_size:   int or tuple/list of 1 integer, specifying the size of the convolution window.\n",
    "#strides:       int or tuple/list of 1 integer, specifying the stride length of the convolution.\n",
    "#               strides > 1 is incompatible with dilation_rate > 1.\n",
    "#padding:       string, \"valid\", \"same\" or \"causal\"(case-insensitive). \"valid\" means no padding.\n",
    "#               \"same\" results in padding evenly to the left/right or up/down of the input.\n",
    "#               When padding=\"same\" and strides=1, the output has the same size as the input.\n",
    "#               \"causal\" results in causal(dilated) convolutions, e.g. output[t] does not depend oninput[t+1:].\n",
    "#               Useful when modeling temporal data where the model should not violate the temporal order.\n",
    "#               See WaveNet: A Generative Model for Raw Audio, section2.1.\n",
    "#data_format:   string, either \"channels_last\" or \"channels_first\". The ordering of the dimensions in the inputs.\n",
    "#               \"channels_last\" corresponds to inputs with shape (batch, steps, features) while \"channels_first\"\n",
    "#               corresponds to inputs with shape (batch, features, steps). It defaults to the image_data_format\n",
    "#               value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"channels_last\".\n",
    "#dilation_rate: int or tuple/list of 1 integers, specifying the dilation rate to use for dilated convolution.\n",
    "#groups:        A positive int specifying the number of groups in which the input is split along the channel axis.\n",
    "#               Each group is convolved separately with filters // groups filters. The output is the concatenation\n",
    "#               of all the groups results along the channel axis. Input channels and filters must both be divisible by groups.\n",
    "#activation:    Activation function. If None, no activation is applied.\n",
    "\n",
    "\n",
    "conv_layer = Conv1D(\n",
    "    filters=1,\n",
    "    kernel_size=3,\n",
    "    strides=1,\n",
    "    padding=\"same\",\n",
    "    data_format=\"channels_first\",\n",
    "    dilation_rate=1,\n",
    "    groups=1,\n",
    "    activation=None,\n",
    "    use_bias=False\n",
    ")\n",
    "\n",
    "array  = np.array([[[1,0,0,0,0],\n",
    "                    [0,1,0,0,0],\n",
    "                    [0,0,1,0,0],\n",
    "                    [0,0,0,1,0],\n",
    "                    [0,0,0,0,1]]])\n",
    "\n",
    "# array  = np.array([[[0,0,0,0,0],\n",
    "#                    [-11,-12,-13,-14,-15],\n",
    "#                    [0,0,0,0,0],\n",
    "#                    [-11,-12,-13,-14,-15],\n",
    "#                    [0,0,0,0,0]]])\n",
    "\n",
    "conv = Sequential()\n",
    "conv.add(conv_layer)\n",
    "conv.add(Flatten(data_format=\"channels_first\"))\n",
    "print (conv.predict(array.astype(float)))\n",
    "print (conv_layer.get_weights())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac79ea4-7b6d-4b1b-9829-1613e2656c2f",
   "metadata": {},
   "source": [
    "# Conv1d NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47b95777-5f8d-4f46-b613-a6c641ec2cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 130)         12126010  \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 130, 130)          0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 128, 8)            3128      \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 128, 8)            200       \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 128, 8)            32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128, 8)            0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 64, 8)             136       \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 64, 8)             200       \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 64, 8)             32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64, 8)             0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 32, 8)             136       \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 32, 8)             200       \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 32, 8)             32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 32, 8)             0         \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 16, 16)            272       \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 16, 16)            784       \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 16, 16)            64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 16, 16)            0         \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 8, 16)             528       \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 8, 16)             784       \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 8, 16)             64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 8, 16)             0         \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 4, 16)             528       \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 4, 16)             784       \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 96)                6240      \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 96)                384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 96)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 96)                9312      \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 96)                384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 96)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 96)                9312      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 96)                384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 96)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 96)                9312      \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 96)                384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 96)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 97        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12169723 (46.42 MB)\n",
      "Trainable params: 12168843 (46.42 MB)\n",
      "Non-trainable params: 880 (3.44 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Reshape\n",
    "#import keras\n",
    "\n",
    "# Convolutional 1D from 130x to 4x\n",
    "conv = Sequential()\n",
    "conv.add(Embedding(\n",
    "    input_dim=dictionary_size_plus_1,\n",
    "    output_dim=max_vector_length,\n",
    "    embeddings_initializer=\"uniform\",\n",
    "    embeddings_regularizer=None,\n",
    "    embeddings_constraint=None,\n",
    "    mask_zero=True))\n",
    "conv.add(Reshape(target_shape=(130,130)))\n",
    "# Decresing from 130 to 128\n",
    "conv.add(Conv1D(filters=8, kernel_size=3,strides=1,padding='valid',activation='relu'))\n",
    "conv.add(Conv1D(filters=8, kernel_size=3,strides=1,padding='same',activation='relu'))\n",
    "conv.add(BatchNormalization())\n",
    "conv.add(Dropout(0.25))\n",
    "conv.add(Conv1D(filters=8, kernel_size=2,strides=2,padding='same',activation='relu'))\n",
    "conv.add(Conv1D(filters=8, kernel_size=3,strides=1,padding='same',activation='relu'))\n",
    "conv.add(BatchNormalization())\n",
    "conv.add(Dropout(0.25))\n",
    "conv.add(Conv1D(filters=8, kernel_size=2,strides=2,padding='same',activation='relu'))\n",
    "conv.add(Conv1D(filters=8, kernel_size=3,strides=1,padding='same',activation='relu'))\n",
    "conv.add(BatchNormalization())\n",
    "conv.add(Dropout(0.25))\n",
    "conv.add(Conv1D(filters=16, kernel_size=2,strides=2,padding='same',activation='relu'))\n",
    "conv.add(Conv1D(filters=16, kernel_size=3,strides=1,padding='same',activation='relu'))\n",
    "conv.add(BatchNormalization())\n",
    "conv.add(Dropout(0.25))\n",
    "conv.add(Conv1D(filters=16, kernel_size=2,strides=2,padding='same',activation='relu'))\n",
    "conv.add(Conv1D(filters=16, kernel_size=3,strides=1,padding='same',activation='relu'))\n",
    "conv.add(BatchNormalization())\n",
    "conv.add(Dropout(0.25))\n",
    "conv.add(Conv1D(filters=16, kernel_size=2,strides=2,padding='same',activation='relu'))\n",
    "conv.add(Conv1D(filters=16, kernel_size=3,strides=1,padding='same',activation='relu'))\n",
    "conv.add(Reshape(target_shape=(4*16,)))\n",
    "conv.add(Dense(96, activation='relu'))\n",
    "conv.add(BatchNormalization())\n",
    "conv.add(Dropout(0.65))\n",
    "conv.add(Dense(96, activation='tanh'))\n",
    "conv.add(BatchNormalization())\n",
    "conv.add(Dropout(0.45))\n",
    "conv.add(Dense(96, activation='relu'))\n",
    "conv.add(BatchNormalization())\n",
    "conv.add(Dropout(0.20))\n",
    "conv.add(Dense(96, activation='tanh'))\n",
    "conv.add(BatchNormalization())\n",
    "conv.add(Dropout(0.15))\n",
    "conv.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "conv.compile(optimizer='adam', loss=MeanSquaredError(), metrics=['accuracy'])\n",
    "conv.summary()\n",
    "\n",
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "early_stopping=EarlyStopping(monitor='val_accuracy',\n",
    "                             baseline=0.70,\n",
    "                             patience=20,\n",
    "                             restore_best_weights=True,\n",
    "                             start_from_epoch=50,\n",
    "                             mode='max',\n",
    "                             verbose=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99eb0dee-e97a-4b93-80bb-ec379617c0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "291/291 [==============================] - 24s 73ms/step - loss: 0.2507 - accuracy: 0.5652 - val_loss: 0.4513 - val_accuracy: 0.4930\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0608 - accuracy: 0.9233 - val_loss: 0.0362 - val_accuracy: 0.9579\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0243 - accuracy: 0.9717 - val_loss: 0.0154 - val_accuracy: 0.9831\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0187 - accuracy: 0.9787 - val_loss: 0.0145 - val_accuracy: 0.9836\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0150 - accuracy: 0.9831 - val_loss: 0.0137 - val_accuracy: 0.9850\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0128 - accuracy: 0.9855 - val_loss: 0.0123 - val_accuracy: 0.9862\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0110 - accuracy: 0.9878 - val_loss: 0.0144 - val_accuracy: 0.9846\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0098 - accuracy: 0.9891 - val_loss: 0.0140 - val_accuracy: 0.9850\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0092 - accuracy: 0.9899 - val_loss: 0.0121 - val_accuracy: 0.9866\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0085 - accuracy: 0.9906 - val_loss: 0.0119 - val_accuracy: 0.9865\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0080 - accuracy: 0.9912 - val_loss: 0.0129 - val_accuracy: 0.9858\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0073 - accuracy: 0.9921 - val_loss: 0.0123 - val_accuracy: 0.9865\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0069 - accuracy: 0.9924 - val_loss: 0.0114 - val_accuracy: 0.9873\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0068 - accuracy: 0.9925 - val_loss: 0.0120 - val_accuracy: 0.9869\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0064 - accuracy: 0.9931 - val_loss: 0.0107 - val_accuracy: 0.9883\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0059 - accuracy: 0.9936 - val_loss: 0.0100 - val_accuracy: 0.9888\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0054 - accuracy: 0.9941 - val_loss: 0.0108 - val_accuracy: 0.9882\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0052 - accuracy: 0.9944 - val_loss: 0.0114 - val_accuracy: 0.9877\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0049 - accuracy: 0.9948 - val_loss: 0.0100 - val_accuracy: 0.9891\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0049 - accuracy: 0.9947 - val_loss: 0.0105 - val_accuracy: 0.9888\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0045 - accuracy: 0.9950 - val_loss: 0.0106 - val_accuracy: 0.9888\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0043 - accuracy: 0.9953 - val_loss: 0.0118 - val_accuracy: 0.9879\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0038 - accuracy: 0.9959 - val_loss: 0.0086 - val_accuracy: 0.9905\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0040 - accuracy: 0.9956 - val_loss: 0.0078 - val_accuracy: 0.9914\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0037 - accuracy: 0.9960 - val_loss: 0.0086 - val_accuracy: 0.9908\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0032 - accuracy: 0.9967 - val_loss: 0.0086 - val_accuracy: 0.9907\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0036 - accuracy: 0.9961 - val_loss: 0.0074 - val_accuracy: 0.9918\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0031 - accuracy: 0.9966 - val_loss: 0.0065 - val_accuracy: 0.9932\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0030 - accuracy: 0.9967 - val_loss: 0.0065 - val_accuracy: 0.9931\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0030 - accuracy: 0.9968 - val_loss: 0.0059 - val_accuracy: 0.9937\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0033 - accuracy: 0.9964 - val_loss: 0.0067 - val_accuracy: 0.9929\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0027 - accuracy: 0.9971 - val_loss: 0.0055 - val_accuracy: 0.9940\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0024 - accuracy: 0.9974 - val_loss: 0.0055 - val_accuracy: 0.9942\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0023 - accuracy: 0.9975 - val_loss: 0.0059 - val_accuracy: 0.9937\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0023 - accuracy: 0.9974 - val_loss: 0.0057 - val_accuracy: 0.9940\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0023 - accuracy: 0.9975 - val_loss: 0.0053 - val_accuracy: 0.9942\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0024 - accuracy: 0.9974 - val_loss: 0.0063 - val_accuracy: 0.9932\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0024 - accuracy: 0.9974 - val_loss: 0.0047 - val_accuracy: 0.9947\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0023 - accuracy: 0.9975 - val_loss: 0.0043 - val_accuracy: 0.9954\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0020 - accuracy: 0.9978 - val_loss: 0.0047 - val_accuracy: 0.9951\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0020 - accuracy: 0.9979 - val_loss: 0.0052 - val_accuracy: 0.9946\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0020 - accuracy: 0.9979 - val_loss: 0.0062 - val_accuracy: 0.9936\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0023 - accuracy: 0.9976 - val_loss: 0.0049 - val_accuracy: 0.9949\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0020 - accuracy: 0.9979 - val_loss: 0.0057 - val_accuracy: 0.9942\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0021 - accuracy: 0.9978 - val_loss: 0.0051 - val_accuracy: 0.9947\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0019 - accuracy: 0.9979 - val_loss: 0.0046 - val_accuracy: 0.9953\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0018 - accuracy: 0.9981 - val_loss: 0.0045 - val_accuracy: 0.9953\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0017 - accuracy: 0.9982 - val_loss: 0.0049 - val_accuracy: 0.9950\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0026 - accuracy: 0.9971 - val_loss: 0.0052 - val_accuracy: 0.9945\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0021 - accuracy: 0.9978 - val_loss: 0.0052 - val_accuracy: 0.9946\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0023 - accuracy: 0.9975 - val_loss: 0.0053 - val_accuracy: 0.9946\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0019 - accuracy: 0.9980 - val_loss: 0.0046 - val_accuracy: 0.9953\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0019 - accuracy: 0.9980 - val_loss: 0.0044 - val_accuracy: 0.9953\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0022 - accuracy: 0.9978 - val_loss: 0.0055 - val_accuracy: 0.9944\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0025 - accuracy: 0.9974 - val_loss: 0.0046 - val_accuracy: 0.9952\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0017 - accuracy: 0.9982 - val_loss: 0.0051 - val_accuracy: 0.9947\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0021 - accuracy: 0.9978 - val_loss: 0.0051 - val_accuracy: 0.9947\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0020 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9948\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0020 - accuracy: 0.9978 - val_loss: 0.0050 - val_accuracy: 0.9947\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0020 - accuracy: 0.9979 - val_loss: 0.0045 - val_accuracy: 0.9953\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0015 - accuracy: 0.9983 - val_loss: 0.0043 - val_accuracy: 0.9955\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0015 - accuracy: 0.9984 - val_loss: 0.0045 - val_accuracy: 0.9954\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0017 - accuracy: 0.9982 - val_loss: 0.0050 - val_accuracy: 0.9947\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0016 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9950\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0021 - accuracy: 0.9978 - val_loss: 0.0054 - val_accuracy: 0.9944\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0017 - accuracy: 0.9983 - val_loss: 0.0046 - val_accuracy: 0.9953\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0016 - accuracy: 0.9983 - val_loss: 0.0044 - val_accuracy: 0.9955\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0014 - accuracy: 0.9985 - val_loss: 0.0046 - val_accuracy: 0.9953\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0014 - accuracy: 0.9986 - val_loss: 0.0048 - val_accuracy: 0.9950\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0015 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9952\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0016 - accuracy: 0.9984 - val_loss: 0.0044 - val_accuracy: 0.9953\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0014 - accuracy: 0.9986 - val_loss: 0.0045 - val_accuracy: 0.9954\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0015 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9952\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0016 - accuracy: 0.9983 - val_loss: 0.0047 - val_accuracy: 0.9951\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0017 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9949\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0015 - accuracy: 0.9984 - val_loss: 0.0055 - val_accuracy: 0.9942\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0016 - accuracy: 0.9983 - val_loss: 0.0047 - val_accuracy: 0.9951\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0015 - accuracy: 0.9985 - val_loss: 0.0046 - val_accuracy: 0.9953\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0015 - accuracy: 0.9985 - val_loss: 0.0043 - val_accuracy: 0.9955\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0013 - accuracy: 0.9986 - val_loss: 0.0052 - val_accuracy: 0.9946\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0018 - accuracy: 0.9981 - val_loss: 0.0050 - val_accuracy: 0.9948\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0018 - accuracy: 0.9981 - val_loss: 0.0046 - val_accuracy: 0.9952\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0014 - accuracy: 0.9986 - val_loss: 0.0048 - val_accuracy: 0.9951\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0017 - accuracy: 0.9983 - val_loss: 0.0043 - val_accuracy: 0.9956\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0014 - accuracy: 0.9986 - val_loss: 0.0052 - val_accuracy: 0.9947\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0014 - accuracy: 0.9986 - val_loss: 0.0047 - val_accuracy: 0.9952\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0014 - accuracy: 0.9986 - val_loss: 0.0052 - val_accuracy: 0.9946\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0014 - accuracy: 0.9985 - val_loss: 0.0048 - val_accuracy: 0.9950\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0020 - accuracy: 0.9978 - val_loss: 0.0054 - val_accuracy: 0.9945\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0017 - accuracy: 0.9981 - val_loss: 0.0045 - val_accuracy: 0.9953\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0014 - accuracy: 0.9985 - val_loss: 0.0045 - val_accuracy: 0.9953\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0013 - accuracy: 0.9986 - val_loss: 0.0047 - val_accuracy: 0.9952\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0014 - accuracy: 0.9985 - val_loss: 0.0052 - val_accuracy: 0.9947\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0013 - accuracy: 0.9987 - val_loss: 0.0049 - val_accuracy: 0.9949\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0013 - accuracy: 0.9987 - val_loss: 0.0045 - val_accuracy: 0.9954\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0015 - accuracy: 0.9984 - val_loss: 0.0042 - val_accuracy: 0.9957\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0012 - accuracy: 0.9988 - val_loss: 0.0041 - val_accuracy: 0.9957\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0013 - accuracy: 0.9987 - val_loss: 0.0043 - val_accuracy: 0.9955\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0012 - accuracy: 0.9987 - val_loss: 0.0048 - val_accuracy: 0.9951\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 0.0015 - accuracy: 0.9984 - val_loss: 0.0045 - val_accuracy: 0.9952\n"
     ]
    }
   ],
   "source": [
    "history = conv.fit(x_train, y_train,\n",
    "                    batch_size=500,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e03e3b6-329a-490c-af2a-4d8545abddf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 0.9947\n",
      "[0.0050274827517569065, 0.9947096705436707]\n",
      "Test score: 0.0050274827517569065\n",
      "Test accuracy: 0.9947096705436707\n"
     ]
    }
   ],
   "source": [
    "score = conv.evaluate(x_valid, y_valid, batch_size=512, verbose=1)\n",
    "print (score)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45beac22-8cbd-4e0d-aa0c-abc897717062",
   "metadata": {},
   "source": [
    "# Conv2d NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "399599d3-6f2a-49c3-8159-75b1574aa77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, None, 130)         12126010  \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 130, 130, 1)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 128, 128, 8)       80        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 8)       584       \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 128, 128, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 128, 128, 8)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 8)         264       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 8)         584       \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 64, 64, 8)         32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 64, 64, 8)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 8)         264       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 32, 32, 8)         584       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 32, 32, 8)         32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 32, 32, 8)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 16, 16, 16)        528       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 16)        2320      \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 16, 16, 16)        64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 16, 16, 16)        0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 8, 8, 16)          1040      \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 8, 8, 16)          2320      \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  (None, 8, 8, 16)          64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 8, 8, 16)          0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 4, 4, 32)          2080      \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 4, 4, 32)          9248      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 96)                49248     \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, 96)                384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 96)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 96)                9312      \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, 96)                384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 96)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 96)                9312      \n",
      "                                                                 \n",
      " batch_normalization_24 (Ba  (None, 96)                384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 96)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 96)                9312      \n",
      "                                                                 \n",
      " batch_normalization_25 (Ba  (None, 96)                384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 96)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 97        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12224947 (46.63 MB)\n",
      "Trainable params: 12224067 (46.63 MB)\n",
      "Non-trainable params: 880 (3.44 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D,Flatten,Reshape\n",
    "\n",
    "# Convolutional 1D from 130x to 4x\n",
    "conv2 = Sequential()\n",
    "conv2.add(Embedding(\n",
    "    input_dim=dictionary_size_plus_1,\n",
    "    output_dim=max_vector_length,\n",
    "    embeddings_initializer=\"uniform\",\n",
    "    embeddings_regularizer=None,\n",
    "    embeddings_constraint=None,\n",
    "    mask_zero=True))\n",
    "conv2.add(Reshape(target_shape=(130,130,1)))\n",
    "# Decresing from 130 to 128\n",
    "conv2.add(Conv2D(filters=8, kernel_size=(3,3),strides=1,padding='valid',activation='relu'))\n",
    "conv2.add(Conv2D(filters=8, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "conv2.add(BatchNormalization())\n",
    "conv2.add(Dropout(0.25))\n",
    "conv2.add(Conv2D(filters=8, kernel_size=(2,2),strides=2,padding='same',activation='relu'))\n",
    "conv2.add(Conv2D(filters=8, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "conv2.add(BatchNormalization())\n",
    "conv2.add(Dropout(0.25))\n",
    "conv2.add(Conv2D(filters=8, kernel_size=(2,2),strides=2,padding='same',activation='relu'))\n",
    "conv2.add(Conv2D(filters=8, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "conv2.add(BatchNormalization())\n",
    "conv2.add(Dropout(0.25))\n",
    "conv2.add(Conv2D(filters=16, kernel_size=(2,2),strides=2,padding='same',activation='relu'))\n",
    "conv2.add(Conv2D(filters=16, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "conv2.add(BatchNormalization())\n",
    "conv2.add(Dropout(0.25))\n",
    "conv2.add(Conv2D(filters=16, kernel_size=(2,2),strides=2,padding='same',activation='relu'))\n",
    "conv2.add(Conv2D(filters=16, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "conv2.add(BatchNormalization())\n",
    "conv2.add(Dropout(0.25))\n",
    "conv2.add(Conv2D(filters=32, kernel_size=(2,2),strides=2,padding='same',activation='relu'))\n",
    "conv2.add(Conv2D(filters=32, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "conv2.add(Flatten())\n",
    "conv2.add(Dense(96, activation='relu'))\n",
    "conv2.add(BatchNormalization())\n",
    "conv2.add(Dropout(0.65))\n",
    "conv2.add(Dense(96, activation='tanh'))\n",
    "conv2.add(BatchNormalization())\n",
    "conv2.add(Dropout(0.45))\n",
    "conv2.add(Dense(96, activation='relu'))\n",
    "conv2.add(BatchNormalization())\n",
    "conv2.add(Dropout(0.20))\n",
    "conv2.add(Dense(96, activation='tanh'))\n",
    "conv2.add(BatchNormalization())\n",
    "conv2.add(Dropout(0.15))\n",
    "conv2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "conv2.compile(optimizer='adam', loss=MeanSquaredError(), metrics=['accuracy'])\n",
    "conv2.summary()\n",
    "\n",
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "early_stopping=EarlyStopping(monitor='val_accuracy',\n",
    "                             baseline=0.70,\n",
    "                             patience=10,\n",
    "                             restore_best_weights=True,\n",
    "                             start_from_epoch=20,\n",
    "                             mode='max',\n",
    "                             verbose=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a20c402-fcf0-48d8-a4d9-c5ab32e859f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "291/291 [==============================] - 171s 581ms/step - loss: 0.2684 - accuracy: 0.5005 - val_loss: 0.2505 - val_accuracy: 0.5070\n",
      "Epoch 2/50\n",
      "291/291 [==============================] - 169s 580ms/step - loss: 0.2547 - accuracy: 0.5004 - val_loss: 0.2510 - val_accuracy: 0.5070\n",
      "Epoch 3/50\n",
      "291/291 [==============================] - 169s 580ms/step - loss: 0.2511 - accuracy: 0.5024 - val_loss: 0.2503 - val_accuracy: 0.5070\n",
      "Epoch 4/50\n",
      "291/291 [==============================] - 169s 580ms/step - loss: 0.2499 - accuracy: 0.5132 - val_loss: 0.2407 - val_accuracy: 0.5865\n",
      "Epoch 5/50\n",
      "291/291 [==============================] - 169s 580ms/step - loss: 0.1107 - accuracy: 0.8184 - val_loss: 0.0092 - val_accuracy: 0.9901\n",
      "Epoch 6/50\n",
      "291/291 [==============================] - 169s 580ms/step - loss: 0.0081 - accuracy: 0.9906 - val_loss: 0.0061 - val_accuracy: 0.9932\n",
      "Epoch 7/50\n",
      "291/291 [==============================] - 169s 579ms/step - loss: 0.0049 - accuracy: 0.9945 - val_loss: 0.0053 - val_accuracy: 0.9941\n",
      "Epoch 8/50\n",
      "291/291 [==============================] - 169s 579ms/step - loss: 0.0038 - accuracy: 0.9957 - val_loss: 0.0049 - val_accuracy: 0.9944\n",
      "Epoch 9/50\n",
      "291/291 [==============================] - 169s 579ms/step - loss: 0.0031 - accuracy: 0.9965 - val_loss: 0.0045 - val_accuracy: 0.9949\n",
      "Epoch 10/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0029 - accuracy: 0.9968 - val_loss: 0.0047 - val_accuracy: 0.9948\n",
      "Epoch 11/50\n",
      "291/291 [==============================] - 168s 579ms/step - loss: 0.0024 - accuracy: 0.9974 - val_loss: 0.0042 - val_accuracy: 0.9953\n",
      "Epoch 12/50\n",
      "291/291 [==============================] - 169s 579ms/step - loss: 0.0021 - accuracy: 0.9977 - val_loss: 0.0046 - val_accuracy: 0.9950\n",
      "Epoch 13/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0021 - accuracy: 0.9977 - val_loss: 0.0044 - val_accuracy: 0.9952\n",
      "Epoch 14/50\n",
      "291/291 [==============================] - 168s 579ms/step - loss: 0.0019 - accuracy: 0.9979 - val_loss: 0.0043 - val_accuracy: 0.9953\n",
      "Epoch 15/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0019 - accuracy: 0.9979 - val_loss: 0.0042 - val_accuracy: 0.9953\n",
      "Epoch 16/50\n",
      "291/291 [==============================] - 168s 579ms/step - loss: 0.0018 - accuracy: 0.9980 - val_loss: 0.0045 - val_accuracy: 0.9950\n",
      "Epoch 17/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0018 - accuracy: 0.9981 - val_loss: 0.0044 - val_accuracy: 0.9952\n",
      "Epoch 18/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0016 - accuracy: 0.9983 - val_loss: 0.0043 - val_accuracy: 0.9953\n",
      "Epoch 19/50\n",
      "291/291 [==============================] - 168s 577ms/step - loss: 0.0016 - accuracy: 0.9983 - val_loss: 0.0044 - val_accuracy: 0.9952\n",
      "Epoch 20/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0014 - accuracy: 0.9986 - val_loss: 0.0041 - val_accuracy: 0.9956\n",
      "Epoch 21/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0014 - accuracy: 0.9985 - val_loss: 0.0044 - val_accuracy: 0.9954\n",
      "Epoch 22/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0013 - accuracy: 0.9986 - val_loss: 0.0042 - val_accuracy: 0.9954\n",
      "Epoch 23/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0013 - accuracy: 0.9986 - val_loss: 0.0046 - val_accuracy: 0.9951\n",
      "Epoch 24/50\n",
      "291/291 [==============================] - 168s 577ms/step - loss: 0.0014 - accuracy: 0.9986 - val_loss: 0.0053 - val_accuracy: 0.9944\n",
      "Epoch 25/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0013 - accuracy: 0.9986 - val_loss: 0.0041 - val_accuracy: 0.9957\n",
      "Epoch 26/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0012 - accuracy: 0.9986 - val_loss: 0.0048 - val_accuracy: 0.9949\n",
      "Epoch 27/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0012 - accuracy: 0.9987 - val_loss: 0.0046 - val_accuracy: 0.9952\n",
      "Epoch 28/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0013 - accuracy: 0.9986 - val_loss: 0.0041 - val_accuracy: 0.9957\n",
      "Epoch 29/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0012 - accuracy: 0.9987 - val_loss: 0.0046 - val_accuracy: 0.9951\n",
      "Epoch 30/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0012 - accuracy: 0.9987 - val_loss: 0.0040 - val_accuracy: 0.9959\n",
      "Epoch 31/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0010 - accuracy: 0.9989 - val_loss: 0.0040 - val_accuracy: 0.9958\n",
      "Epoch 32/50\n",
      "291/291 [==============================] - 168s 577ms/step - loss: 0.0010 - accuracy: 0.9989 - val_loss: 0.0042 - val_accuracy: 0.9956\n",
      "Epoch 33/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0010 - accuracy: 0.9989 - val_loss: 0.0045 - val_accuracy: 0.9953\n",
      "Epoch 34/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0011 - accuracy: 0.9988 - val_loss: 0.0044 - val_accuracy: 0.9955\n",
      "Epoch 35/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0011 - accuracy: 0.9988 - val_loss: 0.0044 - val_accuracy: 0.9955\n",
      "Epoch 36/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0011 - accuracy: 0.9988 - val_loss: 0.0040 - val_accuracy: 0.9957\n",
      "Epoch 37/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 0.0010 - accuracy: 0.9988 - val_loss: 0.0058 - val_accuracy: 0.9938\n",
      "Epoch 38/50\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 9.3285e-04 - accuracy: 0.9990 - val_loss: 0.0045 - val_accuracy: 0.9952\n",
      "Epoch 39/50\n",
      "291/291 [==============================] - 168s 577ms/step - loss: 9.9493e-04 - accuracy: 0.9989 - val_loss: 0.0043 - val_accuracy: 0.9955\n",
      "Epoch 40/50\n",
      "291/291 [==============================] - ETA: 0s - loss: 9.0958e-04 - accuracy: 0.9990Restoring model weights from the end of the best epoch: 30.\n",
      "291/291 [==============================] - 168s 578ms/step - loss: 9.0958e-04 - accuracy: 0.9990 - val_loss: 0.0047 - val_accuracy: 0.9952\n",
      "Epoch 40: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = conv2.fit(x_train, y_train,\n",
    "                    batch_size=500,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f0ceed9-de27-4908-9137-fdd4e09758d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 4s 90ms/step - loss: 0.0045 - accuracy: 0.9952\n",
      "[0.004482968710362911, 0.995238721370697]\n",
      "Test score: 0.004482968710362911\n",
      "Test accuracy: 0.995238721370697\n"
     ]
    }
   ],
   "source": [
    "score = conv2.evaluate(x_valid, y_valid, batch_size=512, verbose=1)\n",
    "print (score)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36241bdb-6793-4947-a849-2b4686729df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
